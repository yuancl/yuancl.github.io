<!DOCTYPE html>



  


<html class="theme-next gemini use-motion" lang="zh-Hans">
<head><meta name="generator" content="Hexo 3.8.0">
  <meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform">
<meta http-equiv="Cache-Control" content="no-siteapp">















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css">




  
  
  
  

  
    
    
  

  

  

  

  

  
    
    
    <link href="//fonts.googleapis.com/css?family=Lato:300,300italic,400,400italic,700,700italic&subset=latin,latin-ext" rel="stylesheet" type="text/css">
  






<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css">

<link href="/css/main.css?v=5.1.2" rel="stylesheet" type="text/css">


  <meta name="keywords" content="Hexo, NexT">








  <link rel="shortcut icon" type="image/x-icon" href="/favicon.ico?v=5.1.2">






<meta name="description" content="不积跬步无以至千里">
<meta property="og:type" content="website">
<meta property="og:title" content="雷哥的博客">
<meta property="og:url" content="http://yoursite.com/index.html">
<meta property="og:site_name" content="雷哥的博客">
<meta property="og:description" content="不积跬步无以至千里">
<meta property="og:locale" content="zh-Hans">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="雷哥的博客">
<meta name="twitter:description" content="不积跬步无以至千里">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Gemini',
    sidebar: {"position":"left","display":"post","offset":12,"offset_float":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: true,
    duoshuo: {
      userId: '0',
      author: '雷哥'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://yoursite.com/">





  <title>雷哥的博客</title>
  














</head>

<body itemscope="" itemtype="http://schema.org/WebPage" lang="zh-Hans">

  
  
    
  

  <div class="container sidebar-position-left 
   page-home 
 ">
    <div class="headband"></div>

    <header id="header" class="header" itemscope="" itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">雷哥的博客</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle"></p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br>
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br>
            
            分类
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br>
            
            归档
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br>
            
            标签
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            
  <section id="posts" class="posts-expand">
    
	
      	    

  

  
  
  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/03/31/rs/总结篇 推荐系统难点/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="雷哥">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/favicon.ico">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="雷哥的博客">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/03/31/rs/总结篇 推荐系统难点/" itemprop="url">总结篇:推荐系统难点</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-03-31T20:31:22+08:00">
                2019-03-31
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing">
                  <a href="/categories/推荐系统/" itemprop="url" rel="index">
                    <span itemprop="name">推荐系统</span>
                  </a>
                </span>

                
                
                  ， 
                
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing">
                  <a href="/categories/推荐系统/总结篇/" itemprop="url" rel="index">
                    <span itemprop="name">总结篇</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p><a href="https://mp.weixin.qq.com/s/0a4Ne9lgx1rmnE1jXfH6zQ" target="_blank" rel="noopener">达观数据个性化推荐系统实践</a><br><a href="https://mp.weixin.qq.com/s/SAmTNxTgtGLZ9cUH81FYgg" target="_blank" rel="noopener">刘志强 奇虎360:机器学习与推荐系统实践</a></p>
<h4 id="整体过程"><a href="#整体过程" class="headerlink" title="整体过程"></a>整体过程</h4><ul>
<li>用户<br>推荐系统本质是将人和物品关联起来，而系统对用户的理解也是由浅入深，初来时彼此陌生，需要有一个冷启的过程，逐渐把握用户的喜好。随着用户行为的丰富，系统对用户兴趣的描述也越来越客观，此时便可能得到更准确的用户偏好，进而完成更精准的推荐。然而物极必反，用户对于一个平台的认知与期望也是一样。随着用户的深度使用，势必对推荐系统生出更高的期待和要求。这时，便可能需要系统在满足深度用户某种刁钻的口味，与大众用户的普遍期待中做出某种取舍。用户也就不可避免的出现了流失。因为系统的能力终归有限，而用户的期望无限。</li>
<li>资源<br>此外资源也会经历类似的过程，新进场的资源虽然天然有某种内容的属性，但其被用户接受，仍然不可避免需要经历一个过程。过程中有些资源会被淘汰，有些则会成长为热门。在不断地引入新资源的过程中，再热门的资源都会有过期的一天。就好比，再会保养的人，也逃不过岁月的流逝。甚至，为了保持系统的实时性，热门的资源需要主动地让出在系统中的曝光份额
</li>
</ul>
<h4 id="如何精准把握用户兴趣"><a href="#如何精准把握用户兴趣" class="headerlink" title="如何精准把握用户兴趣"></a>如何精准把握用户兴趣</h4><p>用户兴趣不仅存在多样性，而且会随着时间的变化而变化</p>
<ul>
<li>长短期兴趣画像让模型效果稳定提升</li>
<li>通过引入时间因子，基于不同的时间周期做用户画像<ul>
<li>比如基于最近半年的或更久的数据做长期用户画像，基于近一个月或三个月做短期用户画像，同时还会有实时用户画像，基于这三种类型用户画像之间的差异化，能够感知用户的兴趣变更</li>
</ul>
</li>
<li>基于用户画像后做一个过滤机制，把推荐过或者质量不佳先过滤。这样做排序时会引入一个时间因子做一个衰减，另外也会做机器学习的预测，可以方便地调整推荐顺序。</li>
<li>接下来做优化，随着时间的推移，对于用户的刻画会更清晰准确</li>
</ul>
<h4 id="冷启动"><a href="#冷启动" class="headerlink" title="冷启动"></a>冷启动</h4><ul>
<li>主要分为:用户冷启动，物品冷启动，系统冷启动</li>
<li>用户冷启动<ul>
<li>和其他领域做映射<br>从其他维度或领域的数据来判断新用户对现存物品的喜好。具体解释就是某个用户可能在已有领域current domain和另一领域out domain都有相关行为，可对两个不同领域的行为建立一个mapping，<font color="blue">当新用户来的时候，如果在另一领域有相关行为，可用该mapping作出prediction</font>，得到新用户对item的喜好程度</li>
<li>先给用户推荐热门内容，等行为多后再进行个性化推荐</li>
<li>利用注册信息<br>根据用户注册账号时填写的性别、年龄、地址等信息，推荐相关性高的内容或者商品<ul>
<li>比如说一个人的性别是男、年龄是40岁、职业是老师，那么就会有对应“性别是男、年龄是40岁、职业是老师”的三个相关推荐列表，再根据筛选，确定最终的推荐列表</li>
</ul>
</li>
<li>授权设备信息<br>通过授权，可以获得手机中的位置，通讯录，按照app等，然后通过这些信息来做进一步聚合推荐<ul>
<li>指的是允许app访问手机的一些信息，比如定位、安装信息、通讯录等，这样就可以推荐通讯录好友喜欢过的内容或商品</li>
<li>或者说你手机里安装过懂球帝，就可以给你推荐足球相关的内容</li>
<li>假如你安装了美丽说、蘑菇街、大姨妈等app，就可以判定你是女性了，更进一步还可以判定你是备孕还是少女</li>
</ul>
</li>
<li>首次登录选标签<br>要求用户进来时选择一个或者多个标签，然后收集整理用户感兴趣的范围，去推荐相关性高的内容和商品</li>
<li>绑定社交账号<br>利用用户的社交网络账号登录（需要用户授权），导入用户在社交网站上的好友信息，然后给用户推荐其好友喜欢的内容或物品</li>
</ul>
</li>
<li>物品冷启动<ul>
<li>对物品分类，可以使用Item-CF方法，推荐给相关用户</li>
<li>设置一定概率的曝光机会，然后根据收益进行调整</li>
</ul>
</li>
<li>系统冷启动<ul>
<li>采用专家标注<br>对物品进行人工的标记，比如电影可以标记心情、剧情类型、类别、故事时间、地点、观众类型、获奖情况、风格、主旨、画面技术等等。在专家标记了一定样本之后使用自然语言理解和机器学习技术，通过分析用户对电影的评价和电影自身的内容属性对新电影进行自我标记。同时还设置了用户反馈界面，通过用户反馈进行改善</li>
</ul>
</li>
</ul>
<h4 id="回声室效应"><a href="#回声室效应" class="headerlink" title="回声室效应"></a>回声室效应</h4><p>为了满足用户的兴趣。第二部分是重复，如果依赖于内容标签或者内容分类，对于标签或者类目来不断地召回新的推荐结果，这会导致推荐结果没有新鲜感</p>
<h4 id="性能方面"><a href="#性能方面" class="headerlink" title="性能方面"></a>性能方面</h4><ul>
<li>采用离线，近实时，实时三层架构解决，可以参考推荐系统架构篇</li>
</ul>
<h4 id="其他问题"><a href="#其他问题" class="headerlink" title="其他问题"></a>其他问题</h4><ul>
<li>精准兴趣<br>在推荐系统中，我们往往使用用户的点击行为来估计用户的喜好类型。然而用户的每次点击未必都是经过其深思熟虑之后的结果，因此行为本身会存在一个置信度的问题。而这个置信度是未知的</li>
<li>新资源找不到合适用户<br>大量优质资源找不到需要的用户，成为层面资源，而低俗的内容大量曝光</li>
<li>EE问题</li>
</ul>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


	
    
	
      	    

  

  
  
  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/03/30/rs/总结篇 推荐系统架构/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="雷哥">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/favicon.ico">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="雷哥的博客">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/03/30/rs/总结篇 推荐系统架构/" itemprop="url">总结篇:推荐系统架构</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-03-30T07:30:21+08:00">
                2019-03-30
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing">
                  <a href="/categories/推荐系统/" itemprop="url" rel="index">
                    <span itemprop="name">推荐系统</span>
                  </a>
                </span>

                
                
                  ， 
                
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing">
                  <a href="/categories/推荐系统/总结篇/" itemprop="url" rel="index">
                    <span itemprop="name">总结篇</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p><a href="https://mp.weixin.qq.com/s/0a4Ne9lgx1rmnE1jXfH6zQ" target="_blank" rel="noopener">达观数据个性化推荐系统实践</a><br><a href="https://zhuanlan.zhihu.com/p/59528983" target="_blank" rel="noopener">张俊林</a><br><a href="http://www.shuang0420.com/2017/03/13/论文笔记%20-%20Wide%20and%20Deep%20Learning%20for%20Recommender%20Systems/" target="_blank" rel="noopener">GP应用推荐举例</a></p>
<h4 id="推荐系统应用方向"><a href="#推荐系统应用方向" class="headerlink" title="推荐系统应用方向"></a>推荐系统应用方向</h4><p>个性化推荐，相关推荐，热门推荐。。。<br></p>
<h4 id="推荐系统设计目标"><a href="#推荐系统设计目标" class="headerlink" title="推荐系统设计目标"></a>推荐系统设计目标</h4><ul>
<li>功能：功能上要全面些，包括相关推荐、个性化推荐、热门推荐等还包括混合推荐</li>
<li>效果：效果在不同领域有差异，如在直播领域关注送礼物、打赏收入等，而资讯行业较关注人均点击数量、用户停留时长等；</li>
<li>性能：性能在不同领域也是有差异的，但是必须是快速、稳定的，不允许出现推荐位置的留白，也就是你的推荐系统可以效果不好但是不能空白，在高并发时要求性能稳定快速。其实在实际业务场景中这三者是相互影响，权衡利弊的
</li>
</ul>
<h4 id="系统层次图"><a href="#系统层次图" class="headerlink" title="系统层次图"></a>系统层次图</h4><ul>
<li>基础层，对于服务多家客户来说首先是基础运算平台，全部基于Hadoop和Spark。基础存储平台是基于HBase、MySQL、Redis、HDFS等，传输平台是DgIO，主要基于消息队列的方式。</li>
<li>在组件层有各种各样的组件和算法库，实现多个产品服务都可以复用。对于这些组件也有相应的研发团队进行升级和维护，如文本分类、标签、语义理解都是由文本组处理，对于搜索引擎性能、相关性等的优化升级是由搜索组完成，组件都是共同使用共同维护。<ul>
<li>组件层有一系列小的组件，基于组件可以做一些模型层的事情，比如推荐相关的做用户画像，因为对于不同行业的用户画像有不同的标准，我们拿到的就是用户id和行为数据，刻画用户画像主要基于向量方式。物品画像主要解决流向，就是物品来了如何及时曝光，这时就需要依据其初始信息进行预估打分，对于已经曝光的物品会记录一段时间的收益情况（点击率、收藏数据等）形成物品画像做一些过滤信息。趋势分析主要是物品曝光后接下来是怎么样的，用户关系主要是基于用户行为分析的，主要做社交关系的推荐。物品关系主要是做算法方面的处理。</li>
</ul>
</li>
<li>算法层主要是包括基于内容的推荐、矩阵分解、协同过滤、深度学习等。基于内容推荐如标签召回、热门召回、内容召回，深度学习各行业都在使用。</li>
<li>组合层，对各种单一推荐算法的召回结果，使用机器学习的方式进行融合，以达到推荐效果的最优化。</li>
<li>应用层，目前提供三种推荐，同时还有推荐理由，就是可解释性
</li>
</ul>
<h4 id="整体架构"><a href="#整体架构" class="headerlink" title="整体架构"></a>整体架构</h4>
<ul>
<li>在线部分<ul>
<li>召回：通过召回环节，将给用户推荐的物品降到千以下规模</li>
<li>粗排：如果召回阶段返回的物品还是太多，可以加入粗排阶段，这个阶段是可选的，粗排可以通过一些简单排序模型进一步减少往后续环节传递的物品</li>
<li>精排：使用复杂的模型来对少量物品精准排序</li>
<li>其他逻辑：即使精排推荐结果出来了，一般并不会直接展示给用户，可能还要上一些业务策略，比如去已读，推荐多样化，加入广告等各种业务策略。之后形成最终推荐结果，将结果展示给用户</li>
</ul>
</li>
<li>近线部分<br>主要目的是<font color="blue">实时收集用户行为反馈</font>，并选择训练实例，实时抽取拼接特征，并近乎实时地更新在线推荐模型。这样做的好处是用户的最新兴趣能够近乎实时地体现到推荐结果里</li>
<li>离线部分<br>通过对<font color="blue">线上用户点击日志的存储和清理，整理离线训练数据</font>，并周期性地更新推荐模型。对于超大规模数据和机器学习模型来说，往往需要高效地分布式机器学习平台来对离线训练进行支持</li>
</ul>

<ul>
<li>GP应用推荐举例
</li>
</ul>
<h4 id="在线部分"><a href="#在线部分" class="headerlink" title="在线部分"></a>在线部分</h4><ul>
<li>召回阶段<br>将物料从千万级别，降低到百级别</li>
</ul>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


	
    
	
    
	
    
	
      	    

  

  
  
  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/03/26/rs/总结篇 推荐算法总结/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="雷哥">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/favicon.ico">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="雷哥的博客">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/03/26/rs/总结篇 推荐算法总结/" itemprop="url">推荐算法总结</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-03-26T07:30:21+08:00">
                2019-03-26
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing">
                  <a href="/categories/推荐系统/" itemprop="url" rel="index">
                    <span itemprop="name">推荐系统</span>
                  </a>
                </span>

                
                
                  ， 
                
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing">
                  <a href="/categories/推荐系统/总结篇/" itemprop="url" rel="index">
                    <span itemprop="name">总结篇</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h4 id="相关文章"><a href="#相关文章" class="headerlink" title="相关文章"></a>相关文章</h4><p><a href="https://mp.weixin.qq.com/s/i8ClwpTGMB5cu0evrrZQGw" target="_blank" rel="noopener">算法粗略介绍：搜索与推荐中的深度学习匹配：推荐篇</a><br><a href="https://www.ibm.com/developerworks/cn/web/1103_zhaoct_recommstudy1" target="_blank" rel="noopener">探索推荐引擎内部的秘密</a><br><a href="https://zhuanlan.zhihu.com/c_188941548" target="_blank" rel="noopener">张俊林-推荐系统召回模型</a><br><a href="https://www.hrwhisper.me/machine-learning-fm-ffm-deepfm-deepffm/" target="_blank" rel="noopener">FM、FFM与DeepFM</a><br><a href="http://www.shuang0420.com/2017/03/13/论文笔记%20-%20Wide%20and%20Deep%20Learning%20for%20Recommender%20Systems/" target="_blank" rel="noopener">WDL论文笔记</a></p>
<h4 id="算法分类"><a href="#算法分类" class="headerlink" title="算法分类"></a>算法分类</h4><ul>
<li><p>分类方法1</p>
<ul>
<li>传统<ul>
<li>协调过滤</li>
<li>矩阵分解(MF)</li>
<li>因式分解机(FM)</li>
</ul>
</li>
<li>基于embedding(深度学习兴起后)<ul>
<li>word-embedding:skip-gram等</li>
<li>graph-embedding:DeepWalk,TransE等</li>
</ul>
</li>
<li>基于深度神经网络<ul>
<li>Deep &amp; Wide</li>
</ul>
</li>
</ul>
</li>
<li><p>分类方法2</p>
<ul>
<li>线性<ul>
<li>LR</li>
<li>在排序模型方面很多基于LR模型，现在很多都是基于深度学习来做，不同模型都有不同的应用场景，并不是单一使用一种场景。<font color="blue">LR模型利用人工特征工程</font>，相对于深度学习的优点是可以感知的，是可以debug的</li>
</ul>
</li>
<li>非线性<ul>
<li>FM,FFM,GBDT+LR,XGboost+LR</li>
<li>LR模型对于特征处理是线性的，利用Xgboost+LR或者GBDT+LR<font color="blue">由线性向非线性转化，能够做到多特征组合</font>，对推荐效果也有不同程度的提升</li>
</ul>
</li>
<li>神经网络<ul>
<li>DeepFM,Wide&amp;Deep</li>
<li>目前还有利用Wide&amp;Deep，可以从特征工程中解放出来，在特征选取方面不需要做很多工作,但是在调参方面工作量比较大</li>
</ul>
</li>
</ul>
</li>
</ul>

<h4 id="协同过滤"><a href="#协同过滤" class="headerlink" title="协同过滤"></a>协同过滤</h4><p><a href="https://www.ibm.com/developerworks/cn/web/1103_zhaoct_recommstudy1" target="_blank" rel="noopener">探索推荐引擎内部的秘密</a></p>
<ul>
<li>基于协同过滤的推荐可以分为三个子类：基于用户的推荐（User-based Recommendation），基于项目的推荐（Item-based Recommendation）和基于模型的推荐（Model-based Recommendation）</li>
<li>基于用户的协同过滤推荐<ul>
<li>基于用户的协同过滤推荐的基本原理是，根据所有用户对物品或者信息的偏好，发现与当前用户口味和偏好相似的“邻居”用户群，在一般的应用中是采用计算“K- 邻居”的算法；然后，基于这 K 个邻居的历史偏好信息，为当前用户进行推荐</li>
</ul>
</li>
<li>基于项目的协同过滤推荐<ul>
<li>基于项目的协同过滤推荐的基本原理也是类似的，只是说它使用所有用户对物品或者信息的偏好，发现物品和物品之间的相似度，然后根据用户的历史偏好信息，将类似的物品推荐给用户</li>
</ul>
</li>
<li>基于协同过滤的推荐机制是现今应用最为广泛的推荐机制，它有以下几个显著的优点：<ul>
<li>它不需要对物品或者用户进行严格的建模，而且不要求物品的描述是机器可理解的，所以这种方法也是领域无关的。</li>
<li>这种方法计算出来的推荐是开放的，可以共用他人的经验，很好的支持用户发现潜在的兴趣偏好</li>
</ul>
</li>
<li>存在以下几个问题：<ul>
<li>方法的核心是基于历史数据，所以对新物品和新用户都有“冷启动”的问题。</li>
<li>推荐的效果依赖于用户历史偏好数据的多少和准确性。</li>
<li>在大部分的实现中，用户历史偏好是用稀疏矩阵进行存储的，而稀疏矩阵上的计算有些明显的问题，包括可能少部分人的错误偏好会对推荐的准确度有很大的影响等等。</li>
<li>对于一些特殊品味的用户不能给予很好的推荐。</li>
<li>由于以历史数据为基础，抓取和建模用户的偏好后，很难修改或者根据用户的使用演变，从而导致这个方法不够灵活。</li>
</ul>
</li>
</ul>
<h4 id="MF"><a href="#MF" class="headerlink" title="MF"></a>MF</h4><ul>
<li>MF（Matrix Factorization，矩阵分解）模型是个在推荐系统领域里资格很深的老前辈协同过滤模型了。核心思想是通过两个低维小矩阵（一个代表用户embedding矩阵，一个代表物品embedding矩阵）的乘积计算，来模拟真实用户点击或评分产生的大的协同信息稀疏矩阵，本质上是编码了用户和物品协同信息的降维模型</li>
<li>当训练完成，每个用户和物品得到对应的低维embedding表达后，如果要预测某个 $User_i 对 Item_j 的评分的时候，只要它们做个内积计算 〈User_i,Item_j 〉$ ，这个得分就是预测得分
</li>
</ul>
<h4 id="SVD-MF-FISM-SVD"><a href="#SVD-MF-FISM-SVD" class="headerlink" title="SVD,MF,FISM,SVD++"></a>SVD,MF,FISM,SVD++</h4><ul>
<li>CF本质就是解决矩阵填充问题</li>
<li>矩阵填充一般是用SVD分解来解决
<ul>
<li>SVD就是在解决以下问题(Loss)</li>
<li>svd有以下缺点：<ul>
<li>missing data(就是没打分的，占比99%)和observed data（观测到的、已打分的）有一样的权重</li>
<li>没有加正则，容易过拟合</li>
</ul>
</li>
<li><font color="purple">注意和MF的区别，这边没没有使用embedding，user，item词嵌入的概念。而是用数学的方法求解的</font></li>
</ul>
</li>
<li>MF<ul>
<li>user和item分别用一个embedding表示，然后用户对item的偏好程度用这两个embedding的内积表示</li>
<li>使用L2-loss（其它loss也可以）和正则：</li>
</ul>
</li>
<li>FISM(Factored Item Similarity Model)<ul>
<li><font color="blue">用user作用过的item的embedding的和来表示user</font>，item用另一套embedding下的一个embedding来表示，最后两者的内积表示user对该item的偏好<ul>
<li>这个模型也叫item-based的CF，因为把括号里的东西展开后，<font color="blue">其实就是找用户作用过的item和item[j]的相似度</font></li>
</ul>
</li>
</ul>
</li>
<li>SVD++<ul>
<li>很简单，另外用一个user的embedding，和上述的FISM的方法，融合来表示user。这曾经是netflix比赛中连续三年效果最好的单模型
</li>
</ul>
</li>
</ul>
<h4 id="FM"><a href="#FM" class="headerlink" title="FM"></a>FM</h4><p><a href="https://zhuanlan.zhihu.com/c_188941548" target="_blank" rel="noopener">张俊林-推荐系统召回模型</a></p>
<ul>
<li><p>从LR到SVM再到FM模型<br>LR模型简单易懂，但不能捕获更高维的特征，比如特征组合这类特征，所以不能很好拟合较复杂的场景(欠拟合)</p>

</li>
<li><p>加入特征组合(提升模型复杂度)</p>
<ul>
<li>虽然这个模型看上去貌似解决了二阶特征组合问题了，但是它有个潜在的问题：它对组合特征建模，泛化能力比较弱</li>
<li>尤其是在大规模稀疏特征存在的场景下，这个毛病尤其突出，比如CTR预估和推荐排序</li>
<li>这些场景的最大特点就是特征的大规模稀疏。所以上述模型并未在工业界广泛采用</li>
<li><font color="blue">主要原因：由于数据稀疏，$x_i x_j$的权重参数$w_{i,j}$很多为0，导致不能学习</font><ul>
<li>在训练数据里两个特征并未同时在训练实例里见到过，意味着 $x_i  and x_j$ 一起出现的次数为0，如果换做SVM的模式，是无法学会这个特征组合的权重的
</li>
</ul>
</li>
</ul>
</li>
<li><p>FM模型<br>对于因子分解机FM来说，<font color="blue">利用特征的嵌入方式，最大的特点是对于稀疏的数据具有很好的学习能力。现实中稀疏的数据很多</font></p>
<ul>
<li><font color="blue">核心：这本质上是在对特征进行embedding化表征</font></li>
<li><p>和SVM模型最大的不同，在于<font color="blue">特征组合权重</font>的计算方法。FM对于每个特征，学习一个大小为k的一维向量，于是，两个特征 $x_i 和 x_j 的特征组合的权重值，通过特征对应的向量 v_i 和 v_j 的内积 &lt;v_i,v_j&gt;$来表示。</p>

</li>
<li><p>为什么模型泛华能力强，能够解决稀疏数据的问题</p>
<ul>
<li>在训练数据里两个特征并未同时在训练实例里见到过，意味着 $x_i  and x_j$ 一起出现的次数为0，如果换做SVM的模式，是无法学会这个特征组合的权重的。</li>
<li>但是因为FM是学习单个特征的embedding，并不依赖某个特定的特征组合是否出现过，所以只要特征 x_i 和其它<font color="blue">任意特征组合</font>出现过，那么就可以学习自己对应的embedding向量<ul>
<li>于是，尽管 $x_i  and x_j$ 这个特征组合没有看到过，但是在预测的时候，如果看到这个新的特征组合，因为 $x_i 和 x_j$ 都能学会自己对应的embedding，所以可以通过内积算出这个新特征组合的权重。</li>
<li>这是为何说FM模型泛化能力强的根本原因 
</li>
</ul>
</li>
</ul>
</li>
<li><p>上式只是对数据的拟合函数，还要根据具体问题比如回归还是分类设以不同的Loss方法进行求解。以及数学求解的方法需要另参考其他资料</p>
</li>
<li><p>算法的效率</p>
<ul>
<li>粗略的看<br>从FM的原始数学公式看，因为在进行二阶（2-order）特征组合的时候，假设有n个不同的特征，那么二阶特征组合意味着任意两个特征都要进行交叉组合，所以可以直接推论得出：FM的时间复杂度是n的平方。但是如果故事仅仅讲到这里，FM模型是不太可能如此广泛地被工业界使用的。因为现实生活应用中的n往往是个非常巨大的特征数，如果FM是n平方的时间复杂度，那估计基本就没人带它玩了</li>
<li>数学公式演示改进(细节也可以参考论文资料等)<br>FM如今被广泛采用并成功替代LR模型的一个关键所在是：它可以通过数学公式改写，把表面貌似是 $O(k<em>n^2 ) 的复杂度降低到 O(k</em>n)$</li>
</ul>
</li>
</ul>
</li>
</ul>
<h4 id="MF到FM的转换理解"><a href="#MF到FM的转换理解" class="headerlink" title="MF到FM的转换理解"></a>MF到FM的转换理解</h4><ul>
<li>本质上，MF模型是FM模型的特例，<font color="blue">MF可以被认为是只有User ID 和Item ID这两个特征Fields的FM模型</font>，MF将这两类特征通过矩阵分解，来达到将这两类特征embedding化表达的目的</li>
<li>而FM则可以看作是MF模型的进一步拓展，除了User ID和Item ID这两类特征外，很多其它类型的特征，都可以进一步融入FM模型里，它将所有这些特征转化为embedding低维向量表达，并计算任意两个特征embedding的内积，就是特征组合的权重
</li>
</ul>
<h4 id="FFM-Field-aware-FM"><a href="#FFM-Field-aware-FM" class="headerlink" title="FFM(Field-aware FM)"></a>FFM(Field-aware FM)</h4><ul>
<li><p>核心思想</p>
<ul>
<li>FM模型的某个特征，在和任意其它特征域的特征进行组合求权重的时候，共享了同一个embedding特征向量</li>
<li>FFM模型是做得更细腻一些，在做特征组合的时候使用的embedding不同的特征向量。</li>
<li>这意味着，如果有F个特征域，那么每个特征由FM模型的一个k维特征embedding，拓展成了（F-1）个k维特征embedding</li>
<li>这个就是Field-aware的深层含义吧</li>
</ul>
</li>
<li><p>算法效率问题</p>
<ul>
<li>FM模型可以通过公式改写，把本来看着是n的平方的计算复杂度，降低到 $O(k*n)$ </li>
<li>而FFM无法做类似的改写，所以它的计算复杂度是 $O(k*n^2$ ) ，这明显在计算速度上也比FM模型慢得多</li>
<li>所以，无论是急剧膨胀的参数量，还是变慢的计算速度，无论从哪个角度看，相对FM模型，FFM模型是略显笨重的。</li>
<li>正因为FFM模型参数量太大，所以在训练FFM模型的时候，很容易过拟合，需要采取早停等防止过拟合的手段</li>
</ul>
</li>
<li><p>数学公式</p>
<ul>
<li>其中$f_i和f_j$分别代表第i个特征和第j个特征所属的field
</li>
</ul>
</li>
</ul>
<h4 id="DeepFM"><a href="#DeepFM" class="headerlink" title="DeepFM"></a>DeepFM</h4><ul>
<li><p>FM模型可以用神经网络进行表示</p>

<ul>
<li>这里需要<font color="red">理解Sparse Feature层和Embeddings层的表示，如何和原始的FM模型等价</font><ul>
<li>Sparse Feature层中维数数据可能不一样，有可能是多维的one-hot向量，比如分类的数据，如果是连续的数值型，那么就是本身<ul>
<li>即使各个field的维度是不一样的，但是它们embedding后长度均为k</li>
<li><font color="blue">也就是说one-hot只有一位为非0，其实就是通过矩阵相乘后就表示和原始的FM模型是等价了</font></li>
</ul>
</li>
<li>最终表现就是这个模型
</li>
</ul>
</li>
</ul>
</li>
<li><p>DeepFM的模型如下图<br><font color="red">共享整个embedding层，进行多层网络训练，提取高阶特征</font></p>
<ul>
<li>左边就是刚才将的FM模型的神经网络表示</li>
<li>右边的则为deep部分，<font color="blue">为全连接的网络，用于挖掘高阶的交叉特征</font>。整个模型共享embedding层，最后的结果就是把FM部分和DNN的部分做sigmoid<br>$Y=sigmoid(Y_{FM}+Y_{DNN})$
</li>
</ul>
</li>
<li><p>类比DeepFFM<br>类似于FFM对于FM模型来说，划分了field，对于不同的field内积时采用对应的隐向量。同样可以把DeepFM进行进化为DeepFFM，<font color="blue">即将每一个field embedding为m个维度为k的隐向量</font>（m为field的个数）</p>
</li>
</ul>
<h4 id="WDL"><a href="#WDL" class="headerlink" title="WDL"></a>WDL</h4><ul>
<li><p>Wide and Deep Learning<br>简单来说，<font color="blue">人脑就是一个不断记忆（memorization）并且归纳（generalization）的过程</font>，而这篇论文的思想，就是将<font color="red">宽线性模型（Wide Model，用于记忆，下图左侧）和深度神经网络模型（Deep Model，用于归纳，下图右侧）结合</font>，汲取各自优势形成了 Wide &amp; Deep 模型用于推荐排序</p>

</li>
<li><p>Wide Model<br>要理解的概念是 Memorization，主要是学习特征的共性或者说相关性，产生的推荐是和已经<font color="blue">有用户行为的物品直接相关的物品</font></p>
<ul>
<li>通过线性模型 + 特征交叉。所带来的Memorization以及记忆能力非常有效和可解释。但是Generalization（泛化能力）需要更多的人工特征工程</li>
<li>用的模型是 逻辑回归(logistic regression, LR)，LR 的优点就是简单(simple)、容易规模化(scalable)、可解释性强(interpretable)。LR 的特征往往是二值且稀疏的(binary and sparse)</li>
<li>总结一下，宽度模型的输入是用户安装应用(installation)和为用户展示（impression）的应用间的向量积（叉乘），模型通常训练 one-hot 编码后的二值特征<ul>
<li>缺点：这种操作不会归纳出训练集中未出现的特征对</li>
</ul>
</li>
</ul>
</li>
<li><p>Deep Model<br>要理解的概念是 Generalization，可以理解为<font color="blue">相关性的传递(transitivity)，会学习新的特征组合</font>，来提高推荐物品的多样性，或者说提供泛化能力(Generalization)</p>
<font color="purple">我的理解就是要用DL能够学习各种未出现的特征组合能力，特征模型的泛化能力</font><br>- DNN几乎不需要特征工程。通过对低纬度的dense embedding进行组合可以学习到更深层次的隐藏特征<br>  - 泛化往往是通过学习 <font color="blue">low-dimensional dense embeddings</font> 来探索过去从未或很少出现的新的特征组合来实现的<br>  - 缺点是有点over-generalize（过度泛化）<br>    - 当query-item矩阵是稀疏并且是high-rank的时候（比如user有特殊的爱好，或item比较小众），很难非常效率的学习出低维度的表示。这种情况下，大部分的query-item都没有什么关系。但是dense embedding会导致几乎所有的query-item预测值都是非0的，<font color="blue">这就导致了推荐过度泛化，会推荐一些不那么相关的物品</font><br>  - 相反，linear model却可以通过<font color="red">cross-product transformation</font>来记住这些<font color="blue">exception rules</font>，而且仅仅使用了非常少的参数<br>- <font color="blue">所以WDL结合LR，这点和 LR 正好互补，因为 LR 只能记住很少的特征组合，能够帮助识别Deep Model中《所有 query-item pair 非零的预测》情况</font>
</li>
<li><p>两者区别与互补</p>
<ul>
<li>Memorization趋向于更加保守，推荐用户之前有过行为的items(只认识出现过的)</li>
<li>generalization更加趋向于提高推荐系统的多样性（diversity）</li>
<li>所以WDL结合LR，这点和 LR 正好互补，因为 LR 只能记住很少的特征组合，能够帮助识别Deep Model中《所有 query-item pair 非零的预测》情况</li>
</ul>
</li>
<li><p>GP推荐系统的整体架构</p>
<ul>
<li>由两个部分组成,检索系统(或者说候选生成系统）和排序系统(排序网络)。</li>
<li>首先，用 检索(retrieval) 的方法对大数据集进行初步筛选，返回最匹配 query 的一部分物品列表，这里的检索通常会结合采用 机器学习模型(machine-learned models) 和 人工定义规则(human-defined rules) 两种方法。从大规模样本中召回最佳候选集之后</li>
<li>再使用 排序系统 对每个物品进行算分、排序，分数 P(y|x)。WDL 就是用在排序系统中</li>
</ul>
</li>
</ul>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


	
    
	
    
	
    
	
      	    

  

  
  
  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/03/15/rl/强化学习基础算法对比总结/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="雷哥">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/favicon.ico">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="雷哥的博客">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/03/15/rl/强化学习基础算法对比总结/" itemprop="url">强化学习基础算法对比总结</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-03-15T22:11:15+08:00">
                2019-03-15
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing">
                  <a href="/categories/机器学习/" itemprop="url" rel="index">
                    <span itemprop="name">机器学习</span>
                  </a>
                </span>

                
                
                  ， 
                
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing">
                  <a href="/categories/机器学习/强化学习/" itemprop="url" rel="index">
                    <span itemprop="name">强化学习</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p><a href="https://yuancl.github.io/categories/机器学习/强化学习/" target="_blank" rel="noopener">我的强化学习文章</a><br><a href="https://blog.csdn.net/Hansry/article/details/80808097" target="_blank" rel="noopener">网络:强化学习算法汇总1</a><br><a href="https://blog.csdn.net/hansry/article/details/80829127" target="_blank" rel="noopener">网络:强化学习算法汇总2</a></p>
<h4 id="不同角度分类"><a href="#不同角度分类" class="headerlink" title="不同角度分类"></a>不同角度分类</h4><ul>
<li>Model free/Model based<ul>
<li>Mode based:比如基于MDP(马尔科夫处理过程)，必须知道很多的环境状态，比如状态转移矩阵,reward等</li>
<li>Model free:不用知道环境的一些信息</li>
</ul>
</li>
<li>基于价值还是基于策略<ul>
<li>基于价值，比如V(s),Q(s,a)等，只能处理离散的行为，状态。得到最优值，对连续行为不好处理(Q-Learning,Sarsa,DQN及其变种)</li>
<li>基于策略，能够解决连续行为状态的场景，比如对状态行为进行建模，能够输出该状态行为的价值数值，所以就可以根据所以行为价值值选择最优的进行迭代(Actor-critic,A3C,DDPG等)</li>
<li>只是基于价值的模型(Critic only)，只会对整个序列完成后才给reward，对中间好的action损失较多，而基于价值和策略的模型就不会(例如Actor-critic),从Loss函数就能看出来<img src="/2019/03/15/rl/强化学习基础算法对比总结/resources/7A5A633D6270A244F2F0BC809FF24466.jpg"></li>
</ul>
</li>
<li>是否使用函数近似<ul>
<li>使用类似神经网络模型逼近V(s),Q(s,a)的真实值，本质就是对参数的求解，一定程度上能够解决连续状态行为的问题</li>
</ul>
</li>
<li>迭代更新策略(MC,TD,DP)<ul>
<li>基于采样的MC,TD,区别是迭代关注到后面的几步问题,实用性讲大部分都是基于TD的</li>
<li>DP不基于采样，所以状态都需要探索</li>
</ul>
</li>
<li>一套架构与否(行为策略和目的策略是否一致)<ul>
<li>行为策略和目的策略分开，或两套深度学习模型，典型的如Actor-critic </li>
</ul>
</li>
</ul>
<h4 id="Q-Learning"><a href="#Q-Learning" class="headerlink" title="Q-Learning"></a>Q-Learning</h4><ul>
<li><p>所属范畴<br>Model free/基于价值/TD/Off-Policy  </p>
</li>
<li><p>Q-Table(状态-行为表)<br>会有一个状态-行为表，来存储对应的价值，使用的时候只需要查表</p>
<img src="/2019/03/15/rl/强化学习基础算法对比总结/resources/FA2597ED524C0B0B01F2501C2CFA8C7A.jpg">
</li>
<li><p>更新Q-Table</p>
<ul>
<li>注意这里是选择s2状态下的最大行为值max $Q(s_2,a)$<img src="/2019/03/15/rl/强化学习基础算法对比总结/resources/69AF8FAD960EF5E9B78057E0E9ECF094.jpg">
</li>
</ul>
</li>
<li><p>算法伪代码</p>
<img src="/2019/03/15/rl/强化学习基础算法对比总结/resources/FF39F31C3A0DBB2EE7363ECFDD4A778D.jpg">
</li>
</ul>
<h4 id="Sarsa"><a href="#Sarsa" class="headerlink" title="Sarsa"></a>Sarsa</h4><ul>
<li>所属范畴<br>Model free/基于价值/TD and MC(Sarsa($\lambda$))/On-policy</li>
<li><p>和QLearning区别<br>Q-learning 在从状态s−&gt;s′的时候，考虑到的为 max Q(s′,a′), 在s′状态中选取 a′时，永远考虑的是最大。而对于Sarsa 而言，在从s′状态中选取 a′时，会采取与从s选取a 的策略一样，即采用 greedy 或者 ϵ−greedy</p>
<img src="/2019/03/15/rl/强化学习基础算法对比总结/resources/0222EC07D3FE2473155650099A69B238.jpg">
<img src="/2019/03/15/rl/强化学习基础算法对比总结/resources/D42F10E3F36A9105D5A55E2262C8E55B.jpg">
</li>
<li><p>算法伪代码</p>
<img src="/2019/03/15/rl/强化学习基础算法对比总结/resources/5504404F4F95CA41BCB2D2F638CA1333.jpg">
</li>
<li><p>Sarsa($\lambda$)</p>
<img src="/2019/03/15/rl/强化学习基础算法对比总结/resources/15578715F45608C37432FD7A4DA06887.jpg">
</li>
</ul>
<h4 id="DQN"><a href="#DQN" class="headerlink" title="DQN"></a>DQN</h4><ul>
<li><p>所属范畴<br>Model free/价值近似函数/TD</p>
</li>
<li><p>和QLearning比较<br>在Q-Learning中，我们提到了用Q表来存储当前状态s1下采取的动作action的值（value，在Q表中也称为Q值）。但是在实际过程中，一个状态s1到下一状态s2，这里的s2可能有很多不同的情况，这将会导致Q表存储的值会很多，不仅占内存，且在搜索的时候也是十分耗时的</p>
<ul>
<li>用神经网络来替代行为策略和目的策略<ul>
<li>输入为状态s和动作a，得到所有的动作值（Q值）</li>
<li>只输入状态值，然后输出所有的动作值<img src="/2019/03/15/rl/强化学习基础算法对比总结/resources/458CEACC21DCDCA5B1DBE0672EDBE177.jpg">
</li>
</ul>
</li>
</ul>
</li>
<li><p>伪代码</p>
<img src="/2019/03/15/rl/强化学习基础算法对比总结/resources/B8A8E886CEF92ACAB6702E24C4E4FFA0.jpg">
</li>
<li><p>变种Double DQN， Dueling DQN等</p>
<ul>
<li>DDQN<br>使用借鉴的思路，使用两个架构相同的近似价值函数<ul>
<li>其中一个用来根据策略生成交互行为并随 时频繁参数 (θ)</li>
<li>另一个则用来生成目标价值</li>
</ul>
</li>
</ul>
</li>
</ul>
<h4 id="Policy-Gradients"><a href="#Policy-Gradients" class="headerlink" title="Policy Gradients"></a>Policy Gradients</h4><ul>
<li>可以解决连续行为空间的情况</li>
<li>强化学习是一个通过奖惩来学习正确行为的机制，有学习奖惩值，根据自己认为的高价值选择行为的，如Q Learning、Deep Q Network 等。也有不通过分析奖励值，直接输出行为的方法，如Policy Gradient。Policy Gradient 直接输出动作的最大好处就是，能够在一个连续区间内挑选动作，而基于值的，往往是在所有动作中计算值，然后选择值最高的那个行为</li>
</ul>
<h4 id="Actor-Critic"><a href="#Actor-Critic" class="headerlink" title="Actor-Critic"></a>Actor-Critic</h4><ul>
<li><p>所属范畴<br>Model free/(基于策略 and 价值/策略近似函数)/TD</p>
</li>
<li><p>Actor Critic 为类似于Policy Gradient 和 Q-Learning 等以值为基础的算法的组合</p>
</li>
<li>Actor Critic 结合了 Policy Gradient（Actor）和 Function Approximation Critic）。Actor 基于概率选择行为，Critic 基于 Actor 的行为评判行为的得分，Actor 根据 Critic 的评分修改选择行为</li>
<li>逻辑<ul>
<li>其中Actor 类似于Policy Gradient，以状态s为输入，神经网络输出动作actions，并从在这些连续动作中按照一定的概率选取合适的动作action。 </li>
<li>Critic 类似于 Q-Learning 等以值为基础的算法，由于在Actor模块中选择了合适的动作action，通过与环境交互可得到新的状态s_, 奖励r，将状态 s_作为神经网络的输入，得到v_，而原来的状态s通过神经网络输出后得到v。 <img src="/2019/03/15/rl/强化学习基础算法对比总结/resources/330CF01329E0F79CDFBF7B3AFABE1701.jpg">
<img src="/2019/03/15/rl/强化学习基础算法对比总结/resources/873B2AE82C380A0DF20A408BAB193BE0.jpg">
<img src="/2019/03/15/rl/强化学习基础算法对比总结/resources/FCB9ECAB27436A64F27F0C3564176EDC.jpg">
</li>
</ul>
</li>
</ul>
<h4 id="A3C"><a href="#A3C" class="headerlink" title="A3C"></a>A3C</h4><ul>
<li>所属范畴<br>Model free/(基于策略 and 价值/策略近似函数)/TD</li>
<li>A3C 其实采用了Actor-Critic 的形式，但是引入了并行计算的概念。为了训练一对Actor 和 Critic，我们将Actor 和 Critic 复制成多份，然后放在不同的核中进行训练。其中需要声明一个主要的Actor-Critic (global)，不断从多个副本中更新的参数进行学习，获得新的参数，同时副本中的参数也不断从 Actor-Critic (global) 中获得并更新。</li>
<li>A3C 是Google DeepMind 提出的一种解决 Actor Critic 不收敛问题的算法。A3C会创建多个并行的环境，让多个拥有副结构的 agent 同时在这些并行环境上更新主结构中的参数。并行中的 agent 们互不干扰，而主结构的参数更新受到副结构提交更新的不连续性干扰，所以更新的相关性被降低，收敛性提高<img src="/2019/03/15/rl/强化学习基础算法对比总结/resources/956A445EB3C04AB5746C141CC6B281B6.jpg">
</li>
</ul>
<h4 id="DDPG-Deep-Deterministic-Policy-Gradient"><a href="#DDPG-Deep-Deterministic-Policy-Gradient" class="headerlink" title="DDPG(Deep Deterministic Policy Gradient)"></a>DDPG(Deep Deterministic Policy Gradient)</h4><ul>
<li>所属范畴<br>Model free/(基于策略 and 价值/策略近似函数)/TD</li>
<li>DDPG算法能较为稳定地解决连续行为空间下强化学习问题</li>
<li>DDPG用到的神经网络是怎么样的？它其实有点类似于Actor-Critic，也需要有基于策略Policy 的神经网络 和 基于价值 Value 的神经网络，但是为了体现DQN的思想，每种神经网络我们都需要再细分成俩个。Policy Gradient 这边有估计网络和现实网络，估计网络用来输出实时的动作，而现实网络则是用来更新价值网络系统的。再看看价值系统这边，我们也有现实网络和估计网络，他们都在输出这个状态的价值，而输入端却有不同，状态现实网络这边会拿着当时actor施加的动作当做输入。在实际运用中，DDPG的这种做法的确带来了更有效的学习过程<img src="/2019/03/15/rl/强化学习基础算法对比总结/resources/61940048D6BE768A829798B0ACDD87BF.jpg"></li>
</ul>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


	
    
	
      	    

  

  
  
  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/02/28/rs/高级推荐模型之二：协同矩阵分解/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="雷哥">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/favicon.ico">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="雷哥的博客">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/02/28/rs/高级推荐模型之二：协同矩阵分解/" itemprop="url">高级推荐模型之二：协同矩阵分解</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-02-28T07:20:21+08:00">
                2019-02-28
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing">
                  <a href="/categories/推荐系统/" itemprop="url" rel="index">
                    <span itemprop="name">推荐系统</span>
                  </a>
                </span>

                
                
                  ， 
                
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing">
                  <a href="/categories/推荐系统/推荐模型简介/" itemprop="url" rel="index">
                    <span itemprop="name">推荐模型简介</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h4 id="为什么需要协同矩阵分解"><a href="#为什么需要协同矩阵分解" class="headerlink" title="为什么需要协同矩阵分解"></a>为什么需要协同矩阵分解</h4><p>矩阵分解的核心就是通过矩阵，这个二维的数据结构，来对用户和物品的交互信息进行建模（如何融入更多信息）</p>
<ul>
<li>因为其二维的属性，矩阵往往只能对用户的某一种交互信息直接进行建模，这就带来很大的局限性</li>
<li>思路一，就是通过建立显式变量和隐变量之间的回归关系，从而让矩阵分解的核心结构可以获得更多信息的帮助。</li>
<li>思路二，则是采用分解机这样的集大成模型，从而把所有的特性，都融入到一个统一的模型中去。</li>
<li>思路三，就是我们这周已经讲到的，利用张量，把二维的信息扩展到 N 维进行建模</li>
</ul>
<h4 id="如何组织更多的二元关系"><a href="#如何组织更多的二元关系" class="headerlink" title="如何组织更多的二元关系"></a>如何组织更多的二元关系</h4><p>除了用户和物品这样很明显的二元关系以外，还有其他也很明显的二元关系，如何把这些二元关系有效地组织起来，就变成了一个有挑战的任务</p>
<ul>
<li>在前面的思路里面可以看到，我们似乎需要选择一个主要的关系来作为这个模型的基础框架，<font color="blue">然后把其他的信息作为补充</font>。在这样两类关系中，选择哪一个作为主要关系，哪一个作为补充关系，就显得有一点困难了</li>
<li>这也就让研究人员想出了协同矩阵分解的思路</li>
</ul>
<h4 id="协同矩阵分解的基本思路"><a href="#协同矩阵分解的基本思路" class="headerlink" title="协同矩阵分解的基本思路"></a>协同矩阵分解的基本思路</h4><ul>
<li>协同矩阵分解的基本思路其实非常直观，那就是有多少种二元关系，就用多少个矩阵分解去建模这些关系</li>
<li><p>如果协同(如果让这多个矩阵产生关系?)</p>
<ul>
<li>理论上基于矩阵分解得到的隐变量，相互是独立的，没有关系的</li>
<li>我们必须有其他的假设。这里的其他假设就是，两组不同的用户隐变量其实是一样的。也就是说，我们假设，或者认定，用户隐变量在用户与用户的关系中，以及在用户与物品的关系中，<font color="blue">是同一组用户隐变量在起作用</font><ul>
<li>说得直白一些，我们认定从两个矩阵分解出来的两组来自同一个因素（这里是用户）的<font color="blue">隐变量是完全一样的</font>。用更加学术的语言来说，这就是将两组矩阵分别投影到了相同的用户空间和物品空间</li>
</ul>
</li>
</ul>
</li>
<li><p>优点<br>我们使用“相同隐变量”这样的假设，可以把这些关系都串联起来，然后减少了总的变量数目，同时也让各种关系互相影响</p>
</li>
<li>缺点<ul>
<li>使用同样的一组隐变量去表达所有的同类关系，这样的假设存在一定的局限性，比较难找到</li>
<li>不同关系的数据量会有很大的差距。比如，用户和物品关系的数据总量可能要比用户与用户的多。所以，由于用户和物品关系的数据多，两个矩阵分解用的同一组用户隐变量，很可能会更多地解释用户和物品的部分，从而造成了学到的隐变量未必能够真正表达所有的关系</li>
</ul>
</li>
</ul>
<h4 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h4><p>从概念上来看，协同矩阵分解和张量分解之间有怎样的关系？是不是所有的张量分解都可以化为多个协同矩阵分解呢</p>
<ul>
<li>我的理解是ok的</li>
</ul>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


	
    
	
      	    

  

  
  
  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/02/27/rs/高级推荐模型之一：张量分解模型/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="雷哥">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/favicon.ico">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="雷哥的博客">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/02/27/rs/高级推荐模型之一：张量分解模型/" itemprop="url">高级推荐模型之一：张量分解模型</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-02-27T08:29:20+08:00">
                2019-02-27
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing">
                  <a href="/categories/推荐系统/" itemprop="url" rel="index">
                    <span itemprop="name">推荐系统</span>
                  </a>
                </span>

                
                
                  ， 
                
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing">
                  <a href="/categories/推荐系统/推荐模型简介/" itemprop="url" rel="index">
                    <span itemprop="name">推荐模型简介</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h4 id="为什么需要张量"><a href="#为什么需要张量" class="headerlink" title="为什么需要张量"></a>为什么需要张量</h4><ul>
<li>矩阵分析的核心思想<ul>
<li>用矩阵这种数据结构来表达用户和物品的相互关系<ul>
<li>这里，我们一般谈论的都是一些最简单的关系，例如评分、点击、购买等（本文我们依然只是讨论评分）</li>
</ul>
</li>
<li><font color="red">在这种二元的模式下，矩阵就是最好的表达用户和物品之间关系的数据结构</font></li>
</ul>
</li>
<li>如何表示更多信息(上下文)<ul>
<li>背景<br>在真实的场景中，用户和物品的关系以及产生这种关系的周围环境是复杂的。一个矩阵并不能完全描述所有的变量。<ul>
<li>例如，用户对于某个物品的评分是发生在某个地点、某个时间段内的。这种所谓的“上下文关系”（Context）往往会对评分产生很大影响。遗憾的是，<font color="blue">一个矩阵无法捕捉这样的上下文关系</font></li>
</ul>
</li>
<li>基于回归的矩阵分解和分解机方法解决<br>我们之前讨论过的“基于回归的矩阵分解”和“分解机”，本质上都是在某种程度上绕开这个问题<ul>
<li>采用的方法就是，<font color="blue">依然用矩阵来表达二元关系，但是把其他信息放进隐变量中</font>，或者是采用基于信息的推荐系统的思路来得到相关信息的建模</li>
</ul>
</li>
</ul>
</li>
</ul>
<p>除了这种思路，还有没有别的方法，<font color="red">可以把上下文关系融入到对用户和物品的建模中去呢</font></p>
<ul>
<li>张量<br>从本质上来说，张量就是矩阵的推广。我们可以这么理解:<ul>
<li>矩阵是对二维关系建模的一种工具；在二维关系中，用户和物品的评分是唯一能够被建模的变量；</li>
<li>而张量，就是对 N维关系的一种建模。而到了 N 维关系中，理论上，我们可以对任意多种上下文关系进行建<ul>
<li>比如，我们刚才提到的时间，就可以组成一个三维的张量，分别为用户、物品和时间。然后，在这个三维的张量中，每一个单元代表着某一个用户对于某一个物品在某一个时间段的评分</li>
</ul>
</li>
</ul>
</li>
</ul>
<h4 id="基于张量分解的推荐模型"><a href="#基于张量分解的推荐模型" class="headerlink" title="基于张量分解的推荐模型"></a>基于张量分解的推荐模型</h4><p>分解多维向量，我理解和之前学习的分解矩阵思想类似：分解为多个矩阵的表示方式</p>
<ul>
<li><p>CP 分解（CANDECOMP/PARAFAC）</p>
<ul>
<li>CP 分解是把一个三维张量分解为三个矩阵。具体来说，比如我们的三维张量是 N 维用户乘以 M 维的物品乘以 R 维的时间段。那么，分解出来的三个矩阵就分别为 N 维乘以 K 维的用户矩阵，M 维乘以 K 维的物品矩阵，以及 R 维乘以 K 维的时间矩阵。</li>
<li>这三个矩阵中的每一个向量都代表某一个用户、某一个物品和某一个时间段。K 在这里是一个参数，类似于矩阵分解中的隐变量的维度，我们也就可以把这个 K 理解成为隐变量的维度</li>
<li>那么在原始的三维张量中，<font color="blue">某一个元素就是这三个矩阵的某三个向量对应元素乘积相加的结果</font></li>
<li>CP 分解的一大好处就是，<font color="blue">分解出来的三个矩阵的隐变量维度是一样的</font>，这也就减少了需要调整的参数的个数</li>
</ul>
</li>
<li><p>HOSVD 分解（High Order Singular Value decomposition）</p>
<ul>
<li>含义<ul>
<li>这种分解和 CP 分解最大的不同就是分解出来的三个矩阵的维度不再一样<ul>
<li>也就是说，在我们之前的例子中，用户矩阵的维度可以是 N 乘以 A，物品矩阵的维度是 M 乘以 B，时间段矩阵的维度是 R 乘以 C。当然，这样就无法还原之前的 N 乘以 M 乘以 R 的三维张量了</li>
<li>于是在技术上，还需要乘以一个 A 乘以 B 乘以 C 的小张量才能对原始数据进行复原。</li>
</ul>
</li>
<li>所以，通俗地讲，HOSVD 分解就是把一个三维的张量，分解成为三个矩阵和一个更小的张量的乘积</li>
</ul>
</li>
<li>优缺点<ul>
<li>好处自然就是给不同的数据以不同的自由度，因为不再限制用户、物品和时间段都必须有一样的维度。</li>
<li>缺点是有了更多的“超参数”需要调整</li>
</ul>
</li>
<li>损失函数<br>在一般的分解过程中，我们可以定义“<strong>平方差</strong>”（Squared Loss），也就是原始数值和预测数值之间的平方差来作为损失函数</li>
</ul>
</li>
</ul>
<h4 id="求解张量分解"><a href="#求解张量分解" class="headerlink" title="求解张量分解"></a>求解张量分解</h4><ul>
<li>随机梯度下降法（SGD, Stochastic Gradient Descent），也就是把张量的分解问题看作是一个一般的优化问题</li>
<li>另外一种方法，也是在矩阵分解中可以使用的，叫作 ALS（Alternating Least Square）方法<ul>
<li>这种方法则是在优化每一轮的时候，按住所有其他的矩阵变量不动，单独优化一个变量</li>
</ul>
</li>
</ul>
<h4 id="问题：从概念上来看，用张量分解对上下文信息进行建模的最大问题是什么"><a href="#问题：从概念上来看，用张量分解对上下文信息进行建模的最大问题是什么" class="headerlink" title="问题：从概念上来看，用张量分解对上下文信息进行建模的最大问题是什么"></a>问题：从概念上来看，用张量分解对上下文信息进行建模的最大问题是什么</h4><ul>
<li>张量的稀疏性</li>
<li>模型更负责，不易求解</li>
</ul>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


	
    
  </section>

  
  <nav class="pagination">
    <span class="page-number current">1</span><a class="page-number" href="/page/2/">2</a><span class="space">&hellip;</span><a class="page-number" href="/page/8/">8</a><a class="extend next" rel="next" href="/page/2/"><i class="fa fa-angle-right"></i></a>
  </nav>



          </div>
          


          

        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      

      <section class="site-overview sidebar-panel sidebar-panel-active">
        <div class="site-author motion-element" itemprop="author" itemscope="" itemtype="http://schema.org/Person">
          <img class="site-author-image" itemprop="image" src="/images/favicon.ico" alt="雷哥">
          <p class="site-author-name" itemprop="name">雷哥</p>
           
              <p class="site-description motion-element" itemprop="description">不积跬步无以至千里</p>
          
        </div>
        <nav class="site-state motion-element">

          
            <div class="site-state-item site-state-posts">
              <a href="/archives">
                <span class="site-state-item-count">72</span>
                <span class="site-state-item-name">日志</span>
              </a>
            </div>
          

          
            
            
            <div class="site-state-item site-state-categories">
              <a href="/categories/index.html">
                <span class="site-state-item-count">18</span>
                <span class="site-state-item-name">分类</span>
              </a>
            </div>
          

          
            
            
            <div class="site-state-item site-state-tags">
              <a href="/tags/index.html">
                <span class="site-state-item-count">16</span>
                <span class="site-state-item-name">标签</span>
              </a>
            </div>
          

        </nav>

        

        <div class="links-of-author motion-element">
          
            
              <span class="links-of-author-item">
                <a href="https://github.com/yuancl" target="_blank" title="GitHub">
                  
                    <i class="fa fa-fw fa-github"></i>
                  
                    
                      GitHub
                    
                </a>
              </span>
            
          
        </div>

        
        

        
        

        


      </section>

      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2019</span>
  <span class="with-love">
    <i class="fa fa-雷哥"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">雷哥</span>
</div>


<div class="powered-by">
  由 <a class="theme-link" href="https://hexo.io">Hexo</a> 强力驱动
</div>

<div class="theme-info">
  主题 -
  <a class="theme-link" href="https://github.com/iissnan/hexo-theme-next">
    NexT.Gemini
  </a>
</div>


        

        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>

  
  <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>

  
  <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.2"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.2"></script>



  
  


  <script type="text/javascript" src="/js/src/affix.js?v=5.1.2"></script>

  <script type="text/javascript" src="/js/src/schemes/pisces.js?v=5.1.2"></script>



  
    <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.2"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.2"></script>

  

  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.2"></script>



  


  




	





  





  






  





  

  

  

  
  
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        tex2jax: {
          inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
          processEscapes: true,
          skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
        }
      });
    </script>

    <script type="text/x-mathjax-config">
      MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for (i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
        }
      });
    </script>
    <script type="text/javascript" src="//cdn.bootcss.com/mathjax/2.7.1/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
  


  

  

</body>
</html>
