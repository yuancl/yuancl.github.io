<!DOCTYPE html>



  


<html class="theme-next gemini use-motion" lang="zh-Hans">
<head><meta name="generator" content="Hexo 3.8.0">
  <meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform">
<meta http-equiv="Cache-Control" content="no-siteapp">















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css">




  
  
  
  

  
    
    
  

  

  

  

  

  
    
    
    <link href="//fonts.googleapis.com/css?family=Lato:300,300italic,400,400italic,700,700italic&subset=latin,latin-ext" rel="stylesheet" type="text/css">
  






<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css">

<link href="/css/main.css?v=5.1.2" rel="stylesheet" type="text/css">


  <meta name="keywords" content="机器学习,强化学习,">








  <link rel="shortcut icon" type="image/x-icon" href="/favicon.ico?v=5.1.2">






<meta name="description" content="Reforcement Learning 什么叫RL和监督学习的区别是，Agent会通过观察(Observation)当前环境(Environment),获得当前的State，接着Action后能够得到Environment的反馈：Reward，然后Agent根据Reward再调整做出正确的Action去改变Environment  Agent:学习主体，可以是一个NN或者其它，作用：Learns">
<meta name="keywords" content="机器学习,强化学习">
<meta property="og:type" content="article">
<meta property="og:title" content="强化学习(简介)">
<meta property="og:url" content="http://yoursite.com/2018/12/23/rl/强化学习(简介)/index.html">
<meta property="og:site_name" content="雷哥的博客">
<meta property="og:description" content="Reforcement Learning 什么叫RL和监督学习的区别是，Agent会通过观察(Observation)当前环境(Environment),获得当前的State，接着Action后能够得到Environment的反馈：Reward，然后Agent根据Reward再调整做出正确的Action去改变Environment  Agent:学习主体，可以是一个NN或者其它，作用：Learns">
<meta property="og:locale" content="zh-Hans">
<meta property="og:image" content="http://yoursite.com/2018/12/23/rl/强化学习(简介)/resources/089167ED63C58D955C18087D366BF2A3.jpg">
<meta property="og:image" content="http://yoursite.com/2018/12/23/rl/强化学习(简介)/resources/260B08ED8010A47991A9DF4BE29D1E57.jpg">
<meta property="og:image" content="http://yoursite.com/2018/12/23/rl/强化学习(简介)/resources/B620070EEBB401F2C731FCC8E23FAB60.jpg">
<meta property="og:image" content="http://yoursite.com/2018/12/23/rl/强化学习(简介)/resources/F64DEE320E6175A281141261369F122A.jpg">
<meta property="og:image" content="http://yoursite.com/2018/12/23/rl/强化学习(简介)/resources/813056D16FC4398AB40E7F56841C8828.jpg">
<meta property="og:image" content="http://yoursite.com/2018/12/23/rl/强化学习(简介)/resources/478F4C2660ABFC1B5E675896C8571F84.jpg">
<meta property="og:image" content="http://yoursite.com/2018/12/23/rl/强化学习(简介)/resources/E5859C0699A3CB2FB7D06715DEF7C293.jpg">
<meta property="og:image" content="http://yoursite.com/2018/12/23/rl/强化学习(简介)/resources/035061213843511C0A7561A1F0E06792.jpg">
<meta property="og:image" content="http://yoursite.com/2018/12/23/rl/强化学习(简介)/resources/FEB8FFD784F357B5CFE54CCD02E5A05B.jpg">
<meta property="og:image" content="http://yoursite.com/2018/12/23/rl/强化学习(简介)/resources/61A9812B02E141127554B513DA22F2CA.jpg">
<meta property="og:image" content="http://yoursite.com/2018/12/23/rl/强化学习(简介)/resources/84B70D51C472CE9220B50917CF343EBE.jpg">
<meta property="og:image" content="http://yoursite.com/2018/12/23/rl/强化学习(简介)/resources/314B5DFA5F6A0AEEACBE25BEEC618D05.jpg">
<meta property="og:image" content="http://yoursite.com/2018/12/23/rl/强化学习(简介)/resources/D113811A3EE6DF3759AC23138C68A4C6.jpg">
<meta property="og:image" content="http://yoursite.com/2018/12/23/rl/强化学习(简介)/resources/26D289911C892B3832B7E88BDA9E3848.jpg">
<meta property="og:image" content="http://yoursite.com/2018/12/23/rl/强化学习(简介)/resources/1060DC495D95BBDB0CD2FB19749CD14E.jpg">
<meta property="og:image" content="http://yoursite.com/2018/12/23/rl/强化学习(简介)/resources/EA44E3EFC2F7B6582C5207FB6461F7EE.jpg">
<meta property="og:image" content="http://yoursite.com/2018/12/23/rl/强化学习(简介)/resources/7BB0A900A5C3D4D5567050C7A7D0FA0A.jpg">
<meta property="og:image" content="http://yoursite.com/2018/12/23/rl/强化学习(简介)/resources/1FDE16A21B149590A05D2335FFC45D90.jpg">
<meta property="og:image" content="http://yoursite.com/2018/12/23/rl/强化学习(简介)/resources/ADBCCF56067A9D873705B18C483D8B4D.jpg">
<meta property="og:image" content="http://yoursite.com/2018/12/23/rl/强化学习(简介)/resources/57B1F1A69DD14E80166F5776FB4E9CF5.jpg">
<meta property="og:image" content="http://yoursite.com/2018/12/23/rl/强化学习(简介)/resources/DE2E7716C70854CC5CE59AC271378ED4.jpg">
<meta property="og:image" content="http://yoursite.com/2018/12/23/rl/强化学习(简介)/resources/FE61F494902468450399EBA1D4B37642.jpg">
<meta property="og:updated_time" content="2019-02-12T11:08:36.297Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="强化学习(简介)">
<meta name="twitter:description" content="Reforcement Learning 什么叫RL和监督学习的区别是，Agent会通过观察(Observation)当前环境(Environment),获得当前的State，接着Action后能够得到Environment的反馈：Reward，然后Agent根据Reward再调整做出正确的Action去改变Environment  Agent:学习主体，可以是一个NN或者其它，作用：Learns">
<meta name="twitter:image" content="http://yoursite.com/2018/12/23/rl/强化学习(简介)/resources/089167ED63C58D955C18087D366BF2A3.jpg">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Gemini',
    sidebar: {"position":"left","display":"post","offset":12,"offset_float":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: true,
    duoshuo: {
      userId: '0',
      author: '雷哥'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://yoursite.com/2018/12/23/rl/强化学习(简介)/">





  <title>强化学习(简介) | 雷哥的博客</title>
  














</head>

<body itemscope="" itemtype="http://schema.org/WebPage" lang="zh-Hans">

  
  
    
  

  <div class="container sidebar-position-left page-post-detail ">
    <div class="headband"></div>

    <header id="header" class="header" itemscope="" itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">雷哥的博客</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle"></p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br>
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br>
            
            分类
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br>
            
            归档
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br>
            
            标签
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/12/23/rl/强化学习(简介)/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="雷哥">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/favicon.ico">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="雷哥的博客">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">强化学习(简介)</h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-12-23T21:30:02+08:00">
                2018-12-23
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing">
                  <a href="/categories/机器学习/" itemprop="url" rel="index">
                    <span itemprop="name">机器学习</span>
                  </a>
                </span>

                
                
                  ， 
                
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing">
                  <a href="/categories/机器学习/强化学习/" itemprop="url" rel="index">
                    <span itemprop="name">强化学习</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        <h4 id="Reforcement-Learning"><a href="#Reforcement-Learning" class="headerlink" title="Reforcement Learning"></a>Reforcement Learning</h4><ul>
<li><p>什么叫RL<br>和监督学习的区别是，Agent会通过观察(Observation)当前环境(Environment),获得当前的State，接着Action后能够得到Environment的反馈：Reward，然后Agent根据Reward再调整做出正确的Action去改变Environment</p>
<ul>
<li>Agent:学习主体，可以是一个NN或者其它，作用：Learns to take actions maximizing expected reward</li>
<li>Environment:外部环境，比如下围棋就是对手，玩电玩的时候，就是主机</li>
<li>State：Agent通过观察获取到的当前环境的输入状态</li>
<li>Action：根据当前状态做出的动作，当然此动作会影响Environment，比如下围棋的时候会影响对手下一步落棋</li>
<li>Reward:做出action，当前Environment给予的评价<img src="/2018/12/23/rl/强化学习(简介)/resources/089167ED63C58D955C18087D366BF2A3.jpg">
<img src="/2018/12/23/rl/强化学习(简介)/resources/260B08ED8010A47991A9DF4BE29D1E57.jpg">
</li>
</ul>
</li>
<li><p>Look for a function</p>
<img src="/2018/12/23/rl/强化学习(简介)/resources/B620070EEBB401F2C731FCC8E23FAB60.jpg">
</li>
<li><p>举例</p>
<ul>
<li>state:输入为当前画面(像素值)</li>
<li>action:左移，右移或者开火</li>
<li>reward:Score<img src="/2018/12/23/rl/强化学习(简介)/resources/F64DEE320E6175A281141261369F122A.jpg">
</li>
</ul>
</li>
</ul>
<ul>
<li>outline<img src="/2018/12/23/rl/强化学习(简介)/resources/813056D16FC4398AB40E7F56841C8828.jpg">
</li>
</ul>
<h4 id="Policy-based-Approach-Learining-an-Actor"><a href="#Policy-based-Approach-Learining-an-Actor" class="headerlink" title="Policy-based Approach(Learining an Actor)"></a>Policy-based Approach(Learining an Actor)</h4><ul>
<li><p>总体分三步</p>
<img src="/2018/12/23/rl/强化学习(简介)/resources/478F4C2660ABFC1B5E675896C8571F84.jpg">
<ul>
<li><p>First step：</p>
<img src="/2018/12/23/rl/强化学习(简介)/resources/E5859C0699A3CB2FB7D06715DEF7C293.jpg">
</li>
<li><p>Second step：</p>
<img src="/2018/12/23/rl/强化学习(简介)/resources/035061213843511C0A7561A1F0E06792.jpg">
</li>
<li><p>Third step(pick the best function)：</p>
<img src="/2018/12/23/rl/强化学习(简介)/resources/FEB8FFD784F357B5CFE54CCD02E5A05B.jpg">
</li>
</ul>
</li>
<li><p>Policy Gradient作用<br>如果Actor,Env,Reward都看做是DNN，那么本质上就是一个NN网络，求极值就很容易。但实际上Env，Reward不是一个NN网络，所以就不能进行微分，不能求出极值，解决办法就是用policy gradient进行处理</p>
<img src="/2018/12/23/rl/强化学习(简介)/resources/61A9812B02E141127554B513DA22F2CA.jpg">
</li>
</ul>
<h4 id="Value-based-Approach-Learning-a-critic"><a href="#Value-based-Approach-Learning-a-critic" class="headerlink" title="Value-based Approach(Learning a critic)"></a>Value-based Approach(Learning a critic)</h4><ul>
<li>是评价一个agent(actor)的好坏，$V^{\pi}(s)$表示给定一个Agent(Actor:$\pi$)，并给定一个State:s，到最后游戏完成后，得到最后的reward expects的值<ul>
<li>比如下面坐标的图，有很多怪，到游戏结束期望分数就容易获得比较高的值，右边图就比较小(因为这个图看到到最后游戏结束，能杀的怪已经很少了)</li>
<li>同一个state，不同的actor，那么$V^{\pi}(s)$值也会不一样<img src="/2018/12/23/rl/强化学习(简介)/resources/84B70D51C472CE9220B50917CF343EBE.jpg">
</li>
</ul>
</li>
</ul>
<ul>
<li><p>How to estimate $V^{\pi}(s)$</p>
<ul>
<li><p>Monte-Carlo,观察到两个state,$S_a,S_b$，并且最后episode结束，Greed为$G_a,G_b$，这个时候，只需要让$V^{\pi}(s_a)\approx G_a,V^{\pi}(s_b)\approx G_b$</p>
<img src="/2018/12/23/rl/强化学习(简介)/resources/314B5DFA5F6A0AEEACBE25BEEC618D05.jpg">
</li>
<li><p>Temporal-difference,不会等到episode才开始计算(不用等到游戏结束就可以更新参数)，原理是$V^{\pi}(s_t),V^{\pi}(s_{t+1})$中间是相差的$r_t$,所以只需要$V^{\pi}(s_t)-V^{\pi}(s_{t+1})\approx r_t$</p>
<img src="/2018/12/23/rl/强化学习(简介)/resources/D113811A3EE6DF3759AC23138C68A4C6.jpg">
</li>
</ul>
</li>
<li><p>Q Learning</p>
<ul>
<li><p>Another Critic</p>
<ul>
<li>输入为state和action,可以对所有action做穷举（如果不能穷举，其实还有其他的方法的），看哪一个reward得分最高(得到Q function)<img src="/2018/12/23/rl/强化学习(简介)/resources/26D289911C892B3832B7E88BDA9E3848.jpg">
</li>
</ul>
</li>
<li><p>每一次都找最大的Qfunction数值的action a</p>
<img src="/2018/12/23/rl/强化学习(简介)/resources/1060DC495D95BBDB0CD2FB19749CD14E.jpg">
</li>
</ul>
</li>
</ul>
<h4 id="Actor-Critic"><a href="#Actor-Critic" class="headerlink" title="Actor+Critic"></a>Actor+Critic</h4><ul>
<li>核心原理：不会像Actor那样跟着环境去学习，因为环境变化是比较多的，所以Actor-Critic是跟着critic去学习<img src="/2018/12/23/rl/强化学习(简介)/resources/EA44E3EFC2F7B6582C5207FB6461F7EE.jpg">
<img src="/2018/12/23/rl/强化学习(简介)/resources/7BB0A900A5C3D4D5567050C7A7D0FA0A.jpg"></li>
<li>A3C<img src="/2018/12/23/rl/强化学习(简介)/resources/1FDE16A21B149590A05D2335FFC45D90.jpg">
</li>
</ul>
<h4 id="Inverse-Reforcement-learning"><a href="#Inverse-Reforcement-learning" class="headerlink" title="Inverse Reforcement learning"></a>Inverse Reforcement learning</h4><ul>
<li>背景：其实生活中的大多数场景，都不好找reward的，不像围棋或者是电玩，有很明确的规则.<ul>
<li>比如如果交通违规，如何处罚等。还比如说让机器人放盘子，之前并没有告诉摔坏盘子会扣分，机器人就不知道</li>
</ul>
</li>
<li>原来的方案：<img src="/2018/12/23/rl/强化学习(简介)/resources/ADBCCF56067A9D873705B18C483D8B4D.jpg"></li>
<li>Inverse Reforcement learning方案：<ul>
<li>正好相反，并不知道Reward Function，是通过学习学习到Reward Function后，然后使用它选择出最好的actor<img src="/2018/12/23/rl/强化学习(简介)/resources/57B1F1A69DD14E80166F5776FB4E9CF5.jpg"></li>
</ul>
</li>
<li><p>步骤：</p>
<ul>
<li>expert和IRL都会自己学习，获得最终Reward，我们假设专家的Reward总数比学习到的好</li>
<li>然后从中我们找到一个最好的Reward Function R</li>
<li>再通过R去得到Actor $\pi$</li>
<li>要注意下是，如果规则变化了，那么下面的循环圈需要不断的重新循环取学习<img src="/2018/12/23/rl/强化学习(简介)/resources/DE2E7716C70854CC5CE59AC271378ED4.jpg">
</li>
</ul>
</li>
<li><p>发现和GAN比较像</p>
<img src="/2018/12/23/rl/强化学习(简介)/resources/FE61F494902468450399EBA1D4B37642.jpg"></li>
</ul>

      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/机器学习/" rel="tag"># 机器学习</a>
          
            <a href="/tags/强化学习/" rel="tag"># 强化学习</a>
          
        </div>
      

      
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2018/12/22/finance/ROE(下)(正确地使用ROE来选股)/" rel="next" title="ROE(下)(正确地使用ROE来选股股)">
                <i class="fa fa-chevron-left"></i> ROE(下)(正确地使用ROE来选股股)
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/2019/01/05/nlp/Attention模型/" rel="prev" title="Attention模型">
                Attention模型 <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </div>
  
  
  
  </article>



    <div class="post-spread">
      
    </div>
  </div>


          </div>
          


          
  <div class="comments" id="comments">
    
  </div>


        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">
            文章目录
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview">
            站点概览
          </li>
        </ul>
      

      <section class="site-overview sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope="" itemtype="http://schema.org/Person">
          <img class="site-author-image" itemprop="image" src="/images/favicon.ico" alt="雷哥">
          <p class="site-author-name" itemprop="name">雷哥</p>
           
              <p class="site-description motion-element" itemprop="description">不积跬步无以至千里</p>
          
        </div>
        <nav class="site-state motion-element">

          
            <div class="site-state-item site-state-posts">
              <a href="/archives">
                <span class="site-state-item-count">77</span>
                <span class="site-state-item-name">日志</span>
              </a>
            </div>
          

          
            
            
            <div class="site-state-item site-state-categories">
              <a href="/categories/index.html">
                <span class="site-state-item-count">23</span>
                <span class="site-state-item-name">分类</span>
              </a>
            </div>
          

          
            
            
            <div class="site-state-item site-state-tags">
              <a href="/tags/index.html">
                <span class="site-state-item-count">21</span>
                <span class="site-state-item-name">标签</span>
              </a>
            </div>
          

        </nav>

        

        <div class="links-of-author motion-element">
          
            
              <span class="links-of-author-item">
                <a href="https://github.com/yuancl" target="_blank" title="GitHub">
                  
                    <i class="fa fa-fw fa-github"></i>
                  
                    
                      GitHub
                    
                </a>
              </span>
            
          
        </div>

        
        

        
        

        


      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-4"><a class="nav-link" href="#Reforcement-Learning"><span class="nav-number">1.</span> <span class="nav-text">Reforcement Learning</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Policy-based-Approach-Learining-an-Actor"><span class="nav-number">2.</span> <span class="nav-text">Policy-based Approach(Learining an Actor)</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Value-based-Approach-Learning-a-critic"><span class="nav-number">3.</span> <span class="nav-text">Value-based Approach(Learning a critic)</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Actor-Critic"><span class="nav-number">4.</span> <span class="nav-text">Actor+Critic</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Inverse-Reforcement-learning"><span class="nav-number">5.</span> <span class="nav-text">Inverse Reforcement learning</span></a></li></ol></div>
            

          </div>
        </section>
      <!--/noindex-->
      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2019</span>
  <span class="with-love">
    <i class="fa fa-雷哥"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">雷哥</span>
</div>


<div class="powered-by">
  由 <a class="theme-link" href="https://hexo.io">Hexo</a> 强力驱动
</div>

<div class="theme-info">
  主题 -
  <a class="theme-link" href="https://github.com/iissnan/hexo-theme-next">
    NexT.Gemini
  </a>
</div>


        

        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>

  
  <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>

  
  <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.2"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.2"></script>



  
  


  <script type="text/javascript" src="/js/src/affix.js?v=5.1.2"></script>

  <script type="text/javascript" src="/js/src/schemes/pisces.js?v=5.1.2"></script>



  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.2"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.2"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.2"></script>



  


  




	





  





  






  





  

  

  

  
  
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        tex2jax: {
          inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
          processEscapes: true,
          skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
        }
      });
    </script>

    <script type="text/x-mathjax-config">
      MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for (i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
        }
      });
    </script>
    <script type="text/javascript" src="//cdn.bootcss.com/mathjax/2.7.1/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
  


  

  

</body>
</html>
