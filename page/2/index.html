<!DOCTYPE html>



  


<html class="theme-next gemini use-motion" lang="zh-Hans">
<head><meta name="generator" content="Hexo 3.8.0">
  <meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform">
<meta http-equiv="Cache-Control" content="no-siteapp">















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css">




  
  
  
  

  
    
    
  

  

  

  

  

  
    
    
    <link href="//fonts.googleapis.com/css?family=Lato:300,300italic,400,400italic,700,700italic&subset=latin,latin-ext" rel="stylesheet" type="text/css">
  






<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css">

<link href="/css/main.css?v=5.1.2" rel="stylesheet" type="text/css">


  <meta name="keywords" content="Hexo, NexT">








  <link rel="shortcut icon" type="image/x-icon" href="/favicon.ico?v=5.1.2">






<meta name="description" content="不积跬步无以至千里">
<meta property="og:type" content="website">
<meta property="og:title" content="雷哥的博客">
<meta property="og:url" content="http://yoursite.com/page/2/index.html">
<meta property="og:site_name" content="雷哥的博客">
<meta property="og:description" content="不积跬步无以至千里">
<meta property="og:locale" content="zh-Hans">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="雷哥的博客">
<meta name="twitter:description" content="不积跬步无以至千里">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Gemini',
    sidebar: {"position":"left","display":"post","offset":12,"offset_float":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: true,
    duoshuo: {
      userId: '0',
      author: '雷哥'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://yoursite.com/page/2/">





  <title>雷哥的博客</title>
  














</head>

<body itemscope="" itemtype="http://schema.org/WebPage" lang="zh-Hans">

  
  
    
  

  <div class="container sidebar-position-left 
   page-home 
 ">
    <div class="headband"></div>

    <header id="header" class="header" itemscope="" itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">雷哥的博客</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle"></p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br>
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br>
            
            分类
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br>
            
            归档
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br>
            
            标签
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            
  <section id="posts" class="posts-expand">
    
	
    
	
    
	
      	    

  

  
  
  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/03/15/rl/强化学习基础算法对比总结/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="雷哥">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/favicon.ico">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="雷哥的博客">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/03/15/rl/强化学习基础算法对比总结/" itemprop="url">强化学习基础算法对比总结</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-03-15T22:11:15+08:00">
                2019-03-15
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing">
                  <a href="/categories/机器学习/" itemprop="url" rel="index">
                    <span itemprop="name">机器学习</span>
                  </a>
                </span>

                
                
                  ， 
                
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing">
                  <a href="/categories/机器学习/强化学习/" itemprop="url" rel="index">
                    <span itemprop="name">强化学习</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p><a href="https://yuancl.github.io/categories/机器学习/强化学习/" target="_blank" rel="noopener">我的强化学习文章</a><br><a href="https://blog.csdn.net/Hansry/article/details/80808097" target="_blank" rel="noopener">网络:强化学习算法汇总1</a><br><a href="https://blog.csdn.net/hansry/article/details/80829127" target="_blank" rel="noopener">网络:强化学习算法汇总2</a></p>
<h4 id="不同角度分类"><a href="#不同角度分类" class="headerlink" title="不同角度分类"></a>不同角度分类</h4><ul>
<li>Model free/Model based<ul>
<li>Mode based:比如基于MDP(马尔科夫处理过程)，必须知道很多的环境状态，比如状态转移矩阵,reward等</li>
<li>Model free:不用知道环境的一些信息</li>
</ul>
</li>
<li>基于价值还是基于策略<ul>
<li>基于价值，比如V(s),Q(s,a)等，只能处理离散的行为，状态。得到最优值，对连续行为不好处理(Q-Learning,Sarsa,DQN及其变种)</li>
<li>基于策略，能够解决连续行为状态的场景，比如对状态行为进行建模，能够输出该状态行为的价值数值，所以就可以根据所以行为价值值选择最优的进行迭代(Actor-critic,A3C,DDPG等)</li>
<li>只是基于价值的模型(Critic only)，只会对整个序列完成后才给reward，对中间好的action损失较多，而基于价值和策略的模型就不会(例如Actor-critic),从Loss函数就能看出来<img src="/2019/03/15/rl/强化学习基础算法对比总结/resources/7A5A633D6270A244F2F0BC809FF24466.jpg"></li>
</ul>
</li>
<li>是否使用函数近似<ul>
<li>使用类似神经网络模型逼近V(s),Q(s,a)的真实值，本质就是对参数的求解，一定程度上能够解决连续状态行为的问题</li>
</ul>
</li>
<li>迭代更新策略(MC,TD,DP)<ul>
<li>基于采样的MC,TD,区别是迭代关注到后面的几步问题,实用性讲大部分都是基于TD的</li>
<li>DP不基于采样，所以状态都需要探索</li>
</ul>
</li>
<li>一套架构与否(行为策略和目的策略是否一致)<ul>
<li>行为策略和目的策略分开，或两套深度学习模型，典型的如Actor-critic </li>
</ul>
</li>
</ul>
<h4 id="Q-Learning"><a href="#Q-Learning" class="headerlink" title="Q-Learning"></a>Q-Learning</h4><ul>
<li><p>所属范畴<br>Model free/基于价值/TD/Off-Policy  </p>
</li>
<li><p>Q-Table(状态-行为表)<br>会有一个状态-行为表，来存储对应的价值，使用的时候只需要查表</p>
<img src="/2019/03/15/rl/强化学习基础算法对比总结/resources/FA2597ED524C0B0B01F2501C2CFA8C7A.jpg">
</li>
<li><p>更新Q-Table</p>
<ul>
<li>注意这里是选择s2状态下的最大行为值max $Q(s_2,a)$<img src="/2019/03/15/rl/强化学习基础算法对比总结/resources/69AF8FAD960EF5E9B78057E0E9ECF094.jpg">
</li>
</ul>
</li>
<li><p>算法伪代码</p>
<img src="/2019/03/15/rl/强化学习基础算法对比总结/resources/FF39F31C3A0DBB2EE7363ECFDD4A778D.jpg">
</li>
</ul>
<h4 id="Sarsa"><a href="#Sarsa" class="headerlink" title="Sarsa"></a>Sarsa</h4><ul>
<li>所属范畴<br>Model free/基于价值/TD and MC(Sarsa($\lambda$))/On-policy</li>
<li><p>和QLearning区别<br>Q-learning 在从状态s−&gt;s′的时候，考虑到的为 max Q(s′,a′), 在s′状态中选取 a′时，永远考虑的是最大。而对于Sarsa 而言，在从s′状态中选取 a′时，会采取与从s选取a 的策略一样，即采用 greedy 或者 ϵ−greedy</p>
<img src="/2019/03/15/rl/强化学习基础算法对比总结/resources/0222EC07D3FE2473155650099A69B238.jpg">
<img src="/2019/03/15/rl/强化学习基础算法对比总结/resources/D42F10E3F36A9105D5A55E2262C8E55B.jpg">
</li>
<li><p>算法伪代码</p>
<img src="/2019/03/15/rl/强化学习基础算法对比总结/resources/5504404F4F95CA41BCB2D2F638CA1333.jpg">
</li>
<li><p>Sarsa($\lambda$)</p>
<img src="/2019/03/15/rl/强化学习基础算法对比总结/resources/15578715F45608C37432FD7A4DA06887.jpg">
</li>
</ul>
<h4 id="DQN"><a href="#DQN" class="headerlink" title="DQN"></a>DQN</h4><ul>
<li><p>所属范畴<br>Model free/价值近似函数/TD</p>
</li>
<li><p>和QLearning比较<br>在Q-Learning中，我们提到了用Q表来存储当前状态s1下采取的动作action的值（value，在Q表中也称为Q值）。但是在实际过程中，一个状态s1到下一状态s2，这里的s2可能有很多不同的情况，这将会导致Q表存储的值会很多，不仅占内存，且在搜索的时候也是十分耗时的</p>
<ul>
<li>用神经网络来替代行为策略和目的策略<ul>
<li>输入为状态s和动作a，得到所有的动作值（Q值）</li>
<li>只输入状态值，然后输出所有的动作值<img src="/2019/03/15/rl/强化学习基础算法对比总结/resources/458CEACC21DCDCA5B1DBE0672EDBE177.jpg">
</li>
</ul>
</li>
</ul>
</li>
<li><p>伪代码</p>
<img src="/2019/03/15/rl/强化学习基础算法对比总结/resources/B8A8E886CEF92ACAB6702E24C4E4FFA0.jpg">
</li>
<li><p>变种Double DQN， Dueling DQN等</p>
<ul>
<li>DDQN<br>使用借鉴的思路，使用两个架构相同的近似价值函数<ul>
<li>其中一个用来根据策略生成交互行为并随 时频繁参数 (θ)</li>
<li>另一个则用来生成目标价值</li>
</ul>
</li>
</ul>
</li>
</ul>
<h4 id="Policy-Gradients"><a href="#Policy-Gradients" class="headerlink" title="Policy Gradients"></a>Policy Gradients</h4><ul>
<li>可以解决连续行为空间的情况</li>
<li>强化学习是一个通过奖惩来学习正确行为的机制，有学习奖惩值，根据自己认为的高价值选择行为的，如Q Learning、Deep Q Network 等。也有不通过分析奖励值，直接输出行为的方法，如Policy Gradient。Policy Gradient 直接输出动作的最大好处就是，能够在一个连续区间内挑选动作，而基于值的，往往是在所有动作中计算值，然后选择值最高的那个行为</li>
</ul>
<h4 id="Actor-Critic"><a href="#Actor-Critic" class="headerlink" title="Actor-Critic"></a>Actor-Critic</h4><ul>
<li><p>所属范畴<br>Model free/(基于策略 and 价值/策略近似函数)/TD</p>
</li>
<li><p>Actor Critic 为类似于Policy Gradient 和 Q-Learning 等以值为基础的算法的组合</p>
</li>
<li>Actor Critic 结合了 Policy Gradient（Actor）和 Function Approximation Critic）。Actor 基于概率选择行为，Critic 基于 Actor 的行为评判行为的得分，Actor 根据 Critic 的评分修改选择行为</li>
<li>逻辑<ul>
<li>其中Actor 类似于Policy Gradient，以状态s为输入，神经网络输出动作actions，并从在这些连续动作中按照一定的概率选取合适的动作action。 </li>
<li>Critic 类似于 Q-Learning 等以值为基础的算法，由于在Actor模块中选择了合适的动作action，通过与环境交互可得到新的状态s_, 奖励r，将状态 s_作为神经网络的输入，得到v_，而原来的状态s通过神经网络输出后得到v。 <img src="/2019/03/15/rl/强化学习基础算法对比总结/resources/330CF01329E0F79CDFBF7B3AFABE1701.jpg">
<img src="/2019/03/15/rl/强化学习基础算法对比总结/resources/873B2AE82C380A0DF20A408BAB193BE0.jpg">
<img src="/2019/03/15/rl/强化学习基础算法对比总结/resources/FCB9ECAB27436A64F27F0C3564176EDC.jpg"></li>
</ul>
</li>
<li>QAC算法(最基本的基于行为价值 Q 的 Actor-Critic 算法)<img src="/2019/03/15/rl/强化学习基础算法对比总结/resources/C5285EA40617696A6C7AB03D0049EB03.jpg">
</li>
</ul>
<h4 id="A3C"><a href="#A3C" class="headerlink" title="A3C"></a>A3C</h4><ul>
<li>所属范畴<br>Model free/(基于策略 and 价值/策略近似函数)/TD</li>
<li>A3C 其实采用了Actor-Critic 的形式，但是引入了并行计算的概念。为了训练一对Actor 和 Critic，我们将Actor 和 Critic 复制成多份，然后放在不同的核中进行训练。其中需要声明一个主要的Actor-Critic (global)，不断从多个副本中更新的参数进行学习，获得新的参数，同时副本中的参数也不断从 Actor-Critic (global) 中获得并更新。</li>
<li>A3C 是Google DeepMind 提出的一种解决 Actor Critic 不收敛问题的算法。A3C会创建多个并行的环境，让多个拥有副结构的 agent 同时在这些并行环境上更新主结构中的参数。并行中的 agent 们互不干扰，而主结构的参数更新受到副结构提交更新的不连续性干扰，所以更新的相关性被降低，收敛性提高<img src="/2019/03/15/rl/强化学习基础算法对比总结/resources/956A445EB3C04AB5746C141CC6B281B6.jpg">
</li>
</ul>
<h4 id="DDPG-Deep-Deterministic-Policy-Gradient"><a href="#DDPG-Deep-Deterministic-Policy-Gradient" class="headerlink" title="DDPG(Deep Deterministic Policy Gradient)"></a>DDPG(Deep Deterministic Policy Gradient)</h4><ul>
<li>所属范畴<br>Model free/(基于策略 and 价值/策略近似函数)/TD</li>
<li>DDPG算法能较为稳定地解决连续行为空间下强化学习问题</li>
<li>DDPG用到的神经网络是怎么样的？它其实有点类似于Actor-Critic，也需要有基于策略Policy 的神经网络 和 基于价值 Value 的神经网络，但是为了体现DQN的思想，每种神经网络我们都需要再细分成俩个。Policy Gradient 这边有估计网络和现实网络，估计网络用来输出实时的动作，而现实网络则是用来更新价值网络系统的。再看看价值系统这边，我们也有现实网络和估计网络，他们都在输出这个状态的价值，而输入端却有不同，状态现实网络这边会拿着当时actor施加的动作当做输入。在实际运用中，DDPG的这种做法的确带来了更有效的学习过程<img src="/2019/03/15/rl/强化学习基础算法对比总结/resources/61940048D6BE768A829798B0ACDD87BF.jpg"></li>
<li>噪音函数<ul>
<li>该算法在学习阶段通过在确定性的行为基础上增加一个噪声函数而实现在确定性行为周围的<font color="blue">小范围内探索</font></li>
<li>该算法还为 Actor 和 Critic 网络各备份了一套参数用来计算行为价值的期待值以<font color="blue">更稳定地提升 Critic 的策略指导水平</font>。使用备份参数的网络称为目标网络，其对应的参数每次更新的幅度很小</li>
</ul>
</li>
<li>伪代码<img src="/2019/03/15/rl/强化学习基础算法对比总结/resources/10C881AA627B5435DA098EC77BEC80A7.jpg">
</li>
</ul>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


	
    
	
      	    

  

  
  
  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/02/28/rs/高级推荐模型之二：协同矩阵分解/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="雷哥">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/favicon.ico">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="雷哥的博客">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/02/28/rs/高级推荐模型之二：协同矩阵分解/" itemprop="url">高级推荐模型之二：协同矩阵分解</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-02-28T07:20:21+08:00">
                2019-02-28
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing">
                  <a href="/categories/推荐系统/" itemprop="url" rel="index">
                    <span itemprop="name">推荐系统</span>
                  </a>
                </span>

                
                
                  ， 
                
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing">
                  <a href="/categories/推荐系统/推荐模型简介/" itemprop="url" rel="index">
                    <span itemprop="name">推荐模型简介</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h4 id="为什么需要协同矩阵分解"><a href="#为什么需要协同矩阵分解" class="headerlink" title="为什么需要协同矩阵分解"></a>为什么需要协同矩阵分解</h4><p>矩阵分解的核心就是通过矩阵，这个二维的数据结构，来对用户和物品的交互信息进行建模（如何融入更多信息）</p>
<ul>
<li>因为其二维的属性，矩阵往往只能对用户的某一种交互信息直接进行建模，这就带来很大的局限性</li>
<li>思路一，就是通过建立显式变量和隐变量之间的回归关系，从而让矩阵分解的核心结构可以获得更多信息的帮助。</li>
<li>思路二，则是采用分解机这样的集大成模型，从而把所有的特性，都融入到一个统一的模型中去。</li>
<li>思路三，就是我们这周已经讲到的，利用张量，把二维的信息扩展到 N 维进行建模</li>
</ul>
<h4 id="如何组织更多的二元关系"><a href="#如何组织更多的二元关系" class="headerlink" title="如何组织更多的二元关系"></a>如何组织更多的二元关系</h4><p>除了用户和物品这样很明显的二元关系以外，还有其他也很明显的二元关系，如何把这些二元关系有效地组织起来，就变成了一个有挑战的任务</p>
<ul>
<li>在前面的思路里面可以看到，我们似乎需要选择一个主要的关系来作为这个模型的基础框架，<font color="blue">然后把其他的信息作为补充</font>。在这样两类关系中，选择哪一个作为主要关系，哪一个作为补充关系，就显得有一点困难了</li>
<li>这也就让研究人员想出了协同矩阵分解的思路</li>
</ul>
<h4 id="协同矩阵分解的基本思路"><a href="#协同矩阵分解的基本思路" class="headerlink" title="协同矩阵分解的基本思路"></a>协同矩阵分解的基本思路</h4><ul>
<li>协同矩阵分解的基本思路其实非常直观，那就是有多少种二元关系，就用多少个矩阵分解去建模这些关系</li>
<li><p>如果协同(如果让这多个矩阵产生关系?)</p>
<ul>
<li>理论上基于矩阵分解得到的隐变量，相互是独立的，没有关系的</li>
<li>我们必须有其他的假设。这里的其他假设就是，两组不同的用户隐变量其实是一样的。也就是说，我们假设，或者认定，用户隐变量在用户与用户的关系中，以及在用户与物品的关系中，<font color="blue">是同一组用户隐变量在起作用</font><ul>
<li>说得直白一些，我们认定从两个矩阵分解出来的两组来自同一个因素（这里是用户）的<font color="blue">隐变量是完全一样的</font>。用更加学术的语言来说，这就是将两组矩阵分别投影到了相同的用户空间和物品空间</li>
</ul>
</li>
</ul>
</li>
<li><p>优点<br>我们使用“相同隐变量”这样的假设，可以把这些关系都串联起来，然后减少了总的变量数目，同时也让各种关系互相影响</p>
</li>
<li>缺点<ul>
<li>使用同样的一组隐变量去表达所有的同类关系，这样的假设存在一定的局限性，比较难找到</li>
<li>不同关系的数据量会有很大的差距。比如，用户和物品关系的数据总量可能要比用户与用户的多。所以，由于用户和物品关系的数据多，两个矩阵分解用的同一组用户隐变量，很可能会更多地解释用户和物品的部分，从而造成了学到的隐变量未必能够真正表达所有的关系</li>
</ul>
</li>
</ul>
<h4 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h4><p>从概念上来看，协同矩阵分解和张量分解之间有怎样的关系？是不是所有的张量分解都可以化为多个协同矩阵分解呢</p>
<ul>
<li>我的理解是ok的</li>
</ul>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


	
    
	
      	    

  

  
  
  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/02/27/rs/高级推荐模型之一：张量分解模型/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="雷哥">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/favicon.ico">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="雷哥的博客">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/02/27/rs/高级推荐模型之一：张量分解模型/" itemprop="url">高级推荐模型之一：张量分解模型</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-02-27T08:29:20+08:00">
                2019-02-27
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing">
                  <a href="/categories/推荐系统/" itemprop="url" rel="index">
                    <span itemprop="name">推荐系统</span>
                  </a>
                </span>

                
                
                  ， 
                
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing">
                  <a href="/categories/推荐系统/推荐模型简介/" itemprop="url" rel="index">
                    <span itemprop="name">推荐模型简介</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h4 id="为什么需要张量"><a href="#为什么需要张量" class="headerlink" title="为什么需要张量"></a>为什么需要张量</h4><ul>
<li>矩阵分析的核心思想<ul>
<li>用矩阵这种数据结构来表达用户和物品的相互关系<ul>
<li>这里，我们一般谈论的都是一些最简单的关系，例如评分、点击、购买等（本文我们依然只是讨论评分）</li>
</ul>
</li>
<li><font color="red">在这种二元的模式下，矩阵就是最好的表达用户和物品之间关系的数据结构</font></li>
</ul>
</li>
<li>如何表示更多信息(上下文)<ul>
<li>背景<br>在真实的场景中，用户和物品的关系以及产生这种关系的周围环境是复杂的。一个矩阵并不能完全描述所有的变量。<ul>
<li>例如，用户对于某个物品的评分是发生在某个地点、某个时间段内的。这种所谓的“上下文关系”（Context）往往会对评分产生很大影响。遗憾的是，<font color="blue">一个矩阵无法捕捉这样的上下文关系</font></li>
</ul>
</li>
<li>基于回归的矩阵分解和分解机方法解决<br>我们之前讨论过的“基于回归的矩阵分解”和“分解机”，本质上都是在某种程度上绕开这个问题<ul>
<li>采用的方法就是，<font color="blue">依然用矩阵来表达二元关系，但是把其他信息放进隐变量中</font>，或者是采用基于信息的推荐系统的思路来得到相关信息的建模</li>
</ul>
</li>
</ul>
</li>
</ul>
<p>除了这种思路，还有没有别的方法，<font color="red">可以把上下文关系融入到对用户和物品的建模中去呢</font></p>
<ul>
<li>张量<br>从本质上来说，张量就是矩阵的推广。我们可以这么理解:<ul>
<li>矩阵是对二维关系建模的一种工具；在二维关系中，用户和物品的评分是唯一能够被建模的变量；</li>
<li>而张量，就是对 N维关系的一种建模。而到了 N 维关系中，理论上，我们可以对任意多种上下文关系进行建<ul>
<li>比如，我们刚才提到的时间，就可以组成一个三维的张量，分别为用户、物品和时间。然后，在这个三维的张量中，每一个单元代表着某一个用户对于某一个物品在某一个时间段的评分</li>
</ul>
</li>
</ul>
</li>
</ul>
<h4 id="基于张量分解的推荐模型"><a href="#基于张量分解的推荐模型" class="headerlink" title="基于张量分解的推荐模型"></a>基于张量分解的推荐模型</h4><p>分解多维向量，我理解和之前学习的分解矩阵思想类似：分解为多个矩阵的表示方式</p>
<ul>
<li><p>CP 分解（CANDECOMP/PARAFAC）</p>
<ul>
<li>CP 分解是把一个三维张量分解为三个矩阵。具体来说，比如我们的三维张量是 N 维用户乘以 M 维的物品乘以 R 维的时间段。那么，分解出来的三个矩阵就分别为 N 维乘以 K 维的用户矩阵，M 维乘以 K 维的物品矩阵，以及 R 维乘以 K 维的时间矩阵。</li>
<li>这三个矩阵中的每一个向量都代表某一个用户、某一个物品和某一个时间段。K 在这里是一个参数，类似于矩阵分解中的隐变量的维度，我们也就可以把这个 K 理解成为隐变量的维度</li>
<li>那么在原始的三维张量中，<font color="blue">某一个元素就是这三个矩阵的某三个向量对应元素乘积相加的结果</font></li>
<li>CP 分解的一大好处就是，<font color="blue">分解出来的三个矩阵的隐变量维度是一样的</font>，这也就减少了需要调整的参数的个数</li>
</ul>
</li>
<li><p>HOSVD 分解（High Order Singular Value decomposition）</p>
<ul>
<li>含义<ul>
<li>这种分解和 CP 分解最大的不同就是分解出来的三个矩阵的维度不再一样<ul>
<li>也就是说，在我们之前的例子中，用户矩阵的维度可以是 N 乘以 A，物品矩阵的维度是 M 乘以 B，时间段矩阵的维度是 R 乘以 C。当然，这样就无法还原之前的 N 乘以 M 乘以 R 的三维张量了</li>
<li>于是在技术上，还需要乘以一个 A 乘以 B 乘以 C 的小张量才能对原始数据进行复原。</li>
</ul>
</li>
<li>所以，通俗地讲，HOSVD 分解就是把一个三维的张量，分解成为三个矩阵和一个更小的张量的乘积</li>
</ul>
</li>
<li>优缺点<ul>
<li>好处自然就是给不同的数据以不同的自由度，因为不再限制用户、物品和时间段都必须有一样的维度。</li>
<li>缺点是有了更多的“超参数”需要调整</li>
</ul>
</li>
<li>损失函数<br>在一般的分解过程中，我们可以定义“<strong>平方差</strong>”（Squared Loss），也就是原始数值和预测数值之间的平方差来作为损失函数</li>
</ul>
</li>
</ul>
<h4 id="求解张量分解"><a href="#求解张量分解" class="headerlink" title="求解张量分解"></a>求解张量分解</h4><ul>
<li>随机梯度下降法（SGD, Stochastic Gradient Descent），也就是把张量的分解问题看作是一个一般的优化问题</li>
<li>另外一种方法，也是在矩阵分解中可以使用的，叫作 ALS（Alternating Least Square）方法<ul>
<li>这种方法则是在优化每一轮的时候，按住所有其他的矩阵变量不动，单独优化一个变量</li>
</ul>
</li>
</ul>
<h4 id="问题：从概念上来看，用张量分解对上下文信息进行建模的最大问题是什么"><a href="#问题：从概念上来看，用张量分解对上下文信息进行建模的最大问题是什么" class="headerlink" title="问题：从概念上来看，用张量分解对上下文信息进行建模的最大问题是什么"></a>问题：从概念上来看，用张量分解对上下文信息进行建模的最大问题是什么</h4><ul>
<li>张量的稀疏性</li>
<li>模型更负责，不易求解</li>
</ul>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


	
    
	
      	    

  

  
  
  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/02/27/rs/基于隐变量的模型之三：分解机/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="雷哥">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/favicon.ico">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="雷哥的博客">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/02/27/rs/基于隐变量的模型之三：分解机/" itemprop="url">基于隐变量的模型之三：分解机</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-02-27T07:19:29+08:00">
                2019-02-27
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing">
                  <a href="/categories/推荐系统/" itemprop="url" rel="index">
                    <span itemprop="name">推荐系统</span>
                  </a>
                </span>

                
                
                  ， 
                
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing">
                  <a href="/categories/推荐系统/推荐模型简介/" itemprop="url" rel="index">
                    <span itemprop="name">推荐模型简介</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h4 id="矩阵分解和基于回归的隐变量模型存在哪些问题"><a href="#矩阵分解和基于回归的隐变量模型存在哪些问题" class="headerlink" title="矩阵分解和基于回归的隐变量模型存在哪些问题"></a>矩阵分解和基于回归的隐变量模型存在哪些问题</h4><ul>
<li>发展脉络 <ul>
<li>首先，矩阵分解主要解决了两个问题，那就是从一个大矩阵降维到两个小矩阵，并且寄希望这两个小矩阵能够抓住用户和物品的相关度。<ul>
<li>然而，单纯的矩阵分解无法融入很多用户和物品的特性</li>
</ul>
</li>
<li>这就引导我们开发出了基于回归的矩阵分解。<ul>
<li>所谓的回归部分，也就是从显式特性出发，建立从显式特性到隐变量之间关系的流程，从而使我们能够把更多的信号放进模型中。</li>
<li>在一定程度上，基于回归的隐变量模型实现了把显式变量和隐变量结合的目的<ul>
<li>但是这类模型的学习过程非常麻烦。实际上，因为这类模型复杂的训练流程，其在实际应用中并不常见。</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<p>那么，有没有其他思路来统一显式变量和隐变量的处理方式呢？</p>
<h4 id="分解机"><a href="#分解机" class="headerlink" title="分解机"></a>分解机</h4><ul>
<li><p>核心原理</p>
<ul>
<li>核心就是认为<font color="red">需要预测的变量（这里我们依然讨论评分）是所有显式变量的一个回归结果</font><ul>
<li>分解机直接借鉴了这一点，也就是说，<font color="blue">分解机的输入是所有的显式变量</font></li>
</ul>
</li>
</ul>
</li>
<li><p>个人理解</p>
<ul>
<li>这种推荐模型本质可以看做是个回归模型：需要预测的变量（这里我们依然讨论评分）是所有显式变量的一个回归结果 </li>
<li><font color="purple">分解机本质就是增加了更多的特征，比如各个显示变量的两两乘积生成新特征</font></li>
<li>适当增加模型复杂度，泛化性强：结合了隐变量，比如显示变量的两两乘积用隐变量的乘积来表示(一种显示变量就用隐变量vector表示)</li>
</ul>
</li>
<li><p>基本思想</p>
<ul>
<li>第一步:把用户的年龄和物品的种类直接当作特性输入到模型中</li>
<li>第二步:分解机是把这两个特性的数值进行乘积，当作一个新的特性，然后进一步处理这种两两配对的关系<ul>
<li>增加了特征(<font color="blue">显示变量两两配对</font>)<br>分解机在对待显式变量的手法上更进了一步，那就是不仅直接对显式变量进行建模，还对显示变量的两两关系进行建模。当然，在原始的论文中，分解机其实还可以对更加高维的关系进行建模，我们这里局限在两两关系上<ul>
<li><font color="blue">把原始特性进行两两配对是构建模型的一种重要的方法，特别是对于非深度学习模型，需要自己做特征工程的模型</font></li>
<li>两两配对问题<ul>
<li>一个问题就是<font color="blue"><strong>特性空间会急速增长</strong></font></li>
<li>另一个更严重的问题就是，如果我们的单独特性中，有一些是“类别特性”（Categorical Feature），那么在两两配对之后就会产生大量的 0，从而变成一个巨大的<font color="blue">稀疏矩阵</font></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<h4 id="如何建模-如何解决上面问题"><a href="#如何建模-如何解决上面问题" class="headerlink" title="如何建模(如何解决上面问题)"></a>如何建模(如何解决上面问题)</h4><ul>
<li>分解机利用了<font color="blue">矩阵分解的降维思路</font></li>
<li>我们不对一个稀疏矩阵直接建模，而是把这个稀疏矩阵分解之后再进行建模</li>
<li>就是先假定，<font color="blue">所有特性都对应一个隐变量向量，两个显式特性的乘积是两个特性的隐变量的点积</font><ul>
<li>也就是说，我们把两个显式特性的乘积分解为了两个向量的乘积。这样，我们就不需要直接表示原来的稀疏矩阵。<p></p></li>
</ul>
</li>
<li>在这样的思路下，分解机成功地把隐变量和显式变量结合到了一起<ul>
<li>当我们的显式特性仅仅是用户 ID 和物品 ID 的时候，分解机的表达退回了最原始的矩阵分解</li>
<li>也就是说，矩阵分解其实可以表达成为特性的两两作用矩阵的分解</li>
</ul>
</li>
<li>在原始的论文中，作者还用分解机模拟了好几种流行的模型</li>
<li>虽然也是为了建立从显式特性到隐变量的关系，但是对比基于回归的矩阵分解而言，分解机的训练过程大大简化了。在实际应用中，我们经常使用“<strong>随机梯度下降</strong>”（SGD, Stochastic Gradient Descent）来对分解机直接进行求解</li>
</ul>
<h4 id="思考问题"><a href="#思考问题" class="headerlink" title="思考问题"></a>思考问题</h4><ul>
<li>分解机能够解决“冷启动”的问题吗<ul>
<li>个人认为是可以解决的：因为本质就是一个回归模型，由隐变量得到显变量的映射。然后映射到指标(比如说点击率，评论得分)</li>
<li>所以在冷启动问题上，对缺失的变量可以看其分布，然后拿到期望值，这样来处理</li>
</ul>
</li>
</ul>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


	
    
	
      	    

  

  
  
  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/02/26/rs/基于隐变量的模型之二：基于回归的矩阵分解/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="雷哥">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/favicon.ico">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="雷哥的博客">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/02/26/rs/基于隐变量的模型之二：基于回归的矩阵分解/" itemprop="url">基于隐变量的模型之二：基于回归的矩阵分解</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-02-26T08:15:19+08:00">
                2019-02-26
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing">
                  <a href="/categories/推荐系统/" itemprop="url" rel="index">
                    <span itemprop="name">推荐系统</span>
                  </a>
                </span>

                
                
                  ， 
                
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing">
                  <a href="/categories/推荐系统/推荐模型简介/" itemprop="url" rel="index">
                    <span itemprop="name">推荐模型简介</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h4 id="基础矩阵分解问题"><a href="#基础矩阵分解问题" class="headerlink" title="基础矩阵分解问题"></a>基础矩阵分解问题</h4><ul>
<li>第一，矩阵分解的矩阵仅仅是对用户和物品的喜好进行了“编码”（Encode），但在融合多种不同的推荐元素方面，表现却很一般</li>
<li>第二，矩阵分解的核心是学习用户的隐向量和物品的隐向量。原则上，这两类隐向量的学习仅能通过训练过程获得。<ul>
<li>我们无法获得新来用户或者新来物品的隐向量了，因为这些用户和物品并不在训练集里</li>
<li>冷启动问题<br>在推荐系统中，这种情况就叫作不能处理“冷启动”（Cold Start）问题，也就是不能处理“冷”用户和“冷”物品。在这样的场景下，直接使用矩阵分解就会有问题</li>
</ul>
</li>
</ul>
<h4 id="基于回归的矩阵分解"><a href="#基于回归的矩阵分解" class="headerlink" title="基于回归的矩阵分解"></a>基于回归的矩阵分解</h4><ul>
<li>首先，有一组用户特性和物品特性来表述每一个用户和物品。这些特性不是隐变量，是显式表达的特性<ul>
<li>用户特性比如用户的年龄、性别、经常出现的地区、已经表达了喜好的类别等</li>
<li>物品特性比如物品的种类、描述等等</li>
<li>这两组显式的特性就是为了解决我们刚才说的第一个问题(融入更多元素)，矩阵分解无法抓住更多的信号。</li>
</ul>
</li>
<li>现在我们有两个独立的部分<ul>
<li>一个是基于矩阵分解的部分，这一部分是分解一个已知的评分矩阵，从而学习到用户和物品的隐向量</li>
<li>另外一个部分，就是用户特性和物品特性</li>
</ul>
</li>
<li>关联两部分<br>用户的隐向量，其实是从用户的显式特性变换而来的<ul>
<li><font color="blue">我们建立一个从显式特性到隐向量的回归模型，使得隐向量受到两方面的制约：从评分矩阵的分解得来的信息和从显式特性回归得来的信息</font></li>
</ul>
</li>
<li>不怕冷启动<br>不再怕“冷启动”了。或者说，在有一部分“冷启动”的情况下，这样的模型可以处理得更好。原因就是我们使用了显示特性来回归隐向量</li>
<li>贝叶斯角度理解<br>我们还可以从贝叶斯的角度来理解基于回归的矩阵分解。把用户的隐向量和物品的隐向量看作是两个随机变量。我们可以认为这些随机变量加上了先验概率分布。只不过，这个先验概率分布的均值不是我们经常使用的 0，而是一个以回归函数的结果为均值的高斯分布，这个回归函数就是我们由显式特性得到的。本质上，我们认为显示特性的某种变换成为了隐向量的先验信息</li>
</ul>
<h4 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h4><ul>
<li>第一，我们简要介绍了矩阵分解的一些问题</li>
<li>第二，我们详细介绍了基于回归的矩阵分解的基本思路，以及这样的模型如何解决了传统矩阵分解关于“冷启动”的难题</li>
<li>第三，如何学习的问题，需要查阅其他资料</li>
</ul>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


	
    
	
      	    

  

  
  
  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/02/26/rs/基于隐变量的模型之一：矩阵分解/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="雷哥">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/favicon.ico">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="雷哥的博客">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/02/26/rs/基于隐变量的模型之一：矩阵分解/" itemprop="url">基于隐变量的模型之一：矩阵分解</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-02-26T07:10:19+08:00">
                2019-02-26
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing">
                  <a href="/categories/推荐系统/" itemprop="url" rel="index">
                    <span itemprop="name">推荐系统</span>
                  </a>
                </span>

                
                
                  ， 
                
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing">
                  <a href="/categories/推荐系统/推荐模型简介/" itemprop="url" rel="index">
                    <span itemprop="name">推荐模型简介</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h4 id="什么是隐变量"><a href="#什么是隐变量" class="headerlink" title="什么是隐变量"></a>什么是隐变量</h4><ul>
<li>就是“隐藏的变量”或者叫“隐藏的参数”，这里主要是指我们假定实际的数据是由一系列的隐含变量产生的</li>
<li>我们通过模型的假设，知道隐变量之间的关系，但暂时并不知道隐变量的取值。因此需要通过“推断”（Inference）过程来确定隐变量的实际取值</li>
<li><p>隐变量往往还带有“统计分布”（Distribution）的假设。什么意思呢？就是隐变量之间，或者隐变量和显式变量之间的关系，我们往往认为是由某种分布产生的</p>
<ul>
<li>举例:高斯混合模型<br>高斯混合模型假设数据是由多个不同的高斯分布产生的，每一个高斯分布有自己的均值和方差<ul>
<li>对于每一个数据点，我们就有一个隐含的变量，来表达当前这个数据点究竟来自哪一个高斯分布</li>
<li>两个高斯分布的均值和方法其实也不知道</li>
</ul>
</li>
</ul>
<p>高斯混合模型，几乎是最简单的隐变量模型，但也给我们了展示了使用隐变量模型对数据建模的灵活性以及训练的复杂性</p>
</li>
</ul>
<h4 id="矩阵分解作为隐变量模型"><a href="#矩阵分解作为隐变量模型" class="headerlink" title="矩阵分解作为隐变量模型"></a>矩阵分解作为隐变量模型</h4><ul>
<li>关系矩阵(用户，物品，评分)<br>在推荐系统中，有一种最普遍的数据表达，那就是用户和物品的交互，比如评分、点击等等<ul>
<li>这里我们用评分作为一般性的讨论。对于每一个用户，如果我们用一个向量来表达其对所有可能物品的评分，那么把所有用户的向量堆积起来，就可以得到一个矩阵</li>
<li>这个矩阵的每一行代表一个用户，每一列代表一个物品，每一个交叉的元素代表某一个用户对于某一个商品的评分</li>
<li>特点<br>这个矩阵的数据其实非常稀少。因为在一个现实的系统中，一个用户不可能对所有的物品都进行评分</li>
<li>补全任务<br>我们的任务其实就是根据有评分的用户物品交互，对那些还没有评分信息的物品进行预测。如果我们能够“补全”（Complete）整个矩阵里的其他元素</li>
</ul>
</li>
</ul>
<h4 id="如何补全-矩阵分解"><a href="#如何补全-矩阵分解" class="headerlink" title="如何补全(矩阵分解)"></a>如何补全(矩阵分解)</h4><ul>
<li><p>核心<br>我们可以看到，矩阵分解的核心其实就是刚才的假设，用隐向量来表达用户和物品，他们的乘积关系就成为了原始的元素。不同的假设可以得到不同的矩阵分解模型</p>
</li>
<li><p>效果<br>在这样的一个假设下，一个原本 1 百万乘以 1 万的矩阵就可以被分解为 1 百万乘以 100 的用户矩阵和 100 乘以 1 万的物品矩阵的乘</p>
</li>
<li><p>降维<br>原本是需要对整个矩阵，也就是 1 百万乘以 1 万个数据进行建模，而现在缩减到了两个小一些的矩阵 1 百万乘以 100 和 100 乘以 1 万</p>
<ul>
<li>对比来看，之前对于每一个用户，我们需要一万个元素来表达用户对于这一万个物品的评分喜好；现在，对每个用于仅仅需要保存 100 个元素</li>
<li>这一百个元素的数值并不代表任何意义。从这个层面上理解矩阵分解，也就能够帮助我们知道，这个方法其实是一种“<strong>降维</strong></li>
</ul>
</li>
</ul>
<h4 id="如何学习"><a href="#如何学习" class="headerlink" title="如何学习"></a>如何学习</h4><ul>
<li>目标函数<br>前面讲到，矩阵里的每一个元素来自于<font color="blue">两个隐向量的点积</font>，我们就可以利用这一点来构造一个目标函数。<ul>
<li>利用<strong>最小二乘法</strong>的原理（Least Square）来拟合求解这些隐向量</li>
<li>这个目标函数其实就是说，这两个隐向量的点积一定要与我们观测到的矩阵数值相近。这里的“相近”是用这两个数值的误差，在这里也就是<strong>平方差</strong>（Square Error）来衡量的</li>
</ul>
</li>
</ul>
<h4 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h4><ul>
<li>第一，我们简要介绍了隐变量模型的基本原理</li>
<li>第二，我们详细介绍了矩阵分解作为隐变量模型的假设和原理</li>
<li>第三，我们简要地讨论了如何求解矩阵分解里的隐变量</li>
</ul>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


	
    
	
      	    

  

  
  
  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/02/25/rs/简单推荐模型之三 基于内容信息的推荐模型/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="雷哥">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/favicon.ico">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="雷哥的博客">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/02/25/rs/简单推荐模型之三 基于内容信息的推荐模型/" itemprop="url">简单推荐模型之三:基于内容信息的推荐模型</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-02-25T07:32:10+08:00">
                2019-02-25
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing">
                  <a href="/categories/推荐系统/" itemprop="url" rel="index">
                    <span itemprop="name">推荐系统</span>
                  </a>
                </span>

                
                
                  ， 
                
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing">
                  <a href="/categories/推荐系统/推荐模型简介/" itemprop="url" rel="index">
                    <span itemprop="name">推荐模型简介</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h4 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h4><ul>
<li>对于基于流行度预测的推荐的问题<ul>
<li>推荐结果不是个性化的。因为流行度预测是一种全局的预测，每个人得到的推荐结果是一样的</li>
</ul>
</li>
<li>而协同过滤的问题<ul>
<li>强烈依赖相似用户以及相似物品的定义</li>
<li>而且对于新用户或者新物品来说有数据稀缺的问题</li>
</ul>
</li>
</ul>
<p>因此，在实际应用中，往往不能在整个系统中单独使用协同过滤</p>
<h4 id="基于内容信息的推荐系统"><a href="#基于内容信息的推荐系统" class="headerlink" title="基于内容信息的推荐系统"></a>基于内容信息的推荐系统</h4><ul>
<li>定义<br>基于内容信息的推荐系统，其实就是<font color="blue">用特征（Feature）来表示用户、物品以及用户和物品的交互，从而能够把推荐问题转换成为监督学习任务</font></li>
</ul>
<h4 id="特征工程"><a href="#特征工程" class="headerlink" title="特征工程"></a>特征工程</h4><ul>
<li>特征工程(物品信息)<br>需要将用户和物品的所有信号用特征来表示<ul>
<li>物品的文本信息<ul>
<li>用 TF-IDF 的方法来形成文本向量。当然，因为文本信息的噪声相对比较大，并且数据维度也比较大（维度等于文本所对应语言的词汇量），很多时候我们都寻求降低这部分数据的维度，降低到一个固定的维度。这种时候，很多所谓“降维”的工具就很有必要了</li>
<li>用“<strong>话题模型</strong>”（Topic Model）对文本进行降维的。也就是说，我们针对每一个文字描述都可以学习到一个话题的分布，这个分布向量可能是 50 维、100 维等等</li>
<li>使用各种“<strong>词嵌入向量</strong>”（Word Embedding）的方法来为文字信息降维，从而能够使用一个固定的维度来表达文字信息</li>
</ul>
</li>
<li>物品的类别信息<ul>
<li>直接获取分类，比如新闻的分类，或者通过其他渠道得到直接的分类</li>
<li>使用ML的手段，来得到分类</li>
</ul>
</li>
<li>知识图谱挖掘信息<ul>
<li>利用知识图谱进行知识的深挖</li>
<li>举个例子，某一篇新闻文章是关于美国总统特朗普的，于是这篇文章可能就会自动被打上美国总统、美国政治等其他标签。这种通过一些原始的信息来进一步推断更加丰富的知识信息，也是重要的物品类别特征的处理工作</li>
</ul>
</li>
</ul>
</li>
<li>特征工程(用户信息)<ul>
<li>最基础、最首要的肯定是用户的基本特性，包括性别、年龄、地理位置</li>
<li>还有围绕这三个特性发展出来的三大种类的特性。比如，不同性别在文章点击率上的差异，不同年龄层在商品购买上的差异，不同地理位置对不同影视作品的喜好等</li>
<li>我们可以为用户进行画像（Profiling）<ul>
<li>有显式的用户画像，比如用户自己定义的喜好，或者用户自己认为不愿意看到的物品或者类别</li>
<li>隐式的：通过用户的“隐反馈”（Implicit Feedback），来对用户的喜好进行建模</li>
</ul>
</li>
</ul>
</li>
</ul>
<h4 id="目标函数"><a href="#目标函数" class="headerlink" title="目标函数"></a>目标函数</h4><p>对于究竟在哪种场景中使用什么样的目标函数，这依然是当前的一个主要研究方向</p>
<ul>
<li>基于评分<br>纯粹的基于评分（Rating）的协同过滤推荐系统一样，我们可以设置监督学习的目标函数是<strong>拟合评分</strong>。当然，已经有很多学者指出评分并不是推荐系统的真正目标。</li>
<li>基于点击率，购买率<br>在实际系统中比较常见的目标函数有点击率和购买率，也有一些相对比较复杂的目标函数，比如预测用户在某一个物品上的停留时长</li>
</ul>
<h4 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h4><ul>
<li>背景：基于流行度和协同过滤的缺点</li>
<li>如何构建特征工程，包括物品和用户</li>
<li>目标函数的确定很重要</li>
</ul>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


	
    
	
      	    

  

  
  
  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/02/24/rs/简单推荐模型之二 基于相似信息的推荐模型/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="雷哥">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/favicon.ico">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="雷哥的博客">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/02/24/rs/简单推荐模型之二 基于相似信息的推荐模型/" itemprop="url">简单推荐模型之二:基于相似信息的推荐模型</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-02-24T15:30:10+08:00">
                2019-02-24
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing">
                  <a href="/categories/推荐系统/" itemprop="url" rel="index">
                    <span itemprop="name">推荐系统</span>
                  </a>
                </span>

                
                
                  ， 
                
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing">
                  <a href="/categories/推荐系统/推荐模型简介/" itemprop="url" rel="index">
                    <span itemprop="name">推荐模型简介</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h4 id="什么是相似信息的推荐模型"><a href="#什么是相似信息的推荐模型" class="headerlink" title="什么是相似信息的推荐模型"></a>什么是相似信息的推荐模型</h4><ul>
<li>定义<br>相似信息的推荐模型又叫<strong>“临近”（Neighborhood）模型</strong>。顾名思义，就是我们希望利用临近、或者相似的数据点来为用户推荐。</li>
<li>协同过滤<br>临近模型的内在假设是推荐系统中著名的“<strong>协同过滤</strong>”（Collaborative Filtering）<ul>
<li><strong>相似的用户可能会有相似的喜好，相似的物品可能会被相似的人所偏好</strong>。</li>
<li>于是，如果我们能够定义怎么寻找相似的用户或者相似的物品，那么我们就可以利用这些类别的人群或者物品来给用户进行推荐。<p></p></li>
</ul>
</li>
<li>举例<br>A,B都看了战狼2，B还看了红海，那么就给A推荐红海<br>思考过程：<ul>
<li>第一，联系用户 A 和用户 B 的是他们都看过《战狼 2》。这就帮助我们定义了 A 和 B 是相似用户</li>
<li>第二，我们的假定是，相似的用户有相似的观影偏好，于是我们就直接把 B 的另外一个观看过的电影《红海行动》拿来推荐给了 A</li>
<li>意义：</li>
<li>这两个步骤其实就很好地解释了“协同过滤”中“协同”的概念，意思就是<font color="blue">相似的用户互相协同，互相过滤信息</font></li>
<li><strong>“协同过滤”从统计模型的意义上来讲，其实就是“借用数据”，<font color="blue">在数据稀缺的情况下帮助建模</font></strong>。掌握这个思路是非常重要的建模手段</li>
<li>在用户 A 数据不足的情况下，我们挖掘到可以借鉴用户 B 的数据<ul>
<li>因此，我们其实是把用户 A 和用户 B“聚类”到了一起，认为他们代表了一个类型的用户。</li>
<li>当我们把对单个用户的建模<font color="red">抽象上升到某一个类型的用户</font>的时候，这就把更多的数据放到了一起</li>
</ul>
</li>
</ul>
</li>
</ul>
<h4 id="基于相似用户的协同过滤"><a href="#基于相似用户的协同过滤" class="headerlink" title="基于相似用户的协同过滤"></a>基于相似用户的协同过滤</h4><p>如何才能够比较系统地定义这样的流程呢？</p>
<ul>
<li>首先，问题被抽象为我们需要估计用户 I 针对一个没有“触碰过”（这里指点击、购买、或者评分等行为）的物品 J 的偏好<ul>
<li>第一步，我们需要构建一个用户集合，这个用户集合得满足两个标准：<ul>
<li>第一，这些用户需要已经触碰过物品 J，这是与用户 I 的一大区别；</li>
<li>第二，这些用户在其他的行为方面需要与用户 I 类似</li>
</ul>
</li>
<li>然后进行打分<ul>
<li>简单的做法<br>首先，我们已经得到了所有和 I 相似的用户对 J 的打分。那么，一种办法就是，直接用这些打分的平均值来预估 J 的评分。也就是说，如果我们认为这个相似集合都是和用户 I 相似的用户，那么他们对 J 的偏好，我们就认为是 I 的偏好。显然这是一个很粗糙的做法</li>
<li>改进方法<ul>
<li>采用加权平均的做法<br>也就是说，和用户 I 越相似的用户，我们越倚重这些人对 J 的偏好</li>
<li>我们也需要对整个评分进行一个修正<ul>
<li>虽然这个相似集合的人都对 J 进行过触碰，但是每个人的喜好毕竟还是不一样的。比如有的用户可能习惯性地会<font color="blue">对很多物品有很强的偏好</font>。因此，仅仅是借鉴每个人的偏好，而忽略了这些用户的偏差，这显然是不够的。所以，<font color="blue">我们需要对这些评分做这样的修正，那就是减去这些相似用户对所有东西的平均打分</font>，也就是说，我们需要把这些用户本人的<font color="blue">偏差</font>给去除掉</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>方法总结：<br>综合刚才说的两个因素，可以得到一个更加合适的打分算法，那就是，用户 I 对物品 J 的打分来自两个部分：<ul>
<li>一部分是 I 的平均打分</li>
<li>另外一部分是 I 对于 J 的一个在平均打分之上的补充打分<ul>
<li>这个补充打分来自于刚才我们建立的相似用户集，是这个相似用户集里每个用户对于 J 的补充打分的一个<font color="blue">加权平均<ul>
<li>权重依赖于这个用户和 I 的相似度</li>
<li>每个用户对于 J 的补充打分是他们对于 J 的直接打分减去他们自己的平均打分</li></ul></font></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>


<h4 id="相似信息的构建"><a href="#相似信息的构建" class="headerlink" title="相似信息的构建"></a>相似信息的构建</h4><p>几个关键要素：</p>
<ul>
<li>我们怎么来定义两个用户是相似的<ul>
<li>一种最简单的办法，就是计算两个用户对于他们都偏好物品的“<strong>皮尔森相关度</strong>”（Pearson Correlation）</li>
<li>皮尔森相关度是针对每一个“两个用户”都同时偏好过的物品，看他们的偏好是否相似，这里的相似是用乘积的形式出现的。当两个偏好的值都比较大的时候，乘积也就比较大</li>
</ul>
</li>
<li>设定一些“阈值”来筛选刚才所说的相关用户集合<ul>
<li>我们可以设置最多达到前 K 个相似用户（比如 K 等于 100 或者 200）</li>
</ul>
</li>
<li>加权平均里面的权重问题<ul>
<li>一种权重，就是直接使用两个用户的相似度，也就是我们刚计算的皮尔森相关度<ul>
<li>当然，这里有一个问题，如果直接使用，我们可能会过分“相信”有一些相关度高但自身数据也不多的用户</li>
<li>所以我们可以把皮尔森相关度乘以一个系数，这个系数是根据自身的偏好数量来定的</li>
</ul>
</li>
</ul>
</li>
</ul>
<h4 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h4><ul>
<li>协同过滤<br>相似的用户可能会有相似的喜好，相似的物品可能会被相似的人所偏好</li>
<li>基于相似用户协同过滤<ul>
<li>问题被抽象为我们需要估计用户 I 针对一个没有“触碰过”（这里指点击、购买、或者评分等行为）的物品 J 的偏好</li>
<li>假设已经构建了这样的用户组，然后就是对需要推荐的物品进行打分，有分为简单的平均打分，和加权打分等</li>
</ul>
</li>
<li>相似信息的构建(皮尔森相似度，设置阈值构建用户集合)</li>
</ul>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


	
    
  </section>

  
  <nav class="pagination">
    <a class="extend prev" rel="prev" href="/"><i class="fa fa-angle-left"></i></a><a class="page-number" href="/">1</a><span class="page-number current">2</span><a class="page-number" href="/page/3/">3</a><span class="space">&hellip;</span><a class="page-number" href="/page/8/">8</a><a class="extend next" rel="next" href="/page/3/"><i class="fa fa-angle-right"></i></a>
  </nav>



          </div>
          


          

        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      

      <section class="site-overview sidebar-panel sidebar-panel-active">
        <div class="site-author motion-element" itemprop="author" itemscope="" itemtype="http://schema.org/Person">
          <img class="site-author-image" itemprop="image" src="/images/favicon.ico" alt="雷哥">
          <p class="site-author-name" itemprop="name">雷哥</p>
           
              <p class="site-description motion-element" itemprop="description">不积跬步无以至千里</p>
          
        </div>
        <nav class="site-state motion-element">

          
            <div class="site-state-item site-state-posts">
              <a href="/archives">
                <span class="site-state-item-count">77</span>
                <span class="site-state-item-name">日志</span>
              </a>
            </div>
          

          
            
            
            <div class="site-state-item site-state-categories">
              <a href="/categories/index.html">
                <span class="site-state-item-count">21</span>
                <span class="site-state-item-name">分类</span>
              </a>
            </div>
          

          
            
            
            <div class="site-state-item site-state-tags">
              <a href="/tags/index.html">
                <span class="site-state-item-count">19</span>
                <span class="site-state-item-name">标签</span>
              </a>
            </div>
          

        </nav>

        

        <div class="links-of-author motion-element">
          
            
              <span class="links-of-author-item">
                <a href="https://github.com/yuancl" target="_blank" title="GitHub">
                  
                    <i class="fa fa-fw fa-github"></i>
                  
                    
                      GitHub
                    
                </a>
              </span>
            
          
        </div>

        
        

        
        

        


      </section>

      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2019</span>
  <span class="with-love">
    <i class="fa fa-雷哥"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">雷哥</span>
</div>


<div class="powered-by">
  由 <a class="theme-link" href="https://hexo.io">Hexo</a> 强力驱动
</div>

<div class="theme-info">
  主题 -
  <a class="theme-link" href="https://github.com/iissnan/hexo-theme-next">
    NexT.Gemini
  </a>
</div>


        

        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>

  
  <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>

  
  <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.2"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.2"></script>



  
  


  <script type="text/javascript" src="/js/src/affix.js?v=5.1.2"></script>

  <script type="text/javascript" src="/js/src/schemes/pisces.js?v=5.1.2"></script>



  
    <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.2"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.2"></script>

  

  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.2"></script>



  


  




	





  





  






  





  

  

  

  
  
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        tex2jax: {
          inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
          processEscapes: true,
          skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
        }
      });
    </script>

    <script type="text/x-mathjax-config">
      MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for (i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
        }
      });
    </script>
    <script type="text/javascript" src="//cdn.bootcss.com/mathjax/2.7.1/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
  


  

  

</body>
</html>
