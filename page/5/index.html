<!DOCTYPE html>



  


<html class="theme-next gemini use-motion" lang="zh-Hans">
<head><meta name="generator" content="Hexo 3.8.0">
  <meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform">
<meta http-equiv="Cache-Control" content="no-siteapp">















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css">




  
  
  
  

  
    
    
  

  

  

  

  

  
    
    
    <link href="//fonts.googleapis.com/css?family=Lato:300,300italic,400,400italic,700,700italic&subset=latin,latin-ext" rel="stylesheet" type="text/css">
  






<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css">

<link href="/css/main.css?v=5.1.2" rel="stylesheet" type="text/css">


  <meta name="keywords" content="Hexo, NexT">








  <link rel="shortcut icon" type="image/x-icon" href="/favicon.ico?v=5.1.2">






<meta name="description" content="不积跬步无以至千里">
<meta property="og:type" content="website">
<meta property="og:title" content="雷哥的博客">
<meta property="og:url" content="http://yoursite.com/page/5/index.html">
<meta property="og:site_name" content="雷哥的博客">
<meta property="og:description" content="不积跬步无以至千里">
<meta property="og:locale" content="zh-Hans">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="雷哥的博客">
<meta name="twitter:description" content="不积跬步无以至千里">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Gemini',
    sidebar: {"position":"left","display":"post","offset":12,"offset_float":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: true,
    duoshuo: {
      userId: '0',
      author: '雷哥'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://yoursite.com/page/5/">





  <title>雷哥的博客</title>
  














</head>

<body itemscope="" itemtype="http://schema.org/WebPage" lang="zh-Hans">

  
  
    
  

  <div class="container sidebar-position-left 
   page-home 
 ">
    <div class="headband"></div>

    <header id="header" class="header" itemscope="" itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">雷哥的博客</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle"></p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br>
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br>
            
            分类
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br>
            
            归档
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br>
            
            标签
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            
  <section id="posts" class="posts-expand">
    
	
    
	
      	    

  

  
  
  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/12/06/dl/第五门课-第三周/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="雷哥">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/favicon.ico">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="雷哥的博客">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/12/06/dl/第五门课-第三周/" itemprop="url">第五门课-第三周</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-12-06T08:17:19+08:00">
                2018-12-06
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing">
                  <a href="/categories/深度学习/" itemprop="url" rel="index">
                    <span itemprop="name">深度学习</span>
                  </a>
                </span>

                
                
                  ， 
                
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing">
                  <a href="/categories/深度学习/吴恩达课程总结/" itemprop="url" rel="index">
                    <span itemprop="name">吴恩达课程总结</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p><a href="https://github.com/yuancl/dl-algorithm/tree/master/5-RecurrentNeuralNetworks/Week3/Machine-Translation" target="_blank" rel="noopener">习题代码:Machine-Translation</a><br><a href="https://github.com/yuancl/dl-algorithm/tree/master/5-RecurrentNeuralNetworks/Week3/Trigger-word-detection" target="_blank" rel="noopener">习题代码:Trigger-word-detection</a></p>
<h4 id="序列结构的各种序列"><a href="#序列结构的各种序列" class="headerlink" title="序列结构的各种序列"></a>序列结构的各种序列</h4><ul>
<li><p>seq2seq<br>分为编码网络的解码网络</p>
<img src="/2018/12/06/dl/第五门课-第三周/resources/4A4F9C5B535DDB65265853ACD2EDC912.jpg">
</li>
<li><p>应用场景</p>
<ul>
<li>机器翻译，比如英文和法文的互相翻译</li>
<li>Image-to-seq<br>例子中使用的AlexNet网络，将最后的softmax输出替换为RNN网络，输出为一个序列<img src="/2018/12/06/dl/第五门课-第三周/resources/49BD4A13FE8A1C4571A631492527A168.jpg">
</li>
</ul>
</li>
<li><p>选择最可能的句子</p>
<ul>
<li>语言模型和翻译模型比较<ul>
<li>语言模型总是以零向量开始$(P(y^{&lt; 1 &gt;},y^{&lt; 2 &gt;},y^{&lt; 3 &gt;}…y^{&lt; n &gt;}))$</li>
<li>而翻译模型输入是法语的encoder，可以理解为条件模型:$P(y^{&lt; 1 &gt;},y^{&lt; 2 &gt;},y^{&lt; 3 &gt;}…y^{&lt; n &gt;}|x^{&lt; 1 &gt;},x^{&lt; 2 &gt;},x^{&lt; 3 &gt;}…x^{&lt; n &gt;})$</li>
<li>所以一个是随机输出seq，另一个是需要概率最大的seq<img src="/2018/12/06/dl/第五门课-第三周/resources/BB67CF9637B51A081225158E964A74BA.jpg"></li>
<li>如何保证翻译模型中的条件概率最大<ul>
<li>贪心算法：没一个输出都保证当前一个term($y^{&lt; i &gt;}$)概率最大，但是并不能保证<font color="red">整个序列概率最大</font>，所以一次挑选一个词并不是最佳的选择</li>
<li>穷举法：将所有句子进行穷举测试，但由单词生成的句子量太大，无法穷举</li>
<li>集束算法</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<h4 id="集束算法-Beam-Search"><a href="#集束算法-Beam-Search" class="headerlink" title="集束算法(Beam Search)"></a>集束算法(Beam Search)</h4><ul>
<li><p>集束算法</p>
<ul>
<li>贪婪算法只会挑出最可能的那一个单词，然后继续。而集束搜索则会考虑多个选择，选择数量就是集束宽(Beam width)</li>
<li>第一步：<br>需要 输入法语句子到编码网络，然后会解码这个网络，这个 softmax 层(上图编号 3 所示)会输 出 10,000 个概率值，得到这 10,000 个输出的概率值，取前三个存起来</li>
<li>第二步：<ul>
<li>选择第一步中的一个词$P(y^{<2>}|x, y^{<1>})$如下图3，输入为第一步的输出和x</1></2></li>
<li>不仅仅 是第二个单词有最大的概率，而是第一个、第二个单词对有最大的概率</li>
<li>$P(y^{<1>},y^{<2>}|x)=P(y^{<1>}|x)P(y^{<2>}|x, y^{<1>})$</1></2></1></2></1></li>
</ul>
</li>
<li>后面的步骤也是模仿第二步进行计算</li>
<li>重复第二步，选择第一步中的其他词进行计算<img src="/2018/12/06/dl/第五门课-第三周/resources/09E08ACC8EC0182CF63C63DD96E9F0EC.jpg">
<img src="/2018/12/06/dl/第五门课-第三周/resources/D81DFB526C95CD2E4362B500F8E26472.jpg"></li>
<li>可以看见，如果集束宽为1，那么其实就是贪心算法</li>
</ul>
</li>
<li><p>改进集束搜索</p>
<ul>
<li><p>问题1：$P(y^{<1>}|x)P(y^{<2>}|x, y^{<1>})$…..由于每一步概率值都小于0，所以比容易造成数值下溢，也就是导致电脑的浮点表示不能精确的存储</1></2></1></p>
<ul>
<li>解决方案：<br>我们总是记录概率的对数和，而不是概率的乘积，就用到了对数函数乘积的性质<img src="/2018/12/06/dl/第五门课-第三周/resources/A0E79789CBD92DE575602B479DAD35D3.jpg">
</li>
</ul>
</li>
<li><p>问题2：由于每一项乘积都小于1，并且目标函数是最大概率的输出，所以一般会偏向于比较短的句子，这样乘积项就比较少</p>
<ul>
<li>解决方案：<br>通过除以翻译结果的单词数量。这样就是取每个单词的概率对数值的平均了，这样很明显地 减少了对输出长的结果的惩罚</li>
</ul>
</li>
<li><p>更柔和的方法：并不直接除以单词数，而是会乘上一个超参数a,比如a=0.7，如果a=1那么就相当于完全用长度来做归一化</p>
</li>
<li><p>集束宽选择<br>集束宽越大效果当然越好，但是计算也越复杂。在产品中，经常可以看到把束宽设到 10</p>
</li>
</ul>
</li>
</ul>
<h4 id="集束搜索误差分析"><a href="#集束搜索误差分析" class="headerlink" title="集束搜索误差分析"></a>集束搜索误差分析</h4><h4 id="Bleu得分"><a href="#Bleu得分" class="headerlink" title="Bleu得分"></a>Bleu得分</h4><ul>
<li>背景：比如机器翻译会得到很多都不错的答案，那么如何选择呢？Bleu得分算法，就是解决这个问题，它做的是；给定一个机器生成的翻译，能够自动地计算一个分数来衡量好坏</li>
</ul>
<h4 id="注意力模型"><a href="#注意力模型" class="headerlink" title="注意力模型"></a>注意力模型</h4><ul>
<li>背景：从Bleu评分可以看出，长句的效果比较差<img src="/2018/12/06/dl/第五门课-第三周/resources/37CDD1E8D8F3D180CB8C734953DD30E0.jpg"></li>
<li><font color="blue">原理：模仿人工翻译，不会一次性把整个文章都读完再翻译，会读一部分内容，翻译一部分</font><ul>
<li>下层的双向LSTM就是先跑所有的法语单词，然后形成context，看具体时间步的注意力需要多少前后关注做准备</li>
</ul>
</li>
<li>理解：在计算当前时间步的时候，会花多少精力去关注多少当前词附近的词语<ul>
<li>这些是注意力权重，即$a^{&lt;t,t’&gt;}$告诉你，当你尝试生成第𝑡个英文词，它应该花多少注意力在第𝑡个法语词上面。当生成一个 特定的英文词时，这允许它在每个时间步去看周围词距内的法语词要花多少注意力<img src="/2018/12/06/dl/第五门课-第三周/resources/EEBE423431B34A94171A26BDFA7882A4.jpg"></li>
</ul>
</li>
<li><p>编程练习：</p>
<ul>
<li>将人工理解(Tuesday 09 Oct 1993)的日期翻译为机器理解的日期(1993-10-09)</li>
<li>这里前一个时间步的输出不用喂给后一个输入，并不像前面练习的恐龙名字一样，前后两个单词是有关联的</li>
<li>在训练过程中，每一个时间步的注意力长度是不一样的<img src="/2018/12/06/dl/第五门课-第三周/resources/691EABB718941C596A7B2C25AF3B853D.jpg"></li>
<li><p>model：<br>总体分为2步，1：右边，one “Attention”如何计算,2:左边，整体的attention模型<br>In this part, you will implement the attention mechanism presented in the lecture videos. Here is a figure to remind you how the model works. The diagram on the left shows the attention model. The diagram on the right shows what one “Attention” step does to calculate the attention variables $\alpha^{\langle t, t’ \rangle}$, which are used to compute the context variable $context^{\langle t \rangle}$ for each timestep in the output ($t=1, \ldots, T_y$).</p>
<img src="/2018/12/06/dl/第五门课-第三周/resources/2868A3ED41699CAA4210EAF9E26E0328.jpg">
<p>Here are some properties of the model that you may notice: </p>
<ul>
<li><p>模型分两个LSTM层，下面一个双向LSTM根据前向后向计算的激活值a，然后匹配上各个时间步的注意力的长度，产出context，第二层LSTM是用context和前一个时间步的输出$S^{&lt; t-1 &gt;}$输出最终值<br>There are two separate LSTMs in this model (see diagram on the left). Because the one at the bottom of the picture is a Bi-directional LSTM and comes <em>before</em> the attention mechanism, we will call it <em>pre-attention</em> Bi-LSTM. The LSTM at the top of the diagram comes <em>after</em> the attention mechanism, so we will call it the <em>post-attention</em> LSTM. The pre-attention Bi-LSTM goes through $T_x$ time steps; the post-attention LSTM goes through $T_y$ time steps. </p>
</li>
<li><p>The post-attention LSTM passes $s^{\langle t \rangle}, c^{\langle t \rangle}$ from one time step to the next. In the lecture videos, we were using only a basic RNN for the post-activation sequence model, so the state captured by the RNN output activations $s^{\langle t\rangle}$. But since we are using an LSTM here, the LSTM has both the output activation $s^{\langle t\rangle}$ and the hidden cell state $c^{\langle t\rangle}$. However, unlike previous text generation examples (such as Dinosaurus in week 1), in this model the post-activation LSTM at time $t$ does will not take the specific generated $y^{\langle t-1 \rangle}$ as input; it only takes $s^{\langle t\rangle}$ and $c^{\langle t\rangle}$ as input. We have designed the model this way, because (unlike language generation where adjacent characters are highly correlated) there isn’t as strong a dependency between the previous character and the next character in a YYYY-MM-DD date. </p>
</li>
<li><p>We use $a^{\langle t \rangle} = [\overrightarrow{a}^{\langle t \rangle}; \overleftarrow{a}^{\langle t \rangle}]$ to represent the concatenation of the activations of both the forward-direction and backward-directions of the pre-attention Bi-LSTM. </p>
</li>
<li><p>The diagram on the right uses a <code>RepeatVector</code> node to copy $s^{\langle t-1 \rangle}$’s value $T_x$ times, and then <code>Concatenation</code> to concatenate $s^{\langle t-1 \rangle}$ and $a^{\langle t \rangle}$ to compute $e^{\langle t, t’}$, which is then passed through a softmax to compute $\alpha^{\langle t, t’ \rangle}$. We’ll explain how to use <code>RepeatVector</code> and <code>Concatenation</code> in Keras below. </p>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<h4 id="语音模型"><a href="#语音模型" class="headerlink" title="语音模型"></a>语音模型</h4><ul>
<li>CTC cost<ul>
<li>背景：很多时候语音输入比输出会多很多，如何在RNN中相同输入输出的模型中使用呢？</li>
<li>CTC 损失函数的一个基本规则是 将空白符之间的重复的字符折叠起来，再说清楚一些，我这里用下划线来表示这个特殊的空 白符(a special blank character)，这样就可以让输出和输入相同数量了</li>
</ul>
</li>
</ul>
<h4 id="触发字检测"><a href="#触发字检测" class="headerlink" title="触发字检测"></a>触发字检测</h4><ul>
<li>生谱图特征得到特征向量$x^{<1>},x^{<2>,…}$</2></1></li>
<li>训练集如何标注：检测到关键词的以后就标注为1，未检测到就标注为0<img src="/2018/12/06/dl/第五门课-第三周/resources/EBCF128EB7F18F6FFFC673EA682EAFE1.jpg"></li>
<li>问题：这样导致0和1的数量很不平衡，简单的处理方式：比 起只在一个时间步上去输出 1，其实你可以在输出变回 0 之前，多次输出 1，或说在固定的 一段时间内输出多个 1</li>
<li>练习题：<ul>
<li>网络架构<img src="/2018/12/06/dl/第五门课-第三周/resources/3927A66C61616AB5B8F15E0F82790B80.jpg"></li>
<li>首先通过生谱图将声音转换为特征向量</li>
<li>然后开始使用了CNN，使5511时间步减小到1375，这个在RNN中大量减小了复杂大</li>
<li>然后用两层RNN，进行0，1预测输出，注意并没有使用双向RNN，因为语音说完就要快速给出结果，并不是等10s说完后才给</li>
<li>Here’s what you should remember:<ul>
<li>Data synthesis is an effective way to create a large training set for speech problems, specifically trigger word detection. </li>
<li>Using a spectrogram and optionally a 1D conv layer is a common pre-processing step prior to passing audio data to an RNN, GRU or LSTM.</li>
<li>An end-to-end deep learning approach can be used to built a very effective trigger word detection system. </li>
</ul>
</li>
</ul>
</li>
</ul>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


	
    
	
      	    

  

  
  
  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/12/01/dl/第五门课-第二周/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="雷哥">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/favicon.ico">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="雷哥的博客">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/12/01/dl/第五门课-第二周/" itemprop="url">第五门课-第二周</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-12-01T18:37:09+08:00">
                2018-12-01
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing">
                  <a href="/categories/深度学习/" itemprop="url" rel="index">
                    <span itemprop="name">深度学习</span>
                  </a>
                </span>

                
                
                  ， 
                
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing">
                  <a href="/categories/深度学习/吴恩达课程总结/" itemprop="url" rel="index">
                    <span itemprop="name">吴恩达课程总结</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p><a href="https://github.com/yuancl/dl-algorithm/tree/master/5-RecurrentNeuralNetworks/Week2" target="_blank" rel="noopener">习题代码:Operations-on-word- vectors</a></p>
<h4 id="词嵌入"><a href="#词嵌入" class="headerlink" title="词嵌入"></a>词嵌入</h4><ul>
<li>背景：one-hot的方式不能表示相近词之间的相似度，比如用语言模型得到 i want a glass of orange juice,如果换成 i want a glass of apple …，  如果是one-hot就不能得到好的结果</li>
<li>原因：one-hot向量通常只有一位为非0，所以它们之间的内积为0，多维空间表示就是垂直的，没有相关性</li>
<li>词嵌入：把之前的10000+维度的one-hot转换为300维的相关特征，把该词嵌入300维的空间中<img src="/2018/12/01/dl/第五门课-第二周/resources/C41732C6B42FCD3CC1C0DF349DDA0403.jpg">
<img src="/2018/12/01/dl/第五门课-第二周/resources/A21F2659F855954FA841C05F9E5F0FB7.jpg"></li>
<li>t-SNE算法，将多维空间映射到2为空间中，如上图左图</li>
</ul>
<h4 id="使用词嵌入-命名实体识别"><a href="#使用词嵌入-命名实体识别" class="headerlink" title="使用词嵌入(命名实体识别)"></a>使用词嵌入(命名实体识别)</h4><ul>
<li>背景：Robert Lin is an apple farmer 与 Robert Lin is a durian cultivator(Robert Lin 是一个榴莲培育家)榴莲培育家训练样本很少包含该词，很可能不能做到命名实体的识别</li>
<li>词嵌入做迁移学习优点及步骤<ul>
<li>泛化性比较好</li>
<li>先从大量的文本集中学习词嵌入。一个非常大的文本集，这个可以解决你的训练样本比较少，比如根本没有durian(榴莲)这个词汇的训练样本</li>
<li>你可以用这些词嵌入模型把它迁移到你的新的只有少量标注训练集的任务中，比如说用这个300维的词嵌入来表示你的单词，比one-hot更低维</li>
<li>是否进行微调？如果你有大量的训练数据集可以考虑微调已有的嵌入词</li>
<li>通常迁移任务 A-&gt;B，通常是A中有大量数据集，B中只有少量数据集这种情况效果比较好<ul>
<li>比如在机器翻译领域词嵌入用得比较少，原因就是我们有大量的翻译样本</li>
</ul>
</li>
</ul>
</li>
<li>词嵌入和人脸编码类比<ul>
<li>相同点，都是通俗理解都是通过编码，得到标识一个物体的唯一向量</li>
<li>不同点，词嵌入是固定的词汇，而人脸编码是给定任意的图片都可以进行编码<img src="/2018/12/01/dl/第五门课-第二周/resources/DA8D7754F10BE0DAA530258811F9AC1E.jpg">
</li>
</ul>
</li>
</ul>
<h4 id="词嵌入的特性"><a href="#词嵌入的特性" class="headerlink" title="词嵌入的特性"></a>词嵌入的特性</h4><ul>
<li>类比推理<ul>
<li>解决问题：man对应woman，那么king对应什么？</li>
<li>目标函数：$e_{man}-e_{woman}\approx e_{king}-e_?$,也就是Find work w：argmax sim($e_w, e_{king}-e_{man}+e_{woman}$)</li>
<li>实现算法：<ul>
<li>该场景的四个词如果映射为二维空间，一般会是平行四边形，通常只有一维数据有一定差异<img src="/2018/12/01/dl/第五门课-第二周/resources/52B643F271BBA6B8880FF8C6499D3894.jpg"></li>
<li>余弦相识度：<ul>
<li>公式：sim(u,v)=$\frac{u^T*v}{||u||_2||v||_2}$=cos($\theta$)</li>
<li>理解：两个向量之间的角度的余弦是衡量它们有多相似的指标，这里就是衡量两个词嵌入向量的相似度<img src="/2018/12/01/dl/第五门课-第二周/resources/CAD5599965AB00A4C6BFCD3BBFC387F5.jpg">
</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<h4 id="嵌入矩阵-Embedding-Matrix"><a href="#嵌入矩阵-Embedding-Matrix" class="headerlink" title="嵌入矩阵(Embedding Matrix)"></a>嵌入矩阵(Embedding Matrix)</h4><ul>
<li>当你应用算法来学习词嵌入时，实际上是学习一个嵌入矩阵，我们的目标就是学习一个嵌入矩阵E</li>
<li>有了嵌入矩阵，然后乘以one-hot向量，就能够得到$E*o_j=e_j$,$e_j$就是表示我们想要的词嵌入</li>
<li>但实践中一般不会$E*o_j=e_j$,$e_j$这样计算，一般会有一个专门的函数来单独查找矩阵E的某列<img src="/2018/12/01/dl/第五门课-第二周/resources/C6433150B98AB53156F78848934AB4F2.jpg">
</li>
</ul>
<h4 id="学习词嵌入"><a href="#学习词嵌入" class="headerlink" title="学习词嵌入"></a>学习词嵌入</h4><p>建立一个语言模型是学习词嵌入的好方法</p>
<ul>
<li>方法1：<br>$Eo_j=e_j$使用这种方法来学习词嵌入矩阵，训练集中有很多序列语句，然后放入神经网络中，来学习E，这种方法比较复杂，最后会有1800维300*6的向量进入隐藏层，然后进入10000维的softmax层<img src="/2018/12/01/dl/第五门课-第二周/resources/34DABF58D294A16191D22C8DED48AEBB.jpg"></li>
<li>方法2(采用固定窗口)：<br>只取前4个词(作为一个窗口)来训练，用一个固定的历史窗口就意味着你可以处理任意长度的句子，因为输入的维度(1200)总是固定的<img src="/2018/12/01/dl/第五门课-第二周/resources/97D2B0D30C4C77C50ADF9A5BB86C1C70.jpg"></li>
<li>方法3(前后数量不固定)<br>可以前后个4个词，<br>或者就附件一个词等(Skip-Gram思想)…<img src="/2018/12/01/dl/第五门课-第二周/resources/74CF627BF0907DB5F4DD4F0A47FC905E.jpg"></li>
<li>总结：<br>如果你真想<font color="red">建立一个语言模型</font>，用目标词的前几个单词作为上下文是常见做法(上图编号9所示)。但如果你的<font color="red">目标是学习词嵌入</font>，那么你就可以用这些其他类型的上下文(上图编号10所示)，它们也能得到很好的词嵌入</li>
</ul>
<h4 id="Word2Vec"><a href="#Word2Vec" class="headerlink" title="Word2Vec"></a>Word2Vec</h4><p>上面都是讲的通过学习一个神经语言模型来得到更好的词嵌入，而<br>Word2Vec是更简单高效的方式来学习这种类型的嵌入</p>
<ul>
<li><p>Skip-Gram</p>
<ul>
<li>在 Skip-Gram模型中，我们要做的是抽取上下文和目标词配对，来构造一个<font color="red">监督学习问题</font><ul>
<li>但是构造这个监督学习问题的目标并不是想要解决这个监督学习问题本身，而是想要使用这个学习问题来学到一个好的词嵌入模型<font color="red">(构建一个监督学习问题，实际想解决学习嵌入词模型)</font></li>
</ul>
</li>
<li>步骤：我们随机选择一个词作为上下文c，然后在随机抽取一个词作为target y<font color="purple">(随机选择y，我理解只是重点强调这个算法本身，实际情况如果要训练得到一个好的词嵌入，必然是不能随机的，是需要选真实的y)</font>，然后就是建立x(c)–&gt;y的映射<ul>
<li>c和E相乘，得到c的词嵌入向量，然后此向量通过softmax进行预测，最后和target建立Loss function来达到学习E的目的</li>
</ul>
</li>
<li>softmax模型，预测不同目标词的概率:softmax:p(t|c)=$\frac{e^{\theta^{T}_{t}e_c}}{\sum^{10,000}_{j=1}e^{\theta{^T_je_c}}}$输出是10000(词典中单词数量)为的向量<ul>
<li>$\theta_t$是一个与输出t有关的参数，即某个词t和标签相符的概率是多少</li>
</ul>
</li>
<li>softmax损失函数：$L(\hat y,y)=-\sum^{10,000}_{i=1}y_ilog\hat y_i$ <font color="red">其中y是one-hot向量，$\hat y$是10.000维的各个词的预测输出概率</font><ul>
<li><font color="red">这是softmax常有的损失模型</font>，$\hat y$是各个分类的概率，可以画一下log函数图形来理解该损失函数，如果$\hat y_i$为1，也就是第i个分类为概率为1，这个时候$L(\hat y,y)$就为0，损失值最小</li>
<li><font color="red">直观理解损失函数</font>：<font color="blue">就是y和$\hat y$都是10000维的，Loss计算就是分别将这两个向量做”内积”，要使”内积”最小，假设第i维，$y_i=1$这个时候softmax的输出$\hat y_i=1$-&gt;$\log\hat y_i=0$(就是所第i维也正是softmax输出最大的分类的概率)-&gt;$y_i\log\hat y_i=0$-&gt;Loss最小</font></li>
</ul>
</li>
<li>缺点(problem)：<br>在 softmax 模型中，每次你想要计算这个概率，你需要对你词汇表中的所有 10,000 个词做求和计算</li>
<li>优化方案：<ul>
<li>分级softmax分类器：不用一下子告诉属于10,000类中的哪一类，可以先告诉属于左边的5000中的一类还是右边5000中的，然后是2500….,这样来构造一颗分类树<img src="/2018/12/01/dl/第五门课-第二周/resources/95F9428AAE4FEA373515DBC5F8A622B8.jpg">
</li>
</ul>
</li>
</ul>
</li>
<li><p>CBOW模型</p>
<ul>
<li>不同版本的 Word2Vec模型，Skip-Gram只是其中的一个，另一个叫做 CBOW，即连续词袋模型(Continuous Bag-Of-Words Model)，它获得中间词两边的的上下 文，然后用周围的词去预测中间的词</li>
<li><font color="red">CBOW 是从原始语句推测目标字词;而Skip-Gram正好相反，是从目标字词推 测出原始语句</font></li>
<li>CBOW对小型数据库比较合适，而Skip-Gram在大型语料中表现更好<img src="/2018/12/01/dl/第五门课-第二周/resources/FF2E1F1A0F94A8221B8B801595C6D5EC.jpg">
</li>
</ul>
</li>
<li><p>负采样(Negative Sampling)</p>
<ul>
<li>背景：之前的softmax分类器中，解决每次都要计算所有样本的问题</li>
<li>Model：选择一个正样本和K个负样本，将softmax的分类转化为一系列二分类问题，只计算其中的正负样本的二分类问题<ul>
<li>正负样本作为输入x，然后用$P(y=1|c,t)=sigmoid(\theta^T_te_c)$进行二分类计算<img src="/2018/12/01/dl/第五门课-第二周/resources/7D0E816C9C5C70572D286ADC59924886.jpg"></li>
</ul>
</li>
<li>负样本k的选取<ul>
<li>语库中的经验频率进行采样，这种会有很多like，the等高频词出现</li>
<li>另一个极端就是1除以词汇表总词数，均匀的抽取样本，但这样对英语单词的分布是没有代表性的</li>
<li>采用一种处于完全独立分布和训练集的观测分布两个极端之间<img src="/2018/12/01/dl/第五门课-第二周/resources/5A531D6FD207171B174D364AF500C77F.jpg">
</li>
</ul>
</li>
</ul>
</li>
</ul>
<h4 id="Glove-Glove-word-vectors"><a href="#Glove-Glove-word-vectors" class="headerlink" title="Glove(Glove word vectors)"></a>Glove(Glove word vectors)</h4><ul>
<li>定义：定义上下文和目标词为任意两个位置相近的单词，假设是左右各 10 词的距离，那么$X_{ij}$就是一个能够获取单词𝑖和单词𝑗出现位置相近时或是彼此接近的频率的计数器。</li>
<li>Glove模型就是进行优化，将他们之间的差距最小化处理<ul>
<li><font color="blue">就是通过一种优化方法，对目前方程进行优化，从而间接学习到词嵌入矩阵</font><img src="/2018/12/01/dl/第五门课-第二周/resources/E4BFB45184A8FE9F410D8920BDD53ED4.jpg"></li>
</ul>
</li>
<li>函数f选择原则：对加权函数f的选择有着启发性的原则，就是既不给这些词(this，is，of，a)过分的权重，也不给这些不常用词(durion)太小的权值</li>
<li>问题：<ul>
<li>你不能保证嵌入向量的独立组成部分是能够理解的</li>
<li>你不能保证这些用来表示特征的轴能够等同于人类可能简单理解的轴，具体而言，第一个特征 可能是个Gender、Roya、Age、Food Cost 和 Size的组合<font color="red">(并不是我们所理解的单纯的Gender维)</font>，它也许是名词或是一个行为动词 和其他所有特征的组合，所以很难看出独立组成部分<img src="/2018/12/01/dl/第五门课-第二周/resources/31256B83B3F1A2CF14D942BFECB3ADFB.jpg">
</li>
</ul>
</li>
</ul>
<h4 id="情感分类"><a href="#情感分类" class="headerlink" title="情感分类"></a>情感分类</h4><ul>
<li>定义：情感分类任务就是看一段文本，然后分辨这个人是否喜欢他们在讨论的这个东西</li>
<li>简单模型：采用的是平均值单元，适合任意长度的评论<ul>
<li><font color="blue">重点理解词嵌入应用的思想：将单词通过词嵌入矩阵得到词嵌入，简单理解为将字符或者是单词映射为数值的一种方法，然后使用End-to-End思想，通过softmax就直接预测输出</font><img src="/2018/12/01/dl/第五门课-第二周/resources/3769B484BF94E06ABF4038346AA63078.jpg"></li>
<li>问题：没有考虑词序，<font color="red">因为均值模型就是把各个单词各个维数值相加然后再平均</font><ul>
<li>比如not good,或者 good…not ,就不能区分了</li>
</ul>
</li>
</ul>
</li>
<li>RNN模型解决词序问题 <ul>
<li>此模型是一个one-many的模型<ul>
<li><font color="blue">直观理解就是，RNN本身就是有一个词一个词有顺序的输入，上一个词对下一个词有影响，所以就能够反映词序问题</font><img src="/2018/12/01/dl/第五门课-第二周/resources/62FD68B5D4C30C44B61209A772F5BD86.jpg">
</li>
</ul>
</li>
</ul>
</li>
</ul>
<h4 id="词嵌入除偏"><a href="#词嵌入除偏" class="headerlink" title="词嵌入除偏"></a>词嵌入除偏</h4><ul>
<li>定义：比如通过词嵌入，Man:Computer Programmer， 同时输出 Woman:Homemaker</li>
<li><font color="blue">解决方法：主要是在词向量中寻找出哪些维度的偏见相关的维度(bias axis)，然后在这些维度上进行调整</font></li>
<li><font color="blue">重点理解：单词到词向量的映射，实际上就是映射到n维空间(n为词向量矩阵)中的一个点,然后看点与点之间的距离来判断词与词之间的相似度</font></li>
<li><p><font color="red">达到目的：让无性别的词到有性别的词的点的距离是相等的,比如Computer Programmer,doctor分别到man,woman的距离是相等的</font></p>
<ul>
<li>找出偏见趋势<ul>
<li>确定哪些轴(哪些维度)，对于性别歧视这种情况来说，我们能做的是$e_{he} − e_{she}$，因为它们的性别不同，然后 将$e_{male}−e_{female}$，然后将这些值取平均(上图编号2所示)，将这些差简单地求平均。这个趋势(上图编号3所示)看起来就是性别趋势或说是偏见趋势<ul>
<li>non bias就是垂直于偏见轴的方向<img src="/2018/12/01/dl/第五门课-第二周/resources/FE259E9589DE8B2F3259660CB076E522.jpg"></li>
</ul>
</li>
</ul>
</li>
<li><p>中和步骤：某些无性别歧视的词语，让他们在non bias轴上进行靠拢，尽量减少映射在bias轴上的距离来减少性别歧视问题</p>
<ul>
<li>比如Computer Programmer,doctor应该是无性别关系的，所以应该尽量靠近non bias轴，<font color="blue">这样的理想效果就是到达空间中man和woman的点距离是相等的</font><img src="/2018/12/01/dl/第五门课-第二周/resources/761E18C6CBBE247CE32CCD5CE15F5E54.jpg">
</li>
</ul>
</li>
<li><p>均衡步：<br>让有偏见的词进行，移动与中轴线等距的一些点上，这样让它们在bias轴上都有一致的相似度，图中由1移到图2的两点</p>
<ul>
<li><font color="blue">直观理解：也是为了让无偏见词，比如上面说的Computer Programmer,doctor达到分性别关系的词man,woman距离相等</font><img src="/2018/12/01/dl/第五门课-第二周/resources/18EA7A252EAD3B3F90796A808AAAC7F5.jpg">
<ul>
<li>经过统计这种偏见词实际上是很少的，需要均衡的词是很少的</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


	
    
	
    
	
      	    

  

  
  
  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/11/27/dl/第五门课-第一周/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="雷哥">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/favicon.ico">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="雷哥的博客">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/11/27/dl/第五门课-第一周/" itemprop="url">第五门课-第一周</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-11-27T08:37:09+08:00">
                2018-11-27
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing">
                  <a href="/categories/深度学习/" itemprop="url" rel="index">
                    <span itemprop="name">深度学习</span>
                  </a>
                </span>

                
                
                  ， 
                
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing">
                  <a href="/categories/深度学习/吴恩达课程总结/" itemprop="url" rel="index">
                    <span itemprop="name">吴恩达课程总结</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>[习题练习]<br><a href="https://github.com/yuancl/dl-algorithm/commit/76c81b18acdc941663d3c59cced76bf837384958" target="_blank" rel="noopener">Building+a+Recurrent+Neural+Network+-+Step+by+Step,主要讲是一步一步构建RNN基础网络和LSTM网络，理解运作原</a><br><a href="https://github.com/yuancl/dl-algorithm/tree/master/5-RecurrentNeuralNetworks/Week1/dinosaurus-island" target="_blank" rel="noopener">dinosaurus-island(character-level language model,练习使用基础RNN模型或者LSTM模型，学习一些文本，然后生成新的文)</a><br><a href="https://github.com/yuancl/dl-algorithm/tree/master/5-RecurrentNeuralNetworks/Week1/Jazz-improvisation-with-LSTM" target="_blank" rel="noopener">Improvise-music with an LSTM network,主要使用LSTM网络生成音</a></p>
<h3 id="循环神经网络基础"><a href="#循环神经网络基础" class="headerlink" title="循环神经网络基础"></a>循环神经网络基础</h3><h4 id="RNN背景"><a href="#RNN背景" class="headerlink" title="RNN背景"></a>RNN背景</h4><ul>
<li>什么是序列问题？<br>比如语音识别，输入是一段音频，要求输出是一段文字Y。或者情感分析，输入评论，要求输出几颗星等。本质输入都是一段序列内容，其实就是X-&gt;Y的映射问题</li>
<li>序列问题特点？<br>可以看见，有些序列问题X,Y长度一致，有些不一致…</li>
<li>为什么不用标准神经网络处理序列问题：<ul>
<li>输入输出不定长</li>
<li>序列上一些位置已经学到的文本信息内容不能在其他位置共享<ul>
<li>比如如果神经网络已经学习到了在位置 1 出现的 Harry 可能是人名的一部分，那么如果 Harry 出现在其他位置，比如$x^{&lt; t &gt;}$时，它也能够<font color="blue">自动识别其为人名的一部分的话</font>，这就很棒了。这可能类似于你在卷积神经网络中看到的,<font color="red">你希望将部分图片里学到的内容快速推广到图片的其他部分</font>，而我们希望对序列数据也有相似的效果。和你在卷积网络中学到的类似，用一个更好的表达方式也能够让你减少模型中参数的数量</li>
<li>RNN传递一个激活值到下一个时间步中进行计算，所以能够解决这个问题，适用于序列问题<img src="/2018/11/27/dl/第五门课-第一周/resources/5E6CE23C6A2573459E4A0E31A919B9B9.jpg"></li>
</ul>
</li>
</ul>
</li>
<li>注意项：<ul>
<li>$a^{<0>}$通常使用零向量作为零时刻的伪激活值</0></li>
<li>注意多种不同的参数$W_{ax},W_{aa},W_{ya}$<img src="/2018/11/27/dl/第五门课-第一周/resources/EE130B0446706C75A520D2DA216849A0.jpg">
</li>
</ul>
</li>
</ul>
<h4 id="前向后向计算"><a href="#前向后向计算" class="headerlink" title="前向后向计算"></a>前向后向计算</h4><ul>
<li>RNN cell<img src="/2018/11/27/dl/第五门课-第一周/resources/E522B44F0437902AC27802C6327A1E05.jpg"></li>
<li><p>前向传播</p>
<ul>
<li>t时刻：<br>$a^{&lt; t &gt;}=g_1(W_{aa}a^{t-1} + W_{ax}x^{t} + b_a)$<br>$\hat y^{t} = g_2(W_{ya}a^{&lt; t &gt;} + b_y)$</li>
<li>激活函数通常使用tanh，y输出激活函数视情况而定<img src="/2018/11/27/dl/第五门课-第一周/resources/65006F27B61C583E368EE798ADB80414.jpg">
</li>
</ul>
</li>
<li><p>后向传播</p>
<ul>
<li>对于一个元素的损失函数：<br>$L^{&lt; t &gt;}(\hat y^{&lt; t &gt;},y^{t}) = -y^{&lt; t &gt;}log\hat y^{&lt; t &gt;} - (1-y^{&lt; t &gt;})log(1-\hat y^{&lt; t &gt;})$</li>
<li>整体序列的损失函数，就是将各时间步的损失值函数相加<br>$L(\hat y,y) = \sum_{t-1}^{T_x}L^{&lt; t &gt;}(\hat y^{&lt; t &gt;},y^{t})$<img src="/2018/11/27/dl/第五门课-第一周/resources/4D96ADA1B3420E7CC0849AA6FC92D737.jpg"></li>
<li>同样也是使用bp算法求偏导，进行后向计算，不用的是RNN会有多个输出$\hat y$<img src="/2018/11/27/dl/第五门课-第一周/resources/B12CDA828E7D580472ABDA550A3FA40A.jpg">
</li>
</ul>
</li>
</ul>
<h4 id="不同类型的RNN"><a href="#不同类型的RNN" class="headerlink" title="不同类型的RNN"></a>不同类型的RNN</h4><ul>
<li>输入输出长度分类：<ul>
<li>many-to-many：机器翻译</li>
<li>many-to-one：情感分类</li>
<li>one-to-one：小型标准神经网络<img src="/2018/11/27/dl/第五门课-第一周/resources/9865F55A9CD63F0A3BAFBC9F28380036.jpg"></li>
<li>one-to-many：音乐作曲<img src="/2018/11/27/dl/第五门课-第一周/resources/23C80D48C0008D0B3730BC7EE8A8A6E8.jpg">
</li>
</ul>
</li>
</ul>
<h4 id="语言模型和序列生成"><a href="#语言模型和序列生成" class="headerlink" title="语言模型和序列生成"></a>语言模型和序列生成</h4><ul>
<li><p>语言模型:语言模型就是它会告诉你某个特定的句子它出现的概率是多少</p>
<ul>
<li>语言模型做的最基本工作就是输入一个句子，准确地说是一个文本序列,然后语言模型会估计某个句子序列中各个单词出现的可能性。</li>
</ul>
</li>
<li><p>RNN模型基础结构</p>
<ul>
<li>将每个单词都转换成对应的one-hot向量，也就是词典中的索引，其中也要注意EOS(结尾符),UNK(未知单词),标点符号</li>
<li>每一层$\hat y$的输出，都是预测该层输入词在字典中出现的概率</li>
<li>最后的输出是每层条件概率的乘积<img src="/2018/11/27/dl/第五门课-第一周/resources/0499490A2E7A743A094E4A97B5DB3E28.jpg">
</li>
</ul>
</li>
</ul>
<h4 id="对新序列采样"><a href="#对新序列采样" class="headerlink" title="对新序列采样"></a>对新序列采样</h4><ul>
<li>作用：一个序列模型之后，要想了解到这个模型学到了什么，一种非正式的方法就是对新序列采样</li>
<li>方法：序列模型模拟了任意特定单词序列的概率，我们要做的就是对这些<font color="red">概率分布</font>进行采样来生成一个新的单词序列</li>
<li>如何结束：1.字典中有EOS，2.时间步的多少</li>
<li>基于词汇和字符的模型，各有优缺点</li>
</ul>
<h4 id="RNN中的梯度问题"><a href="#RNN中的梯度问题" class="headerlink" title="RNN中的梯度问题"></a>RNN中的梯度问题</h4><ul>
<li>梯度消失：<ul>
<li>网络的输出$\hat y$得到的梯度很难传播回去，很难影响靠前层的权重，很难影响前面层(编号 5 所示的层)的计算<img src="/2018/11/27/dl/第五门课-第一周/resources/81FC8B8F333615A20A24E065D6ED2A80.jpg"></li>
<li>基础RNN也同样存在这个问题：前一层名词的单复数和难影响到厚层的动词单复数，很难传递(也是因为输出很难传到前层)</li>
<li>如何解决：<font color="blue">看后面的GRU和LSTM</font></li>
</ul>
</li>
<li>梯度爆炸：<ul>
<li>比较容易发现，比如看见很多NaN，或者不是数字的情况，意味着数值溢出</li>
<li>解决方法：梯度修剪，就是观察你的梯度向量，如果它大于某个阈 值，缩放梯度向量，保证它不会太大，这就是通过一些最大值来修剪的方法，并且具有好的鲁棒性</li>
</ul>
</li>
</ul>
<h3 id="GRU-门控制单元"><a href="#GRU-门控制单元" class="headerlink" title="GRU(门控制单元)"></a>GRU(门控制单元)</h3><h4 id="基础"><a href="#基础" class="headerlink" title="基础"></a>基础</h4><ul>
<li>新增变量：记忆细胞cell<ul>
<li>计算逻辑：如下图3标记中，$\hat C^{&lt; t &gt;} = tanh(W_c[C^{&lt; t-1 &gt;}, x^{&lt; t &gt;}] + b_c)$</li>
<li>作用：提供了记忆的能力，比如说一只猫是单数还是复数，所以当它看到之后的句子的时候，它仍能够判断句子的主语是单数还是复数</li>
</ul>
</li>
<li>新增变量：门控制变量<ul>
<li>计算逻辑：如下图3标记中，$\Gamma _u^{&lt; t &gt;} = tanh(W_u[C^{&lt; t-1 &gt;}, x^{&lt; t &gt;}] + b_u)$</li>
<li>作用：决定什么更新记忆细胞，是由sigmoid激活，如果为1，才更新C值，所以前面层次的值就可以一直保持到后面<img src="/2018/11/27/dl/第五门课-第一周/resources/50749AC4B17773F4D8BC728B49BD2529.jpg"></li>
</ul>
</li>
<li><p>记忆细胞更新逻辑：<br>如下图5标记中,逻辑门为1才更新C值(或者接近1值，新值C的权重更大)<br>$C^{&lt; t &gt;} = \Gamma _u<em>\hat C^{&lt; t &gt;} + (1-\Gamma _u)</em> C^{&lt; t-1 &gt;}$</p>
</li>
<li><p>如何有效控制梯度消失问题<br>因为 sigmoid的值，现在因为门很容易取到 0 值，只要这个值是一个很大的负数, $\Gamma_u$值很容易为0，这种情况，就会变成$C^{&lt; t &gt;}=C^{&lt; t-1 &gt;}$，所以记忆细胞的值很好的被维持了。<font color="red">这就是缓解梯度消失的关键</font></p>
</li>
</ul>
<h4 id="其他"><a href="#其他" class="headerlink" title="其他"></a>其他</h4><ul>
<li>同时记忆细胞c可以是多维向量，这样可以记忆很多的内容</li>
<li>通过完成的GRU还会有一个相关门:这个相关门告诉你计算出的候选值$\hat C$和$C^{&lt; t-1 &gt;}$有多大的相关性</li>
<li>$\Gamma _r^{&lt; t &gt;} = tanh(W_r[C^{&lt; t-1 &gt;}, x^{&lt; t &gt;}] + b_r)$<img src="/2018/11/27/dl/第五门课-第一周/resources/FC1F67CE7DCFC22BF11941ED49367937.jpg">
</li>
</ul>
<h3 id="LSTM-Long-short-term-memory"><a href="#LSTM-Long-short-term-memory" class="headerlink" title="LSTM(Long short term memory)"></a>LSTM(Long short term memory)</h3><h4 id="基础-1"><a href="#基础-1" class="headerlink" title="基础"></a>基础</h4><ul>
<li>LSTM-cell<img src="/2018/11/27/dl/第五门课-第一周/resources/77E989F6FDDCB09EB5933E4BDEBA51EF.jpg"></li>
<li>遗忘门($\Gamma_f$)，让记忆细胞去选择更新新的候选值还是遗忘旧的值<br>$C^{&lt; t &gt;} = \Gamma_u<em>\hat C^{&lt; t &gt;} + (1-\Gamma_f)</em> C^{&lt; t-1 &gt;}$</li>
<li>输出门($\Gamma_o$), $a^{&lt; t &gt;} = \Gamma_o*tanh(c^{&lt; t &gt;})$</li>
<li><p>LSTM重要公式及前向传播：</p>
<img src="/2018/11/27/dl/第五门课-第一周/resources/30F5B97C5D3CB3434341F30985EE7EFB.jpg">  
</li>
<li><p>反向传播：就是BP算法，由后向前，对每一个参数求偏导数，对门$\Gamma$,参数W,偏置b，以及最后的隐藏状态，记忆细胞，输入x</p>
</li>
<li>GRU与LSTM<br>都能够捕获更加深层的神经网络，GRU的优点是比LSTM简单一点的模型，只有两个门，在计算上也运行得更快。但LSTM在历史上是更优的选择</li>
</ul>
<h3 id="双向RNN"><a href="#双向RNN" class="headerlink" title="双向RNN"></a>双向RNN</h3><ul>
<li>背景：有些场景不仅需要参考过去，还应该参考未来<img src="/2018/11/27/dl/第五门课-第一周/resources/7AFE741D0C96EA2412793884699E29E2.jpg">
<img src="/2018/11/27/dl/第五门课-第一周/resources/549D1FAC5CCCD530211F4855989CC5E3.jpg"></li>
<li>缺点：总数需要一段完整的内容<ul>
<li>NLP一般就比较适合，应该经常能够获得完整的文章</li>
<li>语音翻译等就不是很适合了，因为要获得已经完整的一段话语通常不是很现实</li>
</ul>
</li>
</ul>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


	
    
	
      	    

  

  
  
  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/11/26/dl/第四门课-第四周/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="雷哥">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/favicon.ico">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="雷哥的博客">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/11/26/dl/第四门课-第四周/" itemprop="url">第四门课-第四周</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-11-26T08:37:09+08:00">
                2018-11-26
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing">
                  <a href="/categories/深度学习/" itemprop="url" rel="index">
                    <span itemprop="name">深度学习</span>
                  </a>
                </span>

                
                
                  ， 
                
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing">
                  <a href="/categories/深度学习/吴恩达课程总结/" itemprop="url" rel="index">
                    <span itemprop="name">吴恩达课程总结</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p><a href="https://github.com/yuancl/dl-algorithm/tree/master/4-ConvolutionNeuralNetworks/Week4" target="_blank" rel="noopener">习题代码:Face-Recognition and Neural-Style-Transfer</a></p>
<h4 id="人脸识别-Siamese网络"><a href="#人脸识别-Siamese网络" class="headerlink" title="人脸识别(Siamese网络)"></a>人脸识别(Siamese网络)</h4><ul>
<li><p>一般分为验证和识别两步</p>
<img src="/2018/11/26/dl/第四门课-第四周/resources/59203AFA4B9EBA77787F62DF55CCD80C.jpg">
</li>
<li><p>One-shot learning</p>
<ul>
<li>背景：人脸识别的train是很少的图片，并且一般只给你一张图片你就得识别出来，并不是想普通的图片识别一样，有很多的样本。比如新加入的新同事，之前并没有样本</li>
<li>方法：和图片库已有的少量图片做相似度比较<img src="/2018/11/26/dl/第四门课-第四周/resources/D07A181DC5C9F521AD454FF2F5DB4806.jpg"></li>
<li><font color="blue">如何实现：可以使用Siamese network</font>
</li>
</ul>
</li>
<li><p>Siamese network</p>
<ul>
<li>将图片映射为n维向量，将$f(x^{(1)})$看做是$x^{(a)}$的编码，然后通过比较不同图片的编码的差别来区分是否是同一个人<img src="/2018/11/26/dl/第四门课-第四周/resources/2DAAF788ADC4B402DF7D4E839D3C9EB2.jpg"></li>
<li><font color="red">那么怎么判断输出的图片编码好与差呢？</font>可以使用下面的三元组(Triplet)损失函数达到目的</li>
</ul>
</li>
<li><p>Triplet损失 </p>
<ul>
<li>定义：需要Anchor图片，Postive图片，Negative图片，简写为A,P,N</li>
<li>避免网络输出无用,有一个$\alpha$超参数，控制A,P和A,N之间的差距<br>$||f(A)-f(P)||^2 - ||f(A)-f(N)||^2 + \alpha &lt;= 0$</li>
<li>Loss function<br>如果目标已经ok，那么值为0，<font color="blue">可以看见各种场景只需要找到合适的损失函数，然后下面的步骤都类似(用梯度下降等方法求出极值)</font><br>L(A,P,N)=max($||f(A)-f(P)||^2 - ||f(A)-f(N)||^2 + \alpha$, 0)</li>
<li>训练数据需要注意的地方   <ul>
<li>需要注意训练集的对一个人需要多张照片，至少要满足Anchor,Posistion</li>
<li>尽量选择d(A,P)$\approx$d(A,N),这样能够学习到更多内容，如果差别太大，很容易判断，不能学习到有效数据</li>
</ul>
</li>
<li>算法步骤：<ul>
<li><font color="red">目的，学习到一种好的编码映射f(x)</font></li>
<li>1.定义好A,P,N数据集</li>
<li>2.用梯度下降最小化我们之前定义的代价函数J<ul>
<li>这样做的效果就是用反向传播来学习到一种编码方式，如果是同一个人，那么d就很小，如果是不同的人，那么d就会很大</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<h4 id="面部识别与二分类-Siamese变种"><a href="#面部识别与二分类-Siamese变种" class="headerlink" title="面部识别与二分类(Siamese变种)"></a>面部识别与二分类(Siamese变种)</h4><ul>
<li>原始Siamese网络是直接计算编码的L2距离，这里可以将编码经过激活函数，比如sigmoid的处理，来实现分类的目的</li>
<li>$\hat y = sigmoid(\sum_{(k=1)}^{128}w_i|f(x^{(i)})_k - f(x^{(j)})_k|+b)$,当然$|f(x^{(i)})_k - f(x^{(j)})_k|$这一部分还可以替换为其他的相似度计算方法，比如$\chi$平方相似度</li>
<li>还注意下它的输入为成对图片的输入，比如两张同一个人的照片，输出为1。两种不同人的照片，输出就为0<img src="/2018/11/26/dl/第四门课-第四周/resources/DC9EB83890ACAA8FCA96AF8A07C166A4.jpg">
</li>
</ul>
<h4 id="神经风格转换"><a href="#神经风格转换" class="headerlink" title="神经风格转换"></a>神经风格转换</h4><ul>
<li>什么是神经风格转换<img src="/2018/11/26/dl/第四门课-第四周/resources/A479680115E29544AEF55839D4671529.jpg"></li>
<li>什么是深度卷积网络<font color="red">(需要直观感受到不同层次的网络提取的特征,深层和前层是如何计算的)</font><ul>
<li>相关概念<ul>
<li><font color="red">一个神经元就表示一个filter的及输出，在输出中就表示一个通道，也代表一个特征</font>，经常会有多个通道，就是多种filter，代表不同的特征</li>
<li>神经单元激活最大化，比如激活函数是sigmoid，我理解只有在边界两端的值，才能有更明确的分类结果，相应的特征表现也最好</li>
</ul>
</li>
<li>各层的特征<ul>
<li>第一层：主要表现对一些线条，边缘或者特点的颜色等低维特征比较感兴趣<img src="/2018/11/26/dl/第四门课-第四周/resources/4EB5702B957B35A026CF83308BB2ADD1.jpg"></li>
<li>第二层：通常能够看到图片更大的区域，能够检测到更复杂的模型<img src="/2018/11/26/dl/第四门课-第四周/resources/B0FF90770CA0E83194E5F21A951F11DE.jpg"></li>
<li>后面的第三层，第四层….等就能够检测到更具体的事物了<img src="/2018/11/26/dl/第四门课-第四周/resources/B887BCA060D13B6570ADED0664D12697.jpg">
<img src="/2018/11/26/dl/第四门课-第四周/resources/9C880AA1D1D811C893B543198F80C5FA.jpg">
</li>
</ul>
</li>
</ul>
</li>
</ul>
<h4 id="神经风格迁移系统的-Cost-function"><a href="#神经风格迁移系统的-Cost-function" class="headerlink" title="神经风格迁移系统的(Cost function)"></a>神经风格迁移系统的(Cost function)</h4><p>要构造一个神经风格迁移系统，我们需要给生成的图像定义一个代价函数</p>
<ul>
<li>J(G)=$\alpha J_{content}(C,G) + \beta J_{stype}(S,G)$</li>
<li>内容代价函数:<font color="red">就是计算原始图片和生成图片的某一层的激活值的相似度</font><ul>
<li>选取一个预训练模型，比如是VGG卷积模型</li>
<li>选取中间层l，一般不会太深，也不好太浅</li>
<li>计算一对一对的训练数据(一张原始图片，一张生成图片)，分别计算在l层的激活值，然后对比他们的相似度(可以用L2范数)</li>
<li>$J_{content}(C,G)=\frac{1}{2}||a^{[l][C]}-a^{[l][G]}||^2$</li>
</ul>
</li>
<li>下面是风格代价函数的介绍</li>
<li><strong>What you should remember</strong>:<ul>
<li>Neural Style Transfer is an algorithm that given a content image C and a style image S can generate an artistic image</li>
<li>It uses representations (hidden layer activations) based on a pretrained ConvNet. </li>
<li>The content cost function is computed using one hidden layer’s activations.</li>
<li>The style cost function for one layer is computed using the Gram matrix of that layer’s activations. The overall style cost function is obtained using several hidden layers.</li>
<li>Optimizing the total cost function results in synthesizing new images. </li>
</ul>
</li>
</ul>
<h4 id="风格代价函数-style-cost-function"><a href="#风格代价函数-style-cost-function" class="headerlink" title="风格代价函数(style cost function)"></a>风格代价函数(style cost function)</h4><ul>
<li>定义：现在你选择了某一层𝑙，比如这一层去为图片的风格定义一个 深度测量，现在我们要做的就是将图片的风格定义为𝑙层中各个通道之间<font color="blue">激活项</font>的相关系数</li>
<li>理解CNN中的神经元<ul>
<li><font color="red">一个神经元就表示一个filter的及输出，在输出中就表示一个通道，也代表一个特征</font><ul>
<li>这个红色的通道(编号1)对应(编号 3),它能找出图片中的特定位置是否含有这些垂直的纹理</li>
<li>而第二 个通道也就是黄色的通道(编号 2)，对应这个神经元(编号 4)<img src="/2018/11/26/dl/第四门课-第四周/resources/D422B96088E7C2335C19E0465394B878.jpg"></li>
</ul>
</li>
</ul>
</li>
<li>理解相关系数<ul>
<li>定义：相关系数这个概念为你提供了一种去测量这些不同的特征的方法，比如这些垂直纹理，这些橙色或是其他的特征去<font color="blue">测量它们在图片中的各个位置同时出现或不同时出现的频率</font></li>
<li>意义：通过测量，你能得知在生成的<br>图像中垂直纹理和橙色同时出现或者不同时出现的频率，这样你将能够<font color="blue">测量生成的图像的风格与输入的风格图像的相似程度</font></li>
</ul>
</li>
<li>风格矩阵(Gram matrix)(Correlation between filters)：<img src="/2018/11/26/dl/第四门课-第四周/resources/AAB98D324EC1AC62752A4C3A792DE9D5.jpg">
<ul>
<li>通过对k和k’通道中中所有的数值<font color="blue">(注意是激活值，不是各个filter的值)</font>进行计算就得到了𝐺矩阵，也就是风格矩阵</li>
<li>如果不相关，那么$G^{[l]}_{KK’}$会比较小，否则就会很大<img src="/2018/11/26/dl/第四门课-第四周/resources/F2F75B0A0E6AA66A42FB991DAA65DE27.jpg">
<img src="/2018/11/26/dl/第四门课-第四周/resources/E55DCEDA125DF80889F4EC8D3AB77521.jpg">
code:<img src="/2018/11/26/dl/第四门课-第四周/resources/BD74761FA9DA43CE218D8AD9865DA49E.jpg"></li>
<li>分别计算出G和S图片的矩阵，然后带入下面的cost function<font color="blue">这将得到这两个矩阵之间的误差</font></li>
</ul>
</li>
<li>Cost function<ul>
<li><font color="red">直观感受：就是对两张图片分别计算不同通道的输出的相关性G1,G2(上面的风格矩阵)(Gram matrix就展示的不同激活值(filter输出)之间相似度，有点像协方差),然后再优化<strong>使</strong>这两张图片的不同通道的值差距减小，即类似于$\sum(G1-G2)$，cost越小，表示两越相近</font></li>
<li>一般只计算其中<font color="blue">一层</font>的cost，当然可以对每层都这样计算cost，然后相加，但要复杂一些<img src="/2018/11/26/dl/第四门课-第四周/resources/2079BF705ED2A829D0E1EFE3891B921F.jpg"></li>
<li>这是两个矩阵间一个基 本的 Frobenius 范数<img src="/2018/11/26/dl/第四门课-第四周/resources/2155AA530BE9533AA5D00319DAAA164E.jpg">
</li>
</ul>
</li>
</ul>
<h4 id="CNN同样适合于一维到三维"><a href="#CNN同样适合于一维到三维" class="headerlink" title="CNN同样适合于一维到三维"></a>CNN同样适合于一维到三维</h4><p>CNN同样适合于一维和三维数据，但对一维数据(和时间序列相关的)的处理，更常见的使用RNN</p>
<ul>
<li>一维<br>比如心电图信息处理等，它的卷积核更像是一维的滑动窗口一样<img src="/2018/11/26/dl/第四门课-第四周/resources/29B3999CE968EA9B047F4E4360D052E6.jpg"></li>
<li>三维<br>比如在CT图像上，一张图片就是人体的一个切面，当然这种情况它的卷积核也是三维的，并且也可以有通道数<img src="/2018/11/26/dl/第四门课-第四周/resources/31924BC92BF9513EA102C74DE4440FFD.jpg"></li>
</ul>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


	
    
	
    
	
    
	
      	    

  

  
  
  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/11/22/dl/第四门课-第三周/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="雷哥">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/favicon.ico">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="雷哥的博客">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/11/22/dl/第四门课-第三周/" itemprop="url">第四门课-第三周</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-11-22T18:17:09+08:00">
                2018-11-22
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing">
                  <a href="/categories/深度学习/" itemprop="url" rel="index">
                    <span itemprop="name">深度学习</span>
                  </a>
                </span>

                
                
                  ， 
                
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing">
                  <a href="/categories/深度学习/吴恩达课程总结/" itemprop="url" rel="index">
                    <span itemprop="name">吴恩达课程总结</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p><a href="https://github.com/yuancl/dl-algorithm/tree/master/4-ConvolutionNeuralNetworks/Week3" target="_blank" rel="noopener">习题代码地址(主要是YOLO实现)</a></p>
<h4 id="目标定位"><a href="#目标定位" class="headerlink" title="目标定位"></a>目标定位</h4><ul>
<li>定义：<br>在分类问题输出y的基础上增加物体位置的输出：$b_x,b_y,b_w,b_h$及中心坐标及宽高<img src="/2018/11/22/dl/第四门课-第三周/resources/82632EA2C641B2BE9175E3D5AF8DC4DD.jpg"></li>
<li>Loss函数的定义：<br>输出为以y向量，采用平方误差的策略，$L(\hat y,y)=(\hat {y_1}-y_1)^2 + (\hat {y_2}-y_2)^2 + (\hat {y_3}-y_3)^2 + … +(\hat {y_8}-y_8)^2$<img src="/2018/11/22/dl/第四门课-第三周/resources/D79C453613C69F31B4A433AEC8DD5233.jpg">
</li>
</ul>
<h4 id="特征点检测-Landmark-detection"><a href="#特征点检测-Landmark-detection" class="headerlink" title="特征点检测(Landmark detection)"></a>特征点检测(Landmark detection)</h4><ul>
<li>神经网络可以通过输出图片上的特征点的(x,y)坐标来实现对目标特征的识别，例如人脸检测或者snapchar上的头带皇冠的功能：<ul>
<li>人脸检测：对人脸进行64个特征点的检测，总共输出129维的向量,$y_1$表示又没有人脸,然后是64个坐标($x_i,y_i$)</li>
<li>Snapchat：也是通过检测头的上部特征点</li>
<li>或者是人的姿势，也是一些特征点<img src="/2018/11/22/dl/第四门课-第三周/resources/53794E6970AEADBB960981204AE87AED.jpg">
</li>
</ul>
</li>
</ul>
<h4 id="目标检测-Object-detection"><a href="#目标检测-Object-detection" class="headerlink" title="目标检测(Object detection)"></a>目标检测(Object detection)</h4><ul>
<li>Sliding window detection<br>一般会获取三次不同大小的窗口，然后循环图片进行检测<img src="/2018/11/22/dl/第四门课-第三周/resources/F75EFA50CA3AD4A7F3B5F37AD1D312A0.jpg"></li>
<li>计算成本<br>计算成本比较大，步幅大一点能够缩小成本，但是效果不好。步幅小一点检测效果当然会很好，但是计算成本会很大</li>
</ul>
<h4 id="卷积的滑动窗口实现"><a href="#卷积的滑动窗口实现" class="headerlink" title="卷积的滑动窗口实现"></a>卷积的滑动窗口实现</h4><ul>
<li>需要将全连接进行卷积改造<img src="/2018/11/22/dl/第四门课-第三周/resources/A7D2177146E9D5AC92F3894785A9E311.jpg"></li>
<li>实现要点：<ul>
<li>如果按照原始方法，进行四次切割，然后将14x14的图片给CNN，那边就是跑四次CNN，并且中间会有很多重复计算</li>
<li>所以用卷积进行替换，将16x16整张图进行卷积操作<ul>
<li>最后输出的2x2x4网络，需要理解：每一个1x1x4的网络就是类比的原始方法切分后的图片的输出，所以这里会有2x2就是4种切分方式的输出<font color="red">(可以一步一步卷积过程来理解2x2为什么代表之前的四次切分)</font><img src="/2018/11/22/dl/第四门课-第三周/resources/43FC4A32BA0AE542CA77250673434887.jpg"></li>
</ul>
</li>
</ul>
</li>
<li>其他28x28举例：<br>最终是8x8x4 的输出，原始的表示切割了64次，每一次切割后输出都是4种分类<img src="/2018/11/22/dl/第四门课-第三周/resources/95753022667FF235751C309B4A5D7C90.jpg">  
</li>
</ul>
<h4 id="YOLO算法"><a href="#YOLO算法" class="headerlink" title="YOLO算法"></a>YOLO算法</h4><ul>
<li>背景：卷积滑动窗口也不能输出最精准的边界框</li>
<li>算法：<ul>
<li>使用卷积滑动，所以效率比较高</li>
<li>将图片分为3x3，或者19x19，找到对象的中心点所属于的小窗口。然后计算出相对于小窗口的宽带和高度，其中宽带和高度可能会大于1<img src="/2018/11/22/dl/第四门课-第三周/resources/C39D37492B779A3EFD04C6F8AD2C58BA.jpg">
<img src="/2018/11/22/dl/第四门课-第三周/resources/2064B40E26923324CBE1ED8CB3D8C96C.jpg">
</li>
</ul>
</li>
</ul>
<h4 id="交并比"><a href="#交并比" class="headerlink" title="交并比"></a>交并比</h4><ul>
<li>背景：如何判断对象检测算法运作良好呢</li>
<li>一般如果Iou大于0.5就算比较理想<img src="/2018/11/22/dl/第四门课-第三周/resources/E190541366C37B452010A650309F0843.jpg">
</li>
</ul>
<h4 id="非极大值抑制"><a href="#非极大值抑制" class="headerlink" title="非极大值抑制"></a>非极大值抑制</h4><ul>
<li><p>背景：你的算法可能对同一个对象做出多次 检测，所以算法不是对某个对象检测出一次，而是检测出多次<br>比如下面这个图，多个小方框都会说自己内部可能有对象</p>
<img src="/2018/11/22/dl/第四门课-第三周/resources/14897CDC1065F896306DAE0BBB63D19F.jpg">
</li>
<li><p>定义：非最大值意味着你只输出概率最大的分类结果，但抑制很接 近，但不是最大的其他预测结果，所以这方法叫做非极大值抑制</p>
</li>
<li><p>找到一个最大的$P_c$,非极大值抑制就会逐一审视 剩下的矩形，所有和这个最大的边框有很高交并比(IoU)，高度重叠的其他边界框，那么这些输出 就会被抑制</p>
</li>
<li><p>算法步骤：</p>
<ul>
<li>1.得到标记所有边框界，去掉这些边框界中$P_c$很小的，比如0.6，表示出现对象的概率很低</li>
<li>2.找到剩下的边框界中最大的$P_c$，然后去掉和$P_c$重合度最高，也就是IoU比较大的一些边框界</li>
<li>3.在剩下的边框界中重复2步骤，直到每一个边框界都被处理过</li>
</ul>
</li>
</ul>
<h4 id="Anchor-Boxes"><a href="#Anchor-Boxes" class="headerlink" title="Anchor Boxes"></a>Anchor Boxes</h4><ul>
<li>背景：对象检测中存在的一个问题是每个格子只能检测出一个对象,如果你想让一个格子检测出多个对象，可以使用Anchor Boxes</li>
<li>思路：而 anchor box的思路是，这样子，预先定义两个不同形状的 anchor box，或者 anchor box 形状，你要做的是把预测结果和这两个 anchor box <strong>关联起来</strong></li>
<li>算法：输出为16维的向量，分别对应2个archor，然后找到和哪个archor的IoU最高，就和谁关联(每个archor会表示对应到哪个对象)<img src="/2018/11/22/dl/第四门课-第三周/resources/839F34619E1A18553C7228719CF4E324.jpg">
<img src="/2018/11/22/dl/第四门课-第三周/resources/E20DD21008E63DD76E94BE4695C6F6C8.jpg">
</li>
</ul>
<h4 id="YOLO算法-集成"><a href="#YOLO算法-集成" class="headerlink" title="YOLO算法(集成)"></a>YOLO算法(集成)</h4><ul>
<li>Train<img src="/2018/11/22/dl/第四门课-第三周/resources/8B11A706D91156D5BC28FF762DEFF029.jpg"></li>
<li>Prediction<br>方框1得到右边3的输出，方框2得到右边4的输出，最后得到了每个grid(3x3)都得到了一个16维的向量<img src="/2018/11/22/dl/第四门课-第三周/resources/A1B5933F37A0758678E7EA49630F5643.jpg"></li>
<li>Non-max supressed output<ul>
<li>现在得到了每个grid(3x3)都得到了一个16维的向量，先去掉$P_c$比较低的网格，因为这基本代表无对象(下图1-&gt;下图2过程)</li>
<li>对剩下的网格，对每一种类别都使用Non-max supressed方法来确定每个网格对类别的预测<ul>
<li>例如：如果你有三个对象检测类别，你希望检测行人，汽车和摩托车，那么你要做的是， 对于每个类别单独运行非极大值抑制，处理预测结果所属类别的边界框，用非极大值抑制来 处理行人类别，用非极大值抑制处理车子类别，然后对摩托车类别进行非极大值抑制，运行 三次来得到最终的预测结果。所以算法的输出最好能够检测出图像里所有的车子，还有所有 的行人(编号 3 所示)<img src="/2018/11/22/dl/第四门课-第三周/resources/87465058CE19103C0E52E5BBC076A0E5.jpg"></li>
<li>对于每个类别单独运行非极大值抑制<img src="/2018/11/22/dl/第四门课-第三周/resources/98FF932F93FB8DFFAC240D4CEA9A2B95.jpg">
</li>
</ul>
</li>
</ul>
</li>
</ul>
<h4 id="候选区域"><a href="#候选区域" class="headerlink" title="候选区域"></a>候选区域</h4><ul>
<li>背景：CNN会对每个区域都进行计算，是它其中一个缺点，它在显然没有任何对象的区域浪费时间</li>
<li>R-CNN：带区域的卷积网络，或者说带区域的 CNN。 这个算法尝试选出一些区域，在这些区域上运行卷积网络分类器是有意义的，不对每个区域进行计算</li>
<li>基本的 R-CNN 算法是使用某种算法求出候选区域， 然后对每个候选区域运行一下分类器，每个区域会输出一个标签，有没有车子?有没有行人?有没有摩托车?并输出一个边界框，这样你就能在确实存在对象的区域得到一个精确的边界框。R-CNN 算法不会直接信任输入的边界框<img src="/2018/11/22/dl/第四门课-第三周/resources/54DB30472F0B94F4C2580982A05ACF38.jpg">
</li>
</ul>
<h4 id="改进算法"><a href="#改进算法" class="headerlink" title="改进算法"></a>改进算法</h4><ul>
<li>Fast R-CNN<br>最初的算法是逐一对区域分类的，所以 Fast R-CNN用的是滑动窗法的一个卷积实现，和之前学习的”卷积的滑动窗口实现”类似</li>
<li>Faster R-CNN<ul>
<li>使用的是卷积神经网络，而不是更传统的分割算法来获得候选区域色块，<strong>来解决得到候选区域的聚类步骤仍然非常缓慢</strong></li>
<li>吴恩达老师认为：我觉得候选区域是一个有趣的想法，但这个方法需要<strong>两步</strong>，首先得到候选区域，然后再分类，相比之下，能够一步做完，类似于YOLO或者你只看一次(You only look once)这个算法，在我看来，是长远而言更有希望的方向，我认为大多数 Faster R-CNN 的算法实现还是比 YOLO 算法慢很多<img src="/2018/11/22/dl/第四门课-第三周/resources/046AA6B1D31278AA8BC847A21DDD56A2.jpg"></li>
</ul>
</li>
</ul>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


	
    
	
    
  </section>

  
  <nav class="pagination">
    <a class="extend prev" rel="prev" href="/page/4/"><i class="fa fa-angle-left"></i></a><a class="page-number" href="/">1</a><span class="space">&hellip;</span><a class="page-number" href="/page/4/">4</a><span class="page-number current">5</span><a class="page-number" href="/page/6/">6</a><span class="space">&hellip;</span><a class="page-number" href="/page/8/">8</a><a class="extend next" rel="next" href="/page/6/"><i class="fa fa-angle-right"></i></a>
  </nav>



          </div>
          


          

        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      

      <section class="site-overview sidebar-panel sidebar-panel-active">
        <div class="site-author motion-element" itemprop="author" itemscope="" itemtype="http://schema.org/Person">
          <img class="site-author-image" itemprop="image" src="/images/favicon.ico" alt="雷哥">
          <p class="site-author-name" itemprop="name">雷哥</p>
           
              <p class="site-description motion-element" itemprop="description">不积跬步无以至千里</p>
          
        </div>
        <nav class="site-state motion-element">

          
            <div class="site-state-item site-state-posts">
              <a href="/archives">
                <span class="site-state-item-count">77</span>
                <span class="site-state-item-name">日志</span>
              </a>
            </div>
          

          
            
            
            <div class="site-state-item site-state-categories">
              <a href="/categories/index.html">
                <span class="site-state-item-count">21</span>
                <span class="site-state-item-name">分类</span>
              </a>
            </div>
          

          
            
            
            <div class="site-state-item site-state-tags">
              <a href="/tags/index.html">
                <span class="site-state-item-count">19</span>
                <span class="site-state-item-name">标签</span>
              </a>
            </div>
          

        </nav>

        

        <div class="links-of-author motion-element">
          
            
              <span class="links-of-author-item">
                <a href="https://github.com/yuancl" target="_blank" title="GitHub">
                  
                    <i class="fa fa-fw fa-github"></i>
                  
                    
                      GitHub
                    
                </a>
              </span>
            
          
        </div>

        
        

        
        

        


      </section>

      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2019</span>
  <span class="with-love">
    <i class="fa fa-雷哥"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">雷哥</span>
</div>


<div class="powered-by">
  由 <a class="theme-link" href="https://hexo.io">Hexo</a> 强力驱动
</div>

<div class="theme-info">
  主题 -
  <a class="theme-link" href="https://github.com/iissnan/hexo-theme-next">
    NexT.Gemini
  </a>
</div>


        

        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>

  
  <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>

  
  <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.2"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.2"></script>



  
  


  <script type="text/javascript" src="/js/src/affix.js?v=5.1.2"></script>

  <script type="text/javascript" src="/js/src/schemes/pisces.js?v=5.1.2"></script>



  
    <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.2"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.2"></script>

  

  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.2"></script>



  


  




	





  





  






  





  

  

  

  
  
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        tex2jax: {
          inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
          processEscapes: true,
          skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
        }
      });
    </script>

    <script type="text/x-mathjax-config">
      MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for (i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
        }
      });
    </script>
    <script type="text/javascript" src="//cdn.bootcss.com/mathjax/2.7.1/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
  


  

  

</body>
</html>
